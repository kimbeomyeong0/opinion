# 크롤러 병렬 파이프라인

9개의 정치 기사 크롤러를 4단계로 나누어 안정적으로 실행하는 병렬 파이프라인입니다.

## 🎯 파이프라인 구조

### 1단계: 단순한 HTML 크롤러 (병렬 실행)
- **오마이뉴스** (`ohmynews_politics.py`)
- **연합뉴스** (`yonhap_politics.py`)

### 2단계: API 기반 크롤러 (병렬 실행)
- **한겨레** (`hani_politics.py`)
- **뉴스원** (`newsone_politics.py`)
- **경향신문** (`khan_politics.py`)

### 3단계: 복잡한 HTML 크롤러 (순차 실행)
- **동아일보** (`donga_politics.py`)
- **중앙일보** (`joongang_politics.py`)
- **뉴시스** (`newsis_politics.py`)

### 4단계: 복잡한 API 크롤러 (단일 실행)
- **조선일보** (`chosun_politics.py`)

## 🚀 사용법

### 전체 파이프라인 실행
```bash
python3 crawler/run_crawler_pipeline.py
```

### 단계별 실행
```bash
# 1단계만 실행
python3 crawler/run_crawler_stage.py 1

# 2단계만 실행
python3 crawler/run_crawler_stage.py 2

# 3단계만 실행
python3 crawler/run_crawler_stage.py 3

# 4단계만 실행
python3 crawler/run_crawler_stage.py 4
```

## ⚙️ 설정

`crawler/config.py` 파일에서 다음 설정을 조정할 수 있습니다:

- **크롤러별 파라미터**: 페이지 수, 수집 기사 수 등
- **실행 모드**: 병렬/순차 실행 설정
- **대기 시간**: 단계별 대기 시간
- **재시도 설정**: 실패 시 재시도 횟수

## 📊 모니터링

파이프라인 실행 중 다음 정보를 실시간으로 확인할 수 있습니다:

- 각 크롤러의 실행 상태
- 수집된 기사 수
- 실행 시간
- 오류 메시지
- 전체 성공률

## 🔧 주요 특징

### 리소스 관리
- **세마포어**: 동시 실행 크롤러 수 제한
- **Playwright 격리**: 브라우저 리소스 충돌 방지
- **단계별 실행**: 리소스 사용량에 따른 순차 실행

### 에러 핸들링
- **격리된 실행**: 하나의 크롤러 실패가 전체에 영향 없음
- **상세한 로깅**: 각 단계별 실행 결과 추적
- **재시도 로직**: 일시적 오류에 대한 자동 재시도

### 성능 최적화
- **병렬 처리**: 가능한 크롤러들의 동시 실행
- **배치 처리**: 대량 데이터 처리 최적화
- **메모리 관리**: 효율적인 리소스 사용

## 📈 예상 성능

- **전체 실행 시간**: 약 15-20분
- **수집 기사 수**: 총 1,000+ 기사
- **성공률**: 90% 이상 목표

## 🛠️ 문제 해결

### 일반적인 문제
1. **메모리 부족**: Playwright 크롤러 순차 실행으로 해결
2. **네트워크 오류**: 재시도 로직으로 자동 복구
3. **DB 연결 오류**: 연결 풀 설정 조정

### 로그 확인
실행 중 상세한 로그가 출력되며, 오류 발생 시 구체적인 오류 메시지를 확인할 수 있습니다.

## 📝 주의사항

- 크롤러 실행 전 Supabase 연결 설정 확인
- 충분한 메모리와 네트워크 대역폭 확보
- 각 언론사의 이용약관 준수
- 과도한 요청으로 인한 차단 방지
