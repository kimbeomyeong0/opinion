#!/usr/bin/env python3
"""
ê²½í–¥ì‹ ë¬¸ ì •ì¹˜ ì„¹ì…˜ ê¸°ì‚¬ í¬ë¡¤ëŸ¬
"""

import asyncio
import sys
import os
from datetime import datetime
import httpx
import pytz
from playwright.async_api import async_playwright
from rich.console import Console

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from utils.supabase_manager import SupabaseManager

console = Console()

class KhanPoliticsCollector:
    def __init__(self):
        self.base_url = "https://www.khan.co.kr"
        self.api_url = "https://www.khan.co.kr/SecListData.html"
        self.media_name = "ê²½í–¥ì‹ ë¬¸"
        self.articles = []
        self.supabase_manager = SupabaseManager()
        self._playwright = None
        self._browser = None
        self._semaphore = asyncio.Semaphore(4)  # ë™ì‹œ ì²˜ë¦¬ ì œí•œ
        
    async def run(self, num_pages: int = 15):
        """í¬ë¡¤ë§ ì‹¤í–‰"""
        try:
            console.print(f"ğŸš€ {self.media_name} ì •ì¹˜ ê¸°ì‚¬ í¬ë¡¤ë§ ì‹œì‘")
            
            # ê¸°ì‚¬ ëª©ë¡ ìˆ˜ì§‘
            await self.collect_articles(num_pages)
            
            if not self.articles:
                console.print("âŒ ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ë³¸ë¬¸ ìˆ˜ì§‘
            await self.collect_contents()
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
            await self.save_articles()
            
            console.print("\\nğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ!")
            
        except KeyboardInterrupt:
            console.print("â¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤")
        except Exception as e:
            console.print(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        finally:
            await self.cleanup()
    
    async def collect_articles(self, num_pages: int = 15):
        """ê¸°ì‚¬ ëª©ë¡ ìˆ˜ì§‘ - ë³‘ë ¬ ì²˜ë¦¬ë¡œ ìµœì í™”"""
        console.print(f"ğŸ“„ {num_pages}ê°œ í˜ì´ì§€ì—ì„œ ê¸°ì‚¬ ìˆ˜ì§‘ ì‹œì‘...")
        
        # ë³‘ë ¬ ì²˜ë¦¬ë¡œ í˜ì´ì§€ ìˆ˜ì§‘
        tasks = [self._get_page_articles(page) for page in range(1, num_pages + 1)]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ê²°ê³¼ ìˆ˜ì§‘
        for i, result in enumerate(results, 1):
            if isinstance(result, Exception):
                console.print(f"âŒ í˜ì´ì§€ {i} ìˆ˜ì§‘ ì‹¤íŒ¨: {result}")
            else:
                self.articles.extend(result)
                console.print(f"âœ… í˜ì´ì§€ {i} ìˆ˜ì§‘ ì™„ë£Œ: {len(result)}ê°œ ê¸°ì‚¬")
        
        console.print(f"\\nğŸ“Š ìˆ˜ì§‘ ì™„ë£Œ: {len(self.articles)}ê°œ ì„±ê³µ")
    
    async def _get_page_articles(self, page_num: int):
        """íŠ¹ì • í˜ì´ì§€ì—ì„œ ê¸°ì‚¬ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            # í˜„ì¬ ë…„ì›” ê³„ì‚°
            now = datetime.now()
            year = now.year
            month = now.month
            
            # API ìš”ì²­ ë°ì´í„°
            payload = {
                "syncType": "async",
                "type": "politics", 
                "year": str(year),
                "month": str(month).zfill(2),
                "page": str(page_num)
            }
            
            console.print(f"ğŸ“¡ í˜ì´ì§€ {page_num} API í˜¸ì¶œ: {payload}")
            
            async with httpx.AsyncClient(timeout=10.0) as client:  # íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•
                response = await client.post(
                    self.api_url,
                    data=payload,
                    headers={
                        "Content-Type": "application/x-www-form-urlencoded",
                        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
                    }
                )
                response.raise_for_status()
                
                data = response.json()
                items = data.get("items", [])
                console.print(f"ğŸ“Š í˜ì´ì§€ {page_num}ì—ì„œ {len(items)}ê°œ ê¸°ì‚¬ ë°œê²¬")
                
                articles = []
                for i, item in enumerate(items[:10]):  # ê° í˜ì´ì§€ì—ì„œ ìµœëŒ€ 10ê°œ ìˆ˜ì§‘
                    article = {
                        "art_id": item.get("art_id"),
                        "title": item.get("art_title", ""),
                        "summary": item.get("summary", ""),
                        "publish_date": item.get("publish_date", ""),
                        "url": item.get("url", f"{self.base_url}/article/{item.get('art_id')}")
                    }
                    articles.append(article)
                    console.print(f"ğŸ“° ê¸°ì‚¬ {i+1}: {article['title'][:50]}...")
                
                return articles
                
        except Exception as e:
            console.print(f"âŒ í˜ì´ì§€ {page_num} ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            return []

    async def collect_contents(self):
        """ê¸°ì‚¬ ë³¸ë¬¸ ìˆ˜ì§‘ - ë³‘ë ¬ ì²˜ë¦¬ë¡œ ìµœì í™”"""
        console.print(f"ğŸ“– ë³¸ë¬¸ ìˆ˜ì§‘ ì‹œì‘: {len(self.articles)}ê°œ ê¸°ì‚¬")
        
        # ë¸Œë¼ìš°ì € ì´ˆê¸°í™”
        if not self._browser:
            self._playwright = await async_playwright().start()
            self._browser = await self._playwright.chromium.launch(
                headless=True,
                args=[
                    '--no-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-gpu',
                    '--disable-web-security',
                    '--disable-features=VizDisplayCompositor',
                    '--memory-pressure-off',
                    '--disable-background-timer-throttling',
                    '--disable-backgrounding-occluded-windows',
                    '--disable-renderer-backgrounding'
                ]
            )
        
        # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë³¸ë¬¸ ìˆ˜ì§‘
        tasks = [self._extract_content_with_browser(article['url']) for article in self.articles]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ê²°ê³¼ ì²˜ë¦¬
        success_count = 0
        for i, (article, result) in enumerate(zip(self.articles, results), 1):
            if isinstance(result, Exception):
                console.print(f"âŒ [{i}/{len(self.articles)}] ë³¸ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {result}")
                article['content'] = ''
                article['published_at'] = article.get('publish_date', '')
            else:
                article['content'] = result.get('content', '')
                article['published_at'] = result.get('published_at', article.get('publish_date', ''))
                success_count += 1
                console.print(f"âœ… [{i}/{len(self.articles)}] ë³¸ë¬¸ ìˆ˜ì§‘ ì„±ê³µ")
        
        console.print(f"ğŸ“Š ë³¸ë¬¸ ìˆ˜ì§‘ ì™„ë£Œ: {success_count}/{len(self.articles)}ê°œ ì„±ê³µ")
        
    async def _extract_content_with_browser(self, url: str):
        """ë¸Œë¼ìš°ì € ì¬ì‚¬ìš©í•˜ì—¬ ê¸°ì‚¬ ë‚´ìš© ì¶”ì¶œ - ìµœì í™”ëœ ë²„ì „"""
        async with self._semaphore:  # ë™ì‹œ ì²˜ë¦¬ ì œí•œ
            page = None
            try:
                page = await self._browser.new_page()
                await page.goto(url, wait_until='domcontentloaded', timeout=10000)  # íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•
                
                # ë³¸ë¬¸ ì˜ì—­ ëŒ€ê¸° (ìš°ì„ ìˆœìœ„ë³„)
                content_selectors = [
                    'div.art_body#articleBody',
                    'div.art_body',
                    'div[class*="art_body"]',
                    '.article-body',
                    'article'
                ]
                
                content_loaded = False
                for selector in content_selectors:
                    try:
                        await page.wait_for_selector(selector, timeout=2000)
                        content_loaded = True
                        break
                    except:
                        continue
                
                if not content_loaded:
                    console.print(f"âš ï¸ ë³¸ë¬¸ ì˜ì—­ ë¡œë“œ ì‹¤íŒ¨: {url}")
                    return {"content": "", "published_at": ""}
                
                # JavaScriptë¡œ ë°ì´í„° ì¶”ì¶œ - ìµœì í™”ëœ ë²„ì „
                content_data = await page.evaluate("""
                    () => {
                        const result = { published_at: '', content: '' };
                        
                        // 1. ë°œí–‰ì‹œê° ì¶”ì¶œ (ìš°ì„ ìˆœìœ„ë³„)
                        const timeSelectors = [
                            'a[title*="ê¸°ì‚¬ ì…ë ¥/ìˆ˜ì •ì¼"]',
                            '.article-date',
                            '.date',
                            'time'
                        ];
                        
                        for (const selector of timeSelectors) {
                            const element = document.querySelector(selector);
                            if (element) {
                                const paragraphs = element.querySelectorAll('p');
                                let inputTime = '';
                                let modifyTime = '';
                                
                                paragraphs.forEach(p => {
                                    const text = p.textContent || '';
                                    if (text.includes('ì…ë ¥')) {
                                        inputTime = text.replace('ì…ë ¥', '').trim();
                                    } else if (text.includes('ìˆ˜ì •')) {
                                        modifyTime = text.replace('ìˆ˜ì •', '').trim();
                                    }
                                });
                                
                                result.published_at = modifyTime || inputTime || element.textContent?.trim();
                                if (result.published_at) break;
                            }
                        }
                        
                        // 2. ë³¸ë¬¸ ì¶”ì¶œ (ìš°ì„ ìˆœìœ„ë³„)
                        const contentSelectors = [
                            'div.art_body#articleBody',
                            'div.art_body',
                            'div[class*="art_body"]',
                            'div[class*="article"]',
                            'div[class*="content"]'
                        ];
                        
                        let articleBody = null;
                        for (const selector of contentSelectors) {
                            articleBody = document.querySelector(selector);
                            if (articleBody) break;
                        }
                        
                        if (articleBody) {
                            // ê´‘ê³ /ë°°ë„ˆ ì œê±°
                            const unwantedSelectors = [
                                'div[class*="banner"]', 'div[class*="ad"]', 'div[class*="advertisement"]',
                                'script', 'style', 'noscript', 'iframe'
                            ];
                            
                            unwantedSelectors.forEach(selector => {
                                const elements = articleBody.querySelectorAll(selector);
                                elements.forEach(el => el.remove());
                            });
                            
                            // ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìš°ì„ ìˆœìœ„ë³„)
                            const paragraphSelectors = [
                                'p.content_text.text-l',
                                'p.content_text',
                                'p.text-l',
                                'p'
                            ];
                            
                            let contentParagraphs = null;
                            for (const selector of paragraphSelectors) {
                                contentParagraphs = articleBody.querySelectorAll(selector);
                                if (contentParagraphs.length > 0) break;
                            }
                            
                            const contentTexts = [];
                            
                            contentParagraphs?.forEach(p => {
                                let text = p.textContent?.trim() || '';
                                
                                // í•„í„°ë§: ê¸°ìëª…, ì´ë©”ì¼, ì¶œì²˜ ì œê±°
                                text = text.replace(/[ê°€-í£]+\\s*ê¸°ì/g, '')
                                          .replace(/[ê°€-í£]+\\s*íŠ¹íŒŒì›/g, '')
                                          .replace(/[ê°€-í£]+\\s*í†µì‹ ì›/g, '')
                                          .replace(/[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}/g, '')
                                          .replace(/\\[ì¶œì²˜:[^\\]]+\\]/g, '')
                                          .replace(/\\[ê²½í–¥ì‹ ë¬¸\\]/g, '');
                                
                                // ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                                if (text && text.length > 20 && !text.match(/^\\s*$/)) {
                                    contentTexts.push(text);
                                }
                            });
                            
                            result.content = contentTexts.join('\\n\\n');
                        }
                        
                        return result;
                    }
                """)
                
                await page.close()
                return content_data
                
            except Exception as e:
                console.print(f"âŒ ê¸°ì‚¬ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨ {url}: {str(e)}")
                return {"published_at": "", "content": ""}
            finally:
                if page:
                    try:
                        await page.close()
                    except:
                        pass
    
    
    def parse_published_time(self, time_str: str) -> datetime:
        """ë°œí–‰ì‹œê°„ ë¬¸ìì—´ì„ UTC datetimeìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        if not time_str or not time_str.strip():
            return datetime.now(pytz.UTC)
        
        try:
            # "2025.01.05 21:43" í˜•ì‹ íŒŒì‹±
            clean_time = time_str.strip()
            if '.' in clean_time and ':' in clean_time:
                # KST ì‹œê°„ìœ¼ë¡œ íŒŒì‹±
                published_at = datetime.strptime(clean_time, "%Y.%m.%d %H:%M")
                kst = pytz.timezone("Asia/Seoul")
                published_at = kst.localize(published_at)
                # UTCë¡œ ë³€í™˜
                return published_at.astimezone(pytz.UTC)
            else:
                console.print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì‹œê°„ í˜•ì‹: {clean_time}")
                return datetime.now(pytz.UTC)
            
        except Exception as e:
            console.print(f"âš ï¸ ë°œí–‰ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨: {time_str} - {e}")
            return datetime.now(pytz.UTC)
    
    async def save_articles(self):
        """ê¸°ì‚¬ ì €ì¥"""
        console.print(f"ğŸ’¾ Supabaseì— {len(self.articles)}ê°œ ê¸°ì‚¬ ì €ì¥ ì¤‘...")
        
        # ì–¸ë¡ ì‚¬ í™•ì¸
        media = self.supabase_manager.get_media_outlet(self.media_name)
        if not media:
            media_id = self.supabase_manager.create_media_outlet(
                name=self.media_name,
                bias="center-left",
                website=self.base_url
            )
        else:
            media_id = media["id"]
        
        # ì¤‘ë³µ ì²´í¬
        urls = [art["url"] for art in self.articles]
        existing_urls = set()
        
        try:
            for url in urls:
                exists = self.supabase_manager.client.table("articles").select("url").eq("url", url).execute()
                if exists.data:
                    existing_urls.add(url)
        except Exception as e:
            console.print(f"âš ï¸ ì¤‘ë³µ ì²´í¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        success_count = 0
        skip_count = 0
        
        for i, article in enumerate(self.articles, 1):
            try:
                # ì¤‘ë³µ ì²´í¬
                if article["url"] in existing_urls:
                    console.print(f"âš ï¸ [{i}/{len(self.articles)}] ì¤‘ë³µ ê¸°ì‚¬ ìŠ¤í‚µ: {article['title'][:50]}...")
                    skip_count += 1
                    continue
                
                # ë°œí–‰ì‹œê°„ íŒŒì‹±
                published_at = self.parse_published_time(article["published_at"])
                
                # ê¸°ì‚¬ ë°ì´í„° êµ¬ì„±
                article_data = {
                    "title": article["title"],
                    "url": article["url"],
                    "content": article["content"],
                    "published_at": published_at.isoformat(),
                    "created_at": datetime.now(pytz.UTC).isoformat(),
                    "media_id": media_id
                }
                
                # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                success = self.supabase_manager.insert_article(article_data)
                if success:
                    console.print(f"âœ… [{i}/{len(self.articles)}] ì €ì¥ ì„±ê³µ: {article['title'][:50]}...")
                    success_count += 1
                else:
                    console.print(f"âŒ [{i}/{len(self.articles)}] ì €ì¥ ì‹¤íŒ¨: {article['title'][:50]}...")
                    
            except Exception as e:
                console.print(f"âŒ [{i}/{len(self.articles)}] ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        
        console.print(f"\\nğŸ“Š ì €ì¥ ê²°ê³¼:")
        console.print(f"  âœ… ì„±ê³µ: {success_count}ê°œ")
        console.print(f"  âš ï¸ ì¤‘ë³µ ìŠ¤í‚µ: {skip_count}ê°œ")
        total_processed = success_count + skip_count
        success_rate = (success_count / total_processed) * 100 if total_processed > 0 else 0
        console.print(f"  ğŸ“ˆ ì„±ê³µë¥ : {success_rate:.1f}%")
    
    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            if self._browser:
                await self._browser.close()
                self._browser = None
            if self._playwright:
                await self._playwright.stop()
                self._playwright = None
            console.print("ğŸ§¹ ê²½í–¥ì‹ ë¬¸ í¬ë¡¤ëŸ¬ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            console.print(f"âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)[:50]}")

async def main():
    collector = KhanPoliticsCollector()
    await collector.run(num_pages=15)  # 15í˜ì´ì§€ì—ì„œ ê°ê° 10ê°œì”© ì´ 150ê°œ ê¸°ì‚¬ ìˆ˜ì§‘

if __name__ == "__main__":
    asyncio.run(main())