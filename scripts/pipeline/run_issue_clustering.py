#!/usr/bin/env python3
"""
ì´ìŠˆ í´ëŸ¬ìŠ¤í„°ë§ ìŠ¤í¬ë¦½íŠ¸
ë¦¬ë“œë¬¸ ê¸°ë°˜ìœ¼ë¡œ ì •ì¹˜ ë‰´ìŠ¤ë¥¼ ì´ìŠˆë³„ë¡œ êµ°ì§‘í™”
"""

import sys
import os
import json
import pytz
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from utils.supabase_manager import SupabaseManager

# OpenAI ì„¤ì¹˜ í™•ì¸ ë° import
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    print("âŒ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("pip install openai ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
    OPENAI_AVAILABLE = False

@dataclass
class Article:
    """ê¸°ì‚¬ ë°ì´í„° í´ë˜ìŠ¤"""
    id: str
    title: str
    lead_content: str
    media_id: str
    published_at: str

@dataclass
class Cluster:
    """í´ëŸ¬ìŠ¤í„° ë°ì´í„° í´ë˜ìŠ¤"""
    id: str
    name: str
    keywords: List[str]
    articles: List[Article]
    issue_number: Optional[int] = None

class IssueClustering:
    """ì´ìŠˆ í´ëŸ¬ìŠ¤í„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.supabase_manager = SupabaseManager()
        if not self.supabase_manager.client:
            raise Exception("Supabase ì—°ê²° ì‹¤íŒ¨")
        
        if OPENAI_AVAILABLE:
            self.openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        else:
            self.openai_client = None
        
        # ì–¸ë¡ ì‚¬ ì„±í–¥ ë§¤í•‘ í…Œì´ë¸”
        self.media_bias_mapping = self.get_media_bias_mapping()
    
    def get_media_bias_mapping(self) -> Dict[str, str]:
        """ì–¸ë¡ ì‚¬ ID â†’ ì„±í–¥ ë§¤í•‘ í…Œì´ë¸” ìƒì„±"""
        try:
            result = self.supabase_manager.client.table('media_outlets').select('id, bias').execute()
            return {item['id']: item['bias'] for item in result.data}
        except Exception as e:
            print(f"âŒ ì–¸ë¡ ì‚¬ ì„±í–¥ ë§¤í•‘ ì‹¤íŒ¨: {str(e)}")
            return {}
    
    def parse_date_range(self, date_input: str) -> Tuple[str, str]:
        """ì‚¬ìš©ì ì…ë ¥ì„ KST ë‚ ì§œ ë²”ìœ„ë¡œ íŒŒì‹±"""
        try:
            if '~' in date_input:
                start_str, end_str = date_input.split('~')
            else:
                start_str = end_str = date_input.strip()
            
            current_year = datetime.now().year
            
            # í˜•ì‹ ë³€í™˜: 0910 -> 2024-09-10
            start_date = f"{current_year}-{start_str[:2]}-{start_str[2:]}"
            end_date = f"{current_year}-{end_str[:2]}-{end_str[2:]}"
            
            # KST â†’ UTC ë³€í™˜
            kst = pytz.timezone('Asia/Seoul')
            utc = pytz.UTC
            
            # ì‹œì‘: í•´ë‹¹ ë‚  00:00 KST
            start_kst = kst.localize(datetime.strptime(start_date, '%Y-%m-%d'))
            
            # ì¢…ë£Œ: ë‹¤ìŒë‚  00:00 KST (í•´ë‹¹ ë‚  23:59:59ê¹Œì§€ í¬í•¨)
            end_kst = kst.localize(datetime.strptime(end_date, '%Y-%m-%d') + timedelta(days=1))
            
            start_utc = start_kst.astimezone(utc)
            end_utc = end_kst.astimezone(utc)
            
            return start_utc.isoformat(), end_utc.isoformat()
            
        except Exception as e:
            raise ValueError(f"ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜: {e}")
    
    def fetch_articles_by_date_range(self, start_date: str, end_date: str) -> List[Article]:
        """ë‚ ì§œ ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ” ê¸°ì‚¬ë§Œ ì¡°íšŒ"""
        try:
            print(f"ğŸ“… ë‚ ì§œ ë²”ìœ„: {start_date} ~ {end_date}")
            
            result = self.supabase_manager.client.table('articles').select(
                'id, title, content, media_id, published_at'
            ).eq('is_preprocessed', True).gte('published_at', start_date).lt('published_at', end_date).execute()
            
            if not result.data:
                print("âŒ í•´ë‹¹ ë‚ ì§œ ë²”ìœ„ì— ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            articles = []
            for item in result.data:
                # ë¦¬ë“œë¬¸ ì¶”ì¶œ (ì²« ë²ˆì§¸ ë¬¸ë‹¨)
                lead_content = ""
                if item['content']:
                    paragraphs = item['content'].split('\n\n')
                    lead_content = paragraphs[0].strip() if paragraphs else ""
                
                article = Article(
                    id=item['id'],
                    title=item['title'],
                    lead_content=lead_content,
                    media_id=item['media_id'],
                    published_at=item['published_at']
                )
                articles.append(article)
            
            print(f"âœ… {len(articles)}ê°œ ê¸°ì‚¬ ì¡°íšŒ ì™„ë£Œ")
            return articles
            
        except Exception as e:
            print(f"âŒ ê¸°ì‚¬ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def split_into_8_batches(self, articles: List[Article]) -> List[List[Article]]:
        """8ê°œ ë°°ì¹˜ë¡œ ê· ë“± ë¶„í•  (í† í° ì œí•œ í•´ê²°)"""
        batch_size = len(articles) // 8
        batches = []
        
        for i in range(8):
            start_idx = i * batch_size
            if i == 7:  # ë§ˆì§€ë§‰ ë°°ì¹˜
                end_idx = len(articles)
            else:
                end_idx = (i + 1) * batch_size
            
            batch = articles[start_idx:end_idx]
            batches.append(batch)
        
        return batches
    
    def create_clustering_prompt(self, articles: List[Article]) -> str:
        """ë¦¬ë“œë¬¸ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        articles_text = ""
        for i, article in enumerate(articles, 1):
            articles_text += f"{i}. {article.lead_content}\n\n"
        
        prompt = f"""
ë‹¤ìŒì€ ì •ì¹˜ ë‰´ìŠ¤ì˜ ë¦¬ë“œë¬¸(ì²« ë¬¸ë‹¨)ë“¤ì…ë‹ˆë‹¤. ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ì •ì¹˜ ì´ìŠˆë¥¼ ë‹¤ë£¨ëŠ” ê¸°ì‚¬ë“¤ì„ í•˜ë‚˜ì˜ ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.

ë¦¬ë“œë¬¸ë“¤:
{articles_text}

ë¶„ë¥˜ ê¸°ì¤€:
1. **í•µì‹¬ ì •ì¹˜ ì´ìŠˆ ì¤‘ì‹¬**: ê°™ì€ ì •ì¹˜ì  ì‚¬ê±´, ì •ì±…, ì¸ë¬¼, ê¸°ê´€ì„ ë‹¤ë£¨ëŠ” ê¸°ì‚¬ë“¤
2. **ì˜ë¯¸ì  ìœ ì‚¬ì„±**: ë‹¨ìˆœ í‚¤ì›Œë“œê°€ ì•„ë‹Œ ì „ì²´ì  ë§¥ë½ê³¼ ì •ì¹˜ì  ë°°ê²½ì´ ìœ ì‚¬í•œ ê¸°ì‚¬ë“¤
3. **ì‹œê°„ì  ì—°ì†ì„±**: ê°™ì€ ì´ìŠˆì˜ ì§€ì†ì  ë³´ë„ë‚˜ ê´€ë ¨ í›„ì† ê¸°ì‚¬ë“¤
4. **ì •ì¹˜ì  ë§¥ë½**: ê°™ì€ ì •ì¹˜ ì„¸ë ¥, ì •ë‹¹, ì •ë¶€ ë¶€ì²˜ì™€ ê´€ë ¨ëœ ê¸°ì‚¬ë“¤

ì˜ˆì‹œ:
- "ì‚¬ë²•ê°œí˜" ê´€ë ¨ ê¸°ì‚¬ë“¤ â†’ í•˜ë‚˜ì˜ ê·¸ë£¹
- "íŠ¹ê²€ë²• ê°œì •" ê´€ë ¨ ê¸°ì‚¬ë“¤ â†’ í•˜ë‚˜ì˜ ê·¸ë£¹  
- "í•œë¯¸ê´€ê³„" ê´€ë ¨ ê¸°ì‚¬ë“¤ â†’ í•˜ë‚˜ì˜ ê·¸ë£¹
- "ì •ì¹˜ìê¸ˆ" ê´€ë ¨ ê¸°ì‚¬ë“¤ â†’ í•˜ë‚˜ì˜ ê·¸ë£¹

ìš”êµ¬ì‚¬í•­:
1. ê°™ì€ ì •ì¹˜ ì´ìŠˆë¥¼ ë‹¤ë£¨ëŠ” ê¸°ì‚¬ë“¤ì„ í•˜ë‚˜ì˜ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ì–´ì£¼ì„¸ìš”
2. ê° ê·¸ë£¹ì— ì ì ˆí•œ ì´ë¦„ì„ ì œê³µí•´ì£¼ì„¸ìš” (ì •ì¹˜ ì´ìŠˆëª…)
3. ê° ê·¸ë£¹ì˜ í•µì‹¬ í‚¤ì›Œë“œ 3-5ê°œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”
4. ê·¸ë£¹ì´ ë„ˆë¬´ ë§ê±°ë‚˜ ì ì§€ ì•Šë„ë¡ ì ì ˆí•œ ìˆ˜ì¤€ìœ¼ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš” (5-15ê°œ ê·¸ë£¹ ê¶Œì¥)

ì‘ë‹µ í˜•ì‹ (JSON):
{{
    "clusters": [
        {{
            "name": "ì •ì¹˜ ì´ìŠˆëª…",
            "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"],
            "article_indices": [1, 3, 5, 8]
        }}
    ]
}}
"""
        return prompt
    
    def cluster_with_llm(self, articles: List[Article]) -> Optional[List[Cluster]]:
        """LLMì„ ì‚¬ìš©í•œ í´ëŸ¬ìŠ¤í„°ë§"""
        if not self.openai_client:
            print("âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        try:
            print("ğŸ¤– LLM í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘...")
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.create_clustering_prompt(articles)
            
            # LLM í˜¸ì¶œ
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì •ì¹˜ ë‰´ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¦¬ë“œë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ì •ì¹˜ ì´ìŠˆ ê·¸ë£¹ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=4000
            )
            
            # ì‘ë‹µ íŒŒì‹±
            response_text = response.choices[0].message.content
            print("ğŸ“ LLM ì‘ë‹µ ë°›ìŒ")
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
                json_start = response_text.find('{')
                json_end = response_text.rfind('}') + 1
                json_text = response_text[json_start:json_end]
                
                result = json.loads(json_text)
                clusters_data = result.get('clusters', [])
                
                # Cluster ê°ì²´ë¡œ ë³€í™˜
                clusters = []
                for i, cluster_data in enumerate(clusters_data):
                    article_indices = cluster_data.get('article_indices', [])
                    cluster_articles = [articles[idx-1] for idx in article_indices if 1 <= idx <= len(articles)]
                    
                    cluster = Cluster(
                        id=f"cluster_{i+1}",
                        name=cluster_data.get('name', f'ê·¸ë£¹ {i+1}'),
                        keywords=cluster_data.get('keywords', []),
                        articles=cluster_articles
                    )
                    clusters.append(cluster)
                
                print(f"âœ… {len(clusters)}ê°œ í´ëŸ¬ìŠ¤í„° ìƒì„± ì™„ë£Œ")
                return clusters
                
            except json.JSONDecodeError as e:
                print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
                print(f"ì‘ë‹µ ë‚´ìš©: {response_text[:500]}...")
                return None
                
        except Exception as e:
            print(f"âŒ LLM í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def create_merge_prompt(self, all_clusters: List[List[Cluster]]) -> str:
        """ë°°ì¹˜ ê²°ê³¼ í†µí•©ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        clusters_text = ""
        cluster_id = 1
        
        for batch_idx, batch_clusters in enumerate(all_clusters, 1):
            clusters_text += f"\n=== ë°°ì¹˜ {batch_idx} ê²°ê³¼ ===\n"
            for cluster in batch_clusters:
                clusters_text += f"{cluster_id}. {cluster.name}\n"
                clusters_text += f"   í‚¤ì›Œë“œ: {', '.join(cluster.keywords)}\n"
                clusters_text += f"   ê¸°ì‚¬ ìˆ˜: {len(cluster.articles)}ê°œ\n"
                # ë¦¬ë“œë¬¸ ìƒ˜í”Œ ì¶”ê°€
                sample_articles = cluster.articles[:3]
                clusters_text += f"   ë¦¬ë“œë¬¸ ìƒ˜í”Œ:\n"
                for i, article in enumerate(sample_articles, 1):
                    clusters_text += f"     {i}. {article.lead_content[:100]}...\n"
                clusters_text += "\n"
                cluster_id += 1
        
        prompt = f"""
ë‹¤ìŒì€ ì—¬ëŸ¬ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ í´ëŸ¬ìŠ¤í„°ë§í•œ ì •ì¹˜ ë‰´ìŠ¤ ë¦¬ë“œë¬¸ ê²°ê³¼ì…ë‹ˆë‹¤. ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ì •ì¹˜ ì´ìŠˆë“¤ì„ ì •í™•í•˜ê²Œ í•©ì³ì„œ ìµœì¢… ì´ìŠˆ ëª©ë¡ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼:
{clusters_text}

í†µí•© ê°€ì´ë“œë¼ì¸:
1. **ì •ì¹˜ì  ë§¥ë½ ê³ ë ¤**: ê°™ì€ ì •ì¹˜ ì´ìŠˆì˜ ë‹¤ë¥¸ í‘œí˜„ë“¤ì„ ì¸ì‹í•˜ì„¸ìš”
   - ì˜ˆ: "ì‚¬ë²•ê°œí˜"ê³¼ "ì‚¬ë²•ë¶€ ë…ë¦½"ì€ ê°™ì€ ì´ìŠˆ
   - ì˜ˆ: "ì •ì¹˜ìê¸ˆ"ê³¼ "ë¶€ì •ìˆ˜ê¸‰"ì€ ê°™ì€ ì´ìŠˆ
   - ì˜ˆ: "í•œë¯¸ê´€ê³„"ì™€ "ë¯¸êµ­ ë¹„ìë¬¸ì œ"ëŠ” ê°™ì€ ì´ìŠˆ

2. **ë¦¬ë“œë¬¸ íŠ¹ì„± ê³ ë ¤**: ë¦¬ë“œë¬¸ì€ í•µì‹¬ ì •ë³´ë¥¼ ì••ì¶•ì ìœ¼ë¡œ ë‹´ê³  ìˆìœ¼ë¯€ë¡œ
   - ê°™ì€ ì‚¬ê±´ì˜ ë‹¤ë¥¸ ê°ë„ ë³´ë„ë“¤ì„ ì¸ì‹í•˜ì„¸ìš”
   - ê°™ì€ ì¸ë¬¼, ê¸°ê´€, ì •ì±…ê³¼ ê´€ë ¨ëœ ê¸°ì‚¬ë“¤ì„ ë¬¶ì–´ì£¼ì„¸ìš”

3. **ì˜ë¯¸ì  ìœ ì‚¬ì„± íŒë‹¨**: ë‹¨ìˆœ í‚¤ì›Œë“œê°€ ì•„ë‹Œ ì „ì²´ì  ë§¥ë½ìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”
   - ë¦¬ë“œë¬¸ì˜ í•µì‹¬ ì£¼ì œê°€ ê°™ì€ì§€ í™•ì¸
   - ì •ì¹˜ì  ë§¥ë½ê³¼ ë°°ê²½ì´ ìœ ì‚¬í•œì§€ í™•ì¸

ìš”êµ¬ì‚¬í•­:
1. ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ì •ì¹˜ ì´ìŠˆë“¤ì„ í•˜ë‚˜ë¡œ í•©ì³ì£¼ì„¸ìš”
2. ê° ìµœì¢… ì´ìŠˆì— ì ì ˆí•œ ì´ë¦„ì„ ì œê³µí•´ì£¼ì„¸ìš”
3. ê° ì´ìŠˆì˜ í•µì‹¬ í‚¤ì›Œë“œ 3-5ê°œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”
4. í•©ì³ì§„ ì´ìŠˆì— í¬í•¨ëœ ì›ë³¸ í´ëŸ¬ìŠ¤í„° ë²ˆí˜¸ë“¤ì„ ê¸°ë¡í•´ì£¼ì„¸ìš”

ì‘ë‹µ í˜•ì‹ (JSON):
{{
    "final_clusters": [
        {{
            "name": "ìµœì¢… ì •ì¹˜ ì´ìŠˆëª…",
            "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"],
            "merged_from": [1, 5, 8],
            "confidence": "high|medium|low"
        }}
    ]
}}
"""
        return prompt
    
    def merge_batch_clusters(self, all_clusters: List[List[Cluster]]) -> Optional[List[Cluster]]:
        """ë°°ì¹˜ë³„ í´ëŸ¬ìŠ¤í„° ê²°ê³¼ë“¤ì„ í†µí•©"""
        if not self.openai_client:
            print("âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        try:
            print("ğŸ”„ ë°°ì¹˜ ê²°ê³¼ í†µí•© ì¤‘...")
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self.create_merge_prompt(all_clusters)
            
            # LLM í˜¸ì¶œ
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì •ì¹˜ ë‰´ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì—¬ëŸ¬ ë°°ì¹˜ì˜ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ì •ì¹˜ ì´ìŠˆë“¤ì„ ì •í™•í•˜ê²Œ í•©ì³ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=6000
            )
            
            # ì‘ë‹µ íŒŒì‹±
            response_text = response.choices[0].message.content
            print("ğŸ“ í†µí•© ê²°ê³¼ ë°›ìŒ")
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                json_start = response_text.find('{')
                json_end = response_text.rfind('}') + 1
                json_text = response_text[json_start:json_end]
                
                result = json.loads(json_text)
                final_clusters_data = result.get('final_clusters', [])
                
                # ëª¨ë“  ì›ë³¸ í´ëŸ¬ìŠ¤í„°ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ê¸°
                all_original_clusters = []
                for batch_clusters in all_clusters:
                    all_original_clusters.extend(batch_clusters)
                
                # ìµœì¢… í´ëŸ¬ìŠ¤í„° ìƒì„±
                final_clusters = []
                for i, cluster_data in enumerate(final_clusters_data):
                    merged_from_indices = cluster_data.get('merged_from', [])
                    merged_articles = []
                    confidence = cluster_data.get('confidence', 'medium')
                    
                    # í†µí•©ëœ í´ëŸ¬ìŠ¤í„°ë“¤ì˜ ê¸°ì‚¬ë“¤ì„ ìˆ˜ì§‘
                    for idx in merged_from_indices:
                        if 1 <= idx <= len(all_original_clusters):
                            original_cluster = all_original_clusters[idx - 1]
                            merged_articles.extend(original_cluster.articles)
                    
                    # ì¤‘ë³µ ê¸°ì‚¬ ì œê±°
                    unique_articles = []
                    seen_ids = set()
                    for article in merged_articles:
                        if article.id not in seen_ids:
                            unique_articles.append(article)
                            seen_ids.add(article.id)
                    
                    final_cluster = Cluster(
                        id=f"final_cluster_{i+1}",
                        name=cluster_data.get('name', f'í†µí•© ì´ìŠˆ {i+1}'),
                        keywords=cluster_data.get('keywords', []),
                        articles=unique_articles
                    )
                    final_clusters.append(final_cluster)
                    
                    print(f"  ğŸ“Š í†µí•© ì´ìŠˆ {i+1}: {final_cluster.name} ({len(unique_articles)}ê°œ ê¸°ì‚¬, ì‹ ë¢°ë„: {confidence})")
                
                print(f"âœ… {len(final_clusters)}ê°œ ìµœì¢… í´ëŸ¬ìŠ¤í„° ìƒì„± ì™„ë£Œ")
                return final_clusters
                
            except json.JSONDecodeError as e:
                print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
                print(f"ì‘ë‹µ ë‚´ìš©: {response_text[:500]}...")
                return None
                
        except Exception as e:
            print(f"âŒ ë°°ì¹˜ í†µí•© ì‹¤íŒ¨: {str(e)}")
            return None
    
    def filter_clusters(self, clusters: List[Cluster]) -> List[Cluster]:
        """20ê°œ ë¯¸ë§Œ í´ëŸ¬ìŠ¤í„° ì œì™¸"""
        filtered = [c for c in clusters if len(c.articles) >= 20]
        print(f"ğŸ” 20ê°œ ë¯¸ë§Œ í´ëŸ¬ìŠ¤í„° ì œì™¸: {len(clusters)} â†’ {len(filtered)}ê°œ")
        return filtered
    
    def assign_issue_numbers(self, clusters: List[Cluster]) -> List[Cluster]:
        """ê¸°ì‚¬ ìˆ˜ ìˆœìœ¼ë¡œ ì´ìŠˆ ë²ˆí˜¸ í• ë‹¹"""
        # ê¸°ì‚¬ ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        sorted_clusters = sorted(clusters, key=lambda x: len(x.articles), reverse=True)
        
        for i, cluster in enumerate(sorted_clusters, 1):
            cluster.issue_number = i
            cluster.name = f"{cluster.name} (ì´ìŠˆ {i})"
        
        return sorted_clusters
    
    def count_media_bias(self, cluster: Cluster) -> Dict[str, int]:
        """ì–¸ë¡ ì‚¬ ì„±í–¥ë³„ ê¸°ì‚¬ ìˆ˜ ê³„ì‚°"""
        bias_counts = {'left': 0, 'center': 0, 'right': 0}
        
        for article in cluster.articles:
            bias = self.media_bias_mapping.get(article.media_id, 'center')
            if bias in bias_counts:
                bias_counts[bias] += 1
        
        return bias_counts
    
    def save_to_issues_table(self, clusters: List[Cluster]) -> bool:
        """í´ëŸ¬ìŠ¤í„°ë¥¼ issues í…Œì´ë¸”ì— ì €ì¥"""
        try:
            print(f"ğŸ’¾ {len(clusters)}ê°œ ì´ìŠˆë¥¼ issues í…Œì´ë¸”ì— ì €ì¥ ì¤‘...")
            
            issues_data = []
            for cluster in clusters:
                if not cluster.articles:  # ê¸°ì‚¬ê°€ ì—†ëŠ” í´ëŸ¬ìŠ¤í„°ëŠ” ê±´ë„ˆë›°ê¸°
                    continue
                
                # ì–¸ë¡ ì‚¬ ì„±í–¥ë³„ ê¸°ì‚¬ ìˆ˜ ê³„ì‚°
                bias_counts = self.count_media_bias(cluster)
                
                issue_data = {
                    "title": cluster.name,
                    "source": len(cluster.articles),
                    "left_source": bias_counts['left'],
                    "center_source": bias_counts['center'],
                    "right_source": bias_counts['right'],
                    "created_at": datetime.now().isoformat()
                }
                issues_data.append(issue_data)
            
            if not issues_data:
                print("âš ï¸ ì €ì¥í•  ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.")
                return True
            
            # issues í…Œì´ë¸”ì— ì €ì¥
            result = self.supabase_manager.client.table('issues').insert(issues_data).execute()
            
            if result.data:
                print(f"âœ… {len(result.data)}ê°œ ì´ìŠˆ ì €ì¥ ì™„ë£Œ")
                
                # issue_articles í…Œì´ë¸”ì— ì—°ê²° ì •ë³´ ì €ì¥
                self.save_issue_articles_connections(clusters, result.data)
                return True
            else:
                print("âŒ ì´ìŠˆ ì €ì¥ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            print(f"âŒ ì´ìŠˆ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def save_issue_articles_connections(self, clusters: List[Cluster], saved_issues: List[Dict]) -> bool:
        """issue_articles í…Œì´ë¸”ì— ì—°ê²° ì •ë³´ ì €ì¥"""
        try:
            print("ğŸ”— ì´ìŠˆ-ê¸°ì‚¬ ì—°ê²° ì •ë³´ ì €ì¥ ì¤‘...")
            
            connections = []
            for i, cluster in enumerate(clusters):
                if i >= len(saved_issues) or not cluster.articles:
                    continue
                
                issue_id = saved_issues[i]['id']
                for article in cluster.articles:
                    connection = {
                        "issue_id": issue_id,
                        "article_id": article.id
                    }
                    connections.append(connection)
            
            if connections:
                result = self.supabase_manager.client.table('issue_articles').insert(connections).execute()
                if result.data:
                    print(f"âœ… {len(result.data)}ê°œ ì—°ê²° ì •ë³´ ì €ì¥ ì™„ë£Œ")
                    return True
            
            print("âš ï¸ ì—°ê²° ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            print(f"âŒ ì—°ê²° ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def run_clustering(self, start_date: str, end_date: str) -> bool:
        """ë©”ì¸ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰"""
        try:
            print("ğŸš€ ì´ìŠˆ í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘")
            print("="*60)
            
            # 1. ê¸°ì‚¬ ì¡°íšŒ
            articles = self.fetch_articles_by_date_range(start_date, end_date)
            if not articles:
                return False
            
            # 2. 8ê°œ ë°°ì¹˜ë¡œ ë¶„í• 
            batches = self.split_into_8_batches(articles)
            print(f"ğŸ“¦ {len(articles)}ê°œ ê¸°ì‚¬ë¥¼ 8ê°œ ë°°ì¹˜ë¡œ ë¶„í• ")
            
            # 3. ê° ë°°ì¹˜ë³„ í´ëŸ¬ìŠ¤í„°ë§ (ìˆœì°¨ ì²˜ë¦¬)
            all_clusters = []
            for i, batch in enumerate(batches, 1):
                print(f"\nğŸ”„ ë°°ì¹˜ {i}/8 ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ ê¸°ì‚¬)")
                batch_clusters = self.cluster_with_llm(batch)
                if batch_clusters:
                    all_clusters.append(batch_clusters)
                    print(f"âœ… ë°°ì¹˜ {i} ì™„ë£Œ: {len(batch_clusters)}ê°œ í´ëŸ¬ìŠ¤í„°")
                else:
                    print(f"âŒ ë°°ì¹˜ {i} ì‹¤íŒ¨")
            
            if not all_clusters:
                print("âŒ ëª¨ë“  ë°°ì¹˜ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨")
                return False
            
            # 4. ë°°ì¹˜ ê²°ê³¼ í†µí•©
            print(f"\nğŸ”„ {len(all_clusters)}ê°œ ë°°ì¹˜ ê²°ê³¼ í†µí•© ì¤‘...")
            final_clusters = self.merge_batch_clusters(all_clusters)
            if not final_clusters:
                print("âŒ ë°°ì¹˜ í†µí•© ì‹¤íŒ¨")
                return False
            
            # 5. 20ê°œ ì´ìƒ í•„í„°ë§
            filtered_clusters = self.filter_clusters(final_clusters)
            if not filtered_clusters:
                print("âŒ 20ê°œ ì´ìƒ ê¸°ì‚¬ë¥¼ í¬í•¨í•œ í´ëŸ¬ìŠ¤í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # 6. ì´ìŠˆ ë²ˆí˜¸ í• ë‹¹
            numbered_clusters = self.assign_issue_numbers(filtered_clusters)
            
            # 7. ê²°ê³¼ ë¶„ì„
            print(f"\nğŸ“Š ìµœì¢… ê²°ê³¼:")
            for cluster in numbered_clusters:
                bias_counts = self.count_media_bias(cluster)
                print(f"  {cluster.name}: {len(cluster.articles)}ê°œ ê¸°ì‚¬ (ì¢Œ:{bias_counts['left']}, ì¤‘:{bias_counts['center']}, ìš°:{bias_counts['right']})")
            
            # 8. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
            save_success = self.save_to_issues_table(numbered_clusters)
            if not save_success:
                print("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨")
                return False
            
            print(f"\nâœ… í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ! {len(articles)}ê°œ ê¸°ì‚¬ â†’ {len(numbered_clusters)}ê°œ ì´ìŠˆ")
            return True
            
        except Exception as e:
            print(f"âŒ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨: {str(e)}")
            return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ§ª LLM ê¸°ë°˜ ì´ìŠˆ í´ëŸ¬ìŠ¤í„°ë§")
    print("="*60)
    
    try:
        # ë‚ ì§œ ë²”ìœ„ ì…ë ¥
        print("\nğŸ“… í´ëŸ¬ìŠ¤í„°ë§í•  ë‚ ì§œ ë²”ìœ„ë¥¼ ì„ íƒí•˜ì„¸ìš” (KST ê¸°ì¤€)")
        print("ì˜ˆ: 0910~0920, 0901~0930, 0915~0915")
        
        while True:
            date_input = input("\në‚ ì§œ ë²”ìœ„ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            if not date_input:
                print("âŒ ë‚ ì§œ ë²”ìœ„ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue
            
            try:
                clustering = IssueClustering()
                start_date, end_date = clustering.parse_date_range(date_input)
                break
            except ValueError as e:
                print(f"âŒ {e}")
                continue
        
        # í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰
        success = clustering.run_clustering(start_date, end_date)
        
        if success:
            print("\nğŸ‰ í´ëŸ¬ìŠ¤í„°ë§ ì„±ê³µ!")
        else:
            print("\nâŒ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨!")
            
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    main()
