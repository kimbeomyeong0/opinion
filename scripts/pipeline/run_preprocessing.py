#!/usr/bin/env python3
"""
ê³ ì† ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ v3
- ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì†ë„ ìµœì í™”
- ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›
- ì§„í–‰ë¥  í‘œì‹œ ê°œì„ 
"""

import sys
import os
import re
from datetime import datetime
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from utils.supabase_manager import SupabaseManager

# ì •ì¹˜ ì¹´í…Œê³ ë¦¬ ì •ì˜
POLITICAL_CATEGORIES = {
    "êµ­íšŒ/ì •ë‹¹": ["êµ­íšŒ", "ì˜ì›", "ì •ë‹¹", "ì—¬ë‹¹", "ì•¼ë‹¹", "êµ­ì •ê°ì‚¬", "ìƒì„ìœ„"],
    "í–‰ì •ë¶€": ["ì •ë¶€", "ëŒ€í†µë ¹", "ì´ë¦¬", "ë¶€ì²˜", "ì¥ê´€", "ì²­ì™€ëŒ€", "êµ­ë¬´íšŒì˜"],
    "ì„ ê±°": ["ì„ ê±°", "íˆ¬í‘œ", "í›„ë³´", "ë‹¹ì„ ", "ë“í‘œ", "ì„ ê±°êµ¬", "ê³µì²œ", "ì§€ë°©ì„ ê±°"],
    "ì‚¬ë²•/ê²€ì°°": ["ê²€ì°°", "ë²•ì›", "ì¬íŒ", "ê¸°ì†Œ", "ìˆ˜ì‚¬", "íŒê²°", "ê²€ì‚¬", "íŠ¹ê²€", "í—Œì¬", "íƒ„í•µ"],
    "ì •ì±…/ê²½ì œì‚¬íšŒ": ["ì •ì±…", "ì˜ˆì‚°", "ë²•ì•ˆ", "ê°œí˜", "ê²½ì œ", "ë³µì§€", "ë…¸ë™", "ì‚¬íšŒ"],
    "ì™¸êµ/ì•ˆë³´": ["ì™¸êµ", "ì•ˆë³´", "êµ­ë°©", "ë¶í•œ", "ë¯¸êµ­", "ì¤‘êµ­", "ì¼ë³¸", "í•œë¯¸", "í•œì¼", "êµ°ì‚¬"],
    "ì§€ì—­ì •ì¹˜": ["ì§€ì—­", "ì‹œë„", "ì‹œì¥", "ë„ì§€ì‚¬", "êµ¬ì²­ì¥", "ì§€ìì²´", "ì§€ë°©", "ë„ì˜íšŒ", "ê´‘ì—­ì˜íšŒ"],
    "ê¸°íƒ€": []  # ëª…ì‹œì ì¸ í‚¤ì›Œë“œê°€ ì—†ëŠ” ê²½ìš°
}

class FastPreprocessor:
    """ê³ ì† ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, batch_size: int = 100, max_workers: int = 4):
        """ì´ˆê¸°í™”"""
        self.supabase_manager = SupabaseManager()
        if not self.supabase_manager.client:
            raise Exception("Supabase ì—°ê²° ì‹¤íŒ¨")
        
        self.batch_size = batch_size
        self.max_workers = max_workers
    
    def clean_noise(self, text: str) -> str:
        """ê¸°ë³¸ ë…¸ì´ì¦ˆ ì œê±° (ìµœì í™”ëœ ë²„ì „)"""
        if not text:
            return ""
        
        # ì •ê·œì‹ íŒ¨í„´ì„ ë¯¸ë¦¬ ì»´íŒŒì¼í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ
        patterns = [
            (r'\([^)]*\)', ''),  # ì–¸ë¡ ì‚¬ ì •ë³´
            (r'[ê°€-í£]{2,4}\s*ê¸°ì\s*=', ''),  # ê¸°ìëª…
            (r'\[[^\]]*\]', ''),  # ì‹œë¦¬ì¦ˆ í‘œì‹œ
            (r'[â—‡ã€ã€‘â€¦]', ''),  # íŠ¹ìˆ˜ ê¸°í˜¸
            (r'<[^>]*>', ''),  # HTML íƒœê·¸
            (r'&[a-zA-Z0-9#]+;', ''),  # HTML ì—”í‹°í‹°
            (r'\s+', ' ')  # ê³µë°± ì •ë¦¬
        ]
        
        for pattern, replacement in patterns:
            text = re.sub(pattern, replacement, text)
        
        return text.strip()
    
    def clean_title_noise(self, title: str) -> str:
        """ì œëª© ì „ìš© ë…¸ì´ì¦ˆ ì œê±° (ìµœì í™”ëœ ë²„ì „)"""
        if not title:
            return ""
        
        # ê¸°ë³¸ ë…¸ì´ì¦ˆ ì œê±°
        cleaned = self.clean_noise(title)
        
        # ì œëª© íŠ¹í™” íŒ¨í„´ì„ í•˜ë‚˜ì˜ ì •ê·œì‹ìœ¼ë¡œ í†µí•©
        title_patterns = [
            (r'\[(ì†ë³´|ë‹¨ë…|ê¸°íš|íŠ¹ì§‘|ì¸í„°ë·°|ë¶„ì„|í•´ì„¤|ë…¼í‰|ì‚¬ì„¤|ì¹¼ëŸ¼|ê¸°ê³ |ì˜¤í”¼ë‹ˆì–¸|í¬í† |ì˜ìƒ|ë™ì˜ìƒ|ì¸í¬ê·¸ë˜í”½)\]', ''),
            (r'^[ê°€-í£]{1,2}\s*(ê¸°ì|íŠ¹íŒŒì›)\s*[:=]?', ''),
            (r'[â—†â—‡â–²â–³â—â—‹â– â–¡â˜…â˜†â–¶â—€â—â–·â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]+', ''),
            (r'^\[.*?\]', ''),  # ë§¨ ì•ì˜ [ë‚´ìš©] ì œê±°
            (r'^\(.*?\)', ''),  # ë§¨ ì•ì˜ (ë‚´ìš©) ì œê±°
            (r'^<.*?>', ''),    # ë§¨ ì•ì˜ <ë‚´ìš©> ì œê±°
            (r'\s+', ' ')
        ]
        
        for pattern, replacement in title_patterns:
            cleaned = re.sub(pattern, replacement, cleaned)
        
        return cleaned.strip()
    
    def extract_lead_paragraph(self, content: str) -> str:
        """ê¸°ì‚¬ ë³¸ë¬¸ì—ì„œ ì²« ë¬¸ë‹¨(ë¦¬ë“œë¬¸ë‹¨) ì¶”ì¶œ"""
        if not content:
            return ""
        
        # ì²« ë¬¸ë‹¨ì€ ë³´í†µ ë‘ ê°œì˜ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„ë¨
        paragraphs = content.split('\n\n')
        if paragraphs:
            lead_paragraph = paragraphs[0].strip()
            # ë„ˆë¬´ ê¸´ ê²½ìš° ì²« 3ë¬¸ì¥ìœ¼ë¡œ ì œí•œ
            sentences = lead_paragraph.split('.')
            if len(sentences) > 3:
                lead_paragraph = '. '.join(sentences[:3]) + '.'
            return lead_paragraph
        
        # ë¬¸ë‹¨ êµ¬ë¶„ì´ ì—†ëŠ” ê²½ìš° ì²« 200ìë¡œ ì œí•œ
        return content.strip()[:200]
    
    def classify_by_keywords(self, title: str, lead_paragraph: str) -> str:
        """ê³ ì† ê°€ì¤‘ì¹˜ ê¸°ë°˜ í‚¤ì›Œë“œ ë¶„ë¥˜ (ìµœì í™”ë¨)"""
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (í•œ ë²ˆë§Œ)
        title_lower = title.lower()
        lead_lower = lead_paragraph.lower()
        
        # ê°€ì¤‘ì¹˜ ì„¤ì •
        title_weight = 2.0
        content_weight = 1.0
        
        category_scores = {}
        max_score = 0
        best_category = "uncertain"
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ê³„ì‚° (ìµœì í™”ëœ ë£¨í”„)
        for category, keywords in POLITICAL_CATEGORIES.items():
            if not keywords:  # "ê¸°íƒ€" ì¹´í…Œê³ ë¦¬ ìŠ¤í‚µ
                continue
                
            score = 0
            
            # í‚¤ì›Œë“œ ê²€ìƒ‰ì„ í•œ ë²ˆì— ì²˜ë¦¬
            for keyword in keywords:
                if keyword in title_lower:
                    score += title_weight
                if keyword in lead_lower:
                    score += content_weight
            
            category_scores[category] = score
            
            # ìµœê³  ì ìˆ˜ ì¶”ì  (ë³„ë„ max() í˜¸ì¶œ ë°©ì§€)
            if score > max_score:
                max_score = score
                best_category = category
        
        # ì„ê³„ê°’ ì´ìƒì´ë©´ ë¶„ë¥˜ ê²°ê³¼ ë°˜í™˜
        if max_score >= 3.0:
            return best_category
        else:
            return "uncertain"  # LLMìœ¼ë¡œ ë¶„ë¥˜ í•„ìš”
    
    def classify_by_llm(self, title: str, lead_paragraph: str) -> str:
        """OpenAI GPT-4 minië¡œ ì •í™•í•œ ë¶„ë¥˜ (ìƒˆë¡œìš´ API ë°©ì‹)"""
        try:
            from openai import OpenAI
            
            client = OpenAI()
            
            prompt = f"""
ë‹¤ìŒ ì •ì¹˜ ë‰´ìŠ¤ë¥¼ 7ê°œ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:

1. êµ­íšŒ/ì •ë‹¹ - êµ­íšŒì˜ì›, ì •ë‹¹ í™œë™, ì˜ì • í™œë™
2. í–‰ì •ë¶€ - ì •ë¶€, ëŒ€í†µë ¹, ì´ë¦¬, ì •ë¶€ê¸°ê´€
3. ì„ ê±° - ì„ ê±°, íˆ¬í‘œ, í›„ë³´, ê³µì²œ
4. ì‚¬ë²•/ê²€ì°° - ê²€ì°°, ë²•ì›, ì¬íŒ, ìˆ˜ì‚¬
5. ì •ì±…/ê²½ì œì‚¬íšŒ - ì •ì±…, ì‚¬íšŒ ë¬¸ì œ, ê²½ì œ
6. ì™¸êµ/ì•ˆë³´ - ì™¸êµ, ì•ˆë³´, êµ­ë°©
7. ì§€ì—­ì •ì¹˜ - ì§€ë°©ìì¹˜, ì§€ì—­ ì •ì¹˜
8. ê¸°íƒ€ - ìœ„ ì¹´í…Œê³ ë¦¬ì— í¬í•¨ë˜ì§€ ì•ŠëŠ” ê²½ìš°

ì œëª©: {title}
ë¦¬ë“œë¬¸ë‹¨: {lead_paragraph}

ì¹´í…Œê³ ë¦¬ ë²ˆí˜¸(1-8)ë§Œ ë‹µë³€:
"""
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=10,
                temperature=0.1
            )
            
            category_map = {
                "1": "êµ­íšŒ/ì •ë‹¹",
                "2": "í–‰ì •ë¶€", 
                "3": "ì„ ê±°",
                "4": "ì‚¬ë²•/ê²€ì°°",
                "5": "ì •ì±…/ê²½ì œì‚¬íšŒ",
                "6": "ì™¸êµ/ì•ˆë³´",
                "7": "ì§€ì—­ì •ì¹˜",
                "8": "ê¸°íƒ€"
            }
            
            result = response.choices[0].message.content.strip()
            return category_map.get(result, "ê¸°íƒ€")
            
        except Exception as e:
            print(f"âŒ LLM ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}")
            return "ê¸°íƒ€"  # LLM ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
    
    def classify_political_category(self, title: str, lead_paragraph: str) -> str:
        """í•˜ì´ë¸Œë¦¬ë“œ ì •ì¹˜ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        
        # 1ë‹¨ê³„: í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ë¶„ë¥˜
        keyword_category = self.classify_by_keywords(title, lead_paragraph)
        
        # 2ë‹¨ê³„: ë¶ˆí™•ì‹¤í•œ ê²½ìš°ì—ë§Œ LLM ì‚¬ìš©
        if keyword_category == "uncertain":
            llm_category = self.classify_by_llm(title, lead_paragraph)
            return llm_category
        
        return keyword_category
    
    def preprocess_article(self, article: Dict[str, Any]) -> tuple:
        """ê¸°ì‚¬ ì „ì²˜ë¦¬ (í•˜ì´ë¸Œë¦¬ë“œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ í¬í•¨)"""
        try:
            title = article.get('title', '')
            content = article.get('content', '')
            
            if not content:
                return None, None, None, None, "ë³¸ë¬¸ ì—†ìŒ"
            
            # ì œëª© ì „ì²˜ë¦¬
            cleaned_title = self.clean_title_noise(title) if title else ""
            
            # ë³¸ë¬¸ ì „ì²˜ë¦¬
            cleaned_content = self.clean_noise(content)
            
            # ë¦¬ë“œë¬¸ë‹¨ ì¶”ì¶œ
            lead_paragraph = self.extract_lead_paragraph(cleaned_content)
            
            # í•˜ì´ë¸Œë¦¬ë“œ ì •ì¹˜ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
            political_category = self.classify_political_category(cleaned_title, lead_paragraph)
            
            return cleaned_title, cleaned_content, lead_paragraph, political_category, None
            
        except Exception as e:
            return None, None, None, None, f"ì˜ˆì™¸ ë°œìƒ: {str(e)}"
    
    def fetch_unprocessed_articles_batch(self, offset: int, limit: int) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ë¡œ ì „ì²˜ë¦¬ë˜ì§€ ì•Šì€ ê¸°ì‚¬ ì¡°íšŒ"""
        try:
            result = self.supabase_manager.client.table('articles').select(
                'id, title, content, media_id, published_at, is_preprocessed'
            ).eq('is_preprocessed', False).range(offset, offset + limit - 1).execute()
            
            print(f"  ğŸ” ì¡°íšŒëœ ê¸°ì‚¬ ìˆ˜: {len(result.data) if result.data else 0}ê°œ (offset: {offset}, limit: {limit})")
            return result.data if result.data else []
            
        except Exception as e:
            print(f"âŒ ê¸°ì‚¬ ì¡°íšŒ ì‹¤íŒ¨ (offset: {offset}): {str(e)}")
            return []
    
    def fetch_all_unprocessed_articles(self, limit: int) -> List[Dict[str, Any]]:
        """ì „ì²˜ë¦¬ë˜ì§€ ì•Šì€ ëª¨ë“  ê¸°ì‚¬ë¥¼ í•œ ë²ˆì— ì¡°íšŒ"""
        try:
            result = self.supabase_manager.client.table('articles').select(
                'id, title, content, media_id, published_at, is_preprocessed'
            ).eq('is_preprocessed', False).limit(limit).execute()
            
            return result.data if result.data else []
            
        except Exception as e:
            print(f"âŒ ì „ì²´ ê¸°ì‚¬ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def update_articles_batch(self, updates: List[Dict[str, Any]]) -> int:
        """ë°°ì¹˜ë¡œ ê¸°ì‚¬ ì—…ë°ì´íŠ¸"""
        if not updates:
            return 0
        
        try:
            # SupabaseëŠ” ë°°ì¹˜ ì—…ë°ì´íŠ¸ë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ê°œë³„ ì—…ë°ì´íŠ¸
            success_count = 0
            for update in updates:
                try:
                    result = self.supabase_manager.client.table('articles').update({
                        'title': update['title'],
                        'content': update['content'],
                        'lead_paragraph': update['lead_paragraph'],
                        'political_category': update['political_category'],  # ìƒˆë¡œ ì¶”ê°€
                        'is_preprocessed': True,
                        'preprocessed_at': update['preprocessed_at']
                    }).eq('id', update['id']).execute()
                    
                    if result.data:
                        success_count += 1
                except Exception as e:
                    print(f"âŒ ê¸°ì‚¬ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {update['id']} - {str(e)}")
            
            return success_count
            
        except Exception as e:
            print(f"âŒ ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
            return 0
    
    def process_batch(self, articles: List[Dict[str, Any]]) -> tuple:
        """ë°°ì¹˜ ì²˜ë¦¬ (í•˜ì´ë¸Œë¦¬ë“œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ í¬í•¨)"""
        processed_updates = []
        failed_count = 0
        
        for article in articles:
            cleaned_title, cleaned_content, lead_paragraph, political_category, failure_reason = self.preprocess_article(article)
            
            if cleaned_title is not None and cleaned_content is not None and lead_paragraph is not None:
                processed_updates.append({
                    'id': article['id'],
                    'title': cleaned_title,
                    'content': cleaned_content,
                    'lead_paragraph': lead_paragraph,
                    'political_category': political_category,  # ìƒˆë¡œ ì¶”ê°€
                    'preprocessed_at': datetime.now().isoformat()
                })
            else:
                failed_count += 1
                if failure_reason:
                    print(f"âŒ ê¸°ì‚¬ ì²˜ë¦¬ ì‹¤íŒ¨: {article.get('id', 'Unknown')} - {failure_reason}")
        
        return processed_updates, failed_count
    
    def get_total_unprocessed_count(self) -> int:
        """ì „ì²˜ë¦¬ë˜ì§€ ì•Šì€ ê¸°ì‚¬ ì´ ê°œìˆ˜ ì¡°íšŒ"""
        try:
            result = self.supabase_manager.client.table('articles').select('*', count='exact').eq('is_preprocessed', False).execute()
            return result.count if hasattr(result, 'count') else 0
        except Exception as e:
            print(f"âŒ ì´ ê°œìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return 0
    
    def process_articles_fast(self, max_articles: Optional[int] = None) -> bool:
        """ê³ ì† ê¸°ì‚¬ ì „ì²˜ë¦¬ ë©”ì¸ í”„ë¡œì„¸ìŠ¤ (í˜ì´ì§€ë„¤ì´ì…˜ ì§€ì›)"""
        try:
            # ì´ ê°œìˆ˜ ì¡°íšŒ
            total_unprocessed = self.get_total_unprocessed_count()
            if total_unprocessed == 0:
                print("ğŸ“ ì²˜ë¦¬í•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return True
            
            # ì²˜ë¦¬í•  ê°œìˆ˜ ê²°ì •
            process_count = min(max_articles or total_unprocessed, total_unprocessed)
            print(f"ğŸš€ ê³ ì† ì „ì²˜ë¦¬ ì‹œì‘... (ì²˜ë¦¬ ì˜ˆì •: {process_count:,}ê°œ)")
            
            total_processed = 0
            total_failed = 0
            batch_count = 0
            start_time = time.time()
            offset = 0
            
            # í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ ëª¨ë“  ê¸°ì‚¬ ì²˜ë¦¬
            while offset < process_count:
                # í˜„ì¬ ë°°ì¹˜ì˜ ê¸°ì‚¬ ìˆ˜ ê³„ì‚°
                current_batch_size = min(self.batch_size, process_count - offset)
                
                # ë°°ì¹˜ë¡œ ê¸°ì‚¬ ì¡°íšŒ
                batch_articles = self.fetch_unprocessed_articles_batch(offset, current_batch_size)
                if not batch_articles:
                    print("ğŸ“ ë” ì´ìƒ ì²˜ë¦¬í•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    break
                
                    batch_count += 1
                    # ë°°ì¹˜ ì‹œì‘ ë©”ì‹œì§€ëŠ” ì²« ë²ˆì§¸ë§Œ í‘œì‹œ
                    if batch_count == 1:
                        print(f"ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘... (ì´ {process_count:,}ê°œ ê¸°ì‚¬)")
                
                # ë°°ì¹˜ ì²˜ë¦¬
                processed_updates, failed_count = self.process_batch(batch_articles)
                total_failed += failed_count
                
                # ë°°ì¹˜ ì—…ë°ì´íŠ¸
                if processed_updates:
                    success_count = self.update_articles_batch(processed_updates)
                    total_processed += success_count
                
                    # ì§„í–‰ë¥  í‘œì‹œ (í•œ ì¤„ë¡œ ê¹”ë”í•˜ê²Œ)
                    elapsed_time = time.time() - start_time
                    progress = min(100, (offset + len(batch_articles)) / process_count * 100)
                    rate = total_processed / elapsed_time if elapsed_time > 0 else 0
                    eta = (process_count - total_processed) / rate if rate > 0 else 0
                    
                    print(f"\rğŸš€ ì§„í–‰ë¥ : {progress:.1f}% | ì„±ê³µ: {total_processed:,}ê°œ | ì‹¤íŒ¨: {total_failed:,}ê°œ | ì†ë„: {rate:.1f}ê°œ/ì´ˆ | ë‚¨ì€ì‹œê°„: {eta/60:.1f}ë¶„", end="", flush=True)
                
                # ë‹¤ìŒ ë°°ì¹˜ë¡œ ì´ë™
                offset += len(batch_articles)
                
                # ë°°ì¹˜ ê°„ ì§§ì€ ëŒ€ê¸° (API ì œí•œ ë°©ì§€)
                time.sleep(0.1)
            
                # ìµœì¢… ê²°ê³¼ (í•œ ì¤„ë¡œ ê¹”ë”í•˜ê²Œ)
                total_time = time.time() - start_time
                print(f"\rğŸ‰ ì „ì²˜ë¦¬ ì™„ë£Œ! âœ… ì„±ê³µ: {total_processed:,}ê°œ | âŒ ì‹¤íŒ¨: {total_failed:,}ê°œ | â±ï¸ ì†Œìš”ì‹œê°„: {total_time/60:.1f}ë¶„ | ğŸ“ˆ ì†ë„: {total_processed/total_time:.1f}ê°œ/ì´ˆ")
            
            return total_processed > 0
                
        except Exception as e:
            print(f"âŒ ì „ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {str(e)}")
            return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ“° ê³ ì† ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ v3")
    print("=" * 60)
    
    try:
        # ë°°ì¹˜ í¬ê¸° ì„¤ì •
        batch_size = 100  # í•œ ë²ˆì— ì²˜ë¦¬í•  ê¸°ì‚¬ ìˆ˜ (ìµœì í™”ë¨)
        max_workers = 4  # ë³‘ë ¬ ì²˜ë¦¬ ìŠ¤ë ˆë“œ ìˆ˜
        
        print(f"âš™ï¸  ì„¤ì •: ë°°ì¹˜ í¬ê¸° {batch_size}ê°œ, ìµœëŒ€ ì›Œì»¤ {max_workers}ê°œ")
        
        # is_preprocessed = Falseì¸ ëª¨ë“  ê¸°ì‚¬ ì²˜ë¦¬
        max_articles = None  # ì „ì²´ ì²˜ë¦¬
        
        # ì „ì²˜ë¦¬ ì‹¤í–‰
        preprocessor = FastPreprocessor(batch_size=batch_size, max_workers=max_workers)
        success = preprocessor.process_articles_fast(max_articles)
        
        if success:
            print(f"\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
        else:
            print(f"\nâŒ ì „ì²˜ë¦¬ ì‹¤íŒ¨!")
            
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    main()
