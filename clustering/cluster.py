#!/usr/bin/env python3
"""
ì •ì¹˜ ë‰´ìŠ¤ í´ëŸ¬ìŠ¤í„°ë§ ìŠ¤í¬ë¦½íŠ¸
- UMAP + HDBSCANì„ ì‚¬ìš©í•œ í´ëŸ¬ìŠ¤í„°ë§
- LLMì„ í†µí•œ ì´ìŠˆ ì œëª©/ìš”ì•½ ìƒì„±
- ì •ì¹˜ ì„±í–¥ ë¶„ì„
- ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import pandas as pd
import umap
import hdbscan
from datetime import datetime
from rich.console import Console
from rich.progress import Progress, TextColumn, BarColumn, TimeElapsedColumn
from rich.panel import Panel
from openai import OpenAI
import asyncio
import aiohttp
from concurrent.futures import ThreadPoolExecutor

from utils.supabase_manager import get_supabase_client

console = Console()

class PoliticalNewsClusterer:
    """ì •ì¹˜ ë‰´ìŠ¤ í´ëŸ¬ìŠ¤í„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.supabase = get_supabase_client()
        self.openai_client = OpenAI()
        
        # ë°ì´í„° ì €ì¥ì†Œ
        self.embeddings_data = None
        self.articles_data = None
        self.media_outlets = None
        self.embeddings = None
        self.umap_embedding = None
        self.cluster_labels = None
        self.clusters_info = None
        
        # ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬ ë§¤í•‘
        self.id_to_article = None
        self.id_to_media = None
        
        console.print("âœ… Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        console.print("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (gpt-4o-mini)")
        
    def load_embeddings_with_pagination(self) -> bool:
        """ì„ë² ë”© ë°ì´í„°ë¥¼ í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ ë¡œë“œ"""
        try:
            console.print("ğŸ“Š ì„ë² ë”© ë°ì´í„° ë¡œë“œ ì¤‘...")
            
            all_embeddings = []
            offset = 0
            batch_size = 100
            
            with Progress(
                TextColumn("[progress.description]{task.description}"),
                BarColumn(),
                TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
                TimeElapsedColumn(),
                console=console
            ) as progress:
                
                task = progress.add_task("ì„ë² ë”© ë°ì´í„° ë¡œë“œ ì¤‘...", total=None)
                
                while True:
                    result = self.supabase.client.table('articles_embeddings').select(
                        'cleaned_article_id, embedding_vector, model_name'
                    ).eq('embedding_type', 'combined').range(offset, offset + batch_size - 1).execute()
                    
                    if not result.data:
                        break
                    
                    all_embeddings.extend(result.data)
                    progress.update(task, description=f"ì„ë² ë”© ë°ì´í„° ë¡œë“œ ì¤‘... ({len(all_embeddings)}ê°œ)")
                    
                    if len(result.data) < batch_size:
                        break
                    
                    offset += batch_size
            
            if not all_embeddings:
                console.print("âŒ ì„ë² ë”© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # DataFrameìœ¼ë¡œ ë³€í™˜
            self.embeddings_data = pd.DataFrame(all_embeddings)
            
            # ì„ë² ë”© ë²¡í„° ì¶”ì¶œ
            self.embeddings = np.array([eval(emb) for emb in self.embeddings_data['embedding_vector']])
            
            console.print(f"âœ… ì„ë² ë”© ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(all_embeddings)}ê°œ")
            console.print(f"   - ì„ë² ë”© ì°¨ì›: {self.embeddings.shape[1]}")
            
            return True
            
        except Exception as e:
            console.print(f"âŒ ì„ë² ë”© ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def load_articles_data(self) -> bool:
        """ê¸°ì‚¬ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        try:
            console.print("ğŸ“° ê¸°ì‚¬ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì¤‘...")
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¡°íšŒ
            embedding_ids = self.embeddings_data['cleaned_article_id'].tolist()
            
            # ë°°ì¹˜ í¬ê¸°ë¥¼ ì‘ê²Œ ì„¤ì •í•˜ì—¬ URL ê¸¸ì´ ì œí•œ íšŒí”¼
            batch_size = 100
            all_articles = []
            
            for i in range(0, len(embedding_ids), batch_size):
                batch_ids = embedding_ids[i:i + batch_size]
                
                result = self.supabase.client.table('articles_cleaned').select(
                    'id, article_id, merged_content'
                ).in_('id', batch_ids).execute()
                
                if result.data:
                    all_articles.extend(result.data)
            
            if not all_articles:
                console.print("âŒ ê¸°ì‚¬ ë©”íƒ€ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            self.articles_data = pd.DataFrame(all_articles)
            console.print(f"âœ… ê¸°ì‚¬ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(all_articles)}ê°œ")
            
            return True
            
        except Exception as e:
            console.print(f"âŒ ê¸°ì‚¬ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def load_media_outlets(self) -> bool:
        """ì–¸ë¡ ì‚¬ ì •ë³´ ë¡œë“œ"""
        try:
            console.print("ğŸ“º ì–¸ë¡ ì‚¬ ì •ë³´ ë¡œë“œ ì¤‘...")
            
            result = self.supabase.client.table('media_outlets').select('id, name, bias').execute()
            
            if not result.data:
                console.print("âŒ ì–¸ë¡ ì‚¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            self.media_outlets = pd.DataFrame(result.data)
            console.print(f"âœ… ì–¸ë¡ ì‚¬ ì •ë³´ ë¡œë“œ ì™„ë£Œ: {len(result.data)}ê°œ")
            
            return True
            
        except Exception as e:
            console.print(f"âŒ ì–¸ë¡ ì‚¬ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def create_performance_mappings(self) -> bool:
        """ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬ ë§¤í•‘ ìƒì„±"""
        try:
            console.print("âš¡ ì„±ëŠ¥ ìµœì í™” ë§¤í•‘ ìƒì„± ì¤‘...")
            
            # 1. embedding_id -> article_id ë§¤í•‘
            self.id_to_article = self.articles_data.set_index('id')['article_id'].to_dict()
            
            # 2. article_id -> media_id ë§¤í•‘ (ì‚¬ì „ ë¡œë“œ) - ë°°ì¹˜ ì²˜ë¦¬ë¡œ URL ê¸¸ì´ ì œí•œ íšŒí”¼
            article_ids = list(self.id_to_article.values())
            batch_size = 100  # URL ê¸¸ì´ ì œí•œ íšŒí”¼
            media_results_data = []
            
            for i in range(0, len(article_ids), batch_size):
                batch_ids = article_ids[i:i + batch_size]
                media_results = self.supabase.client.table('articles').select(
                    'id, media_id'
                ).in_('id', batch_ids).execute()
                
                if media_results.data:
                    media_results_data.extend(media_results.data)
            
            media_results = type('obj', (object,), {'data': media_results_data})()
            
            if media_results.data:
                self.id_to_media = {row['id']: row['media_id'] for row in media_results.data}
            else:
                self.id_to_media = {}
            
            console.print(f"âœ… ì„±ëŠ¥ ìµœì í™” ë§¤í•‘ ì™„ë£Œ:")
            console.print(f"   - embedding_id -> article_id: {len(self.id_to_article)}ê°œ")
            console.print(f"   - article_id -> media_id: {len(self.id_to_media)}ê°œ")
            
            return True
            
        except Exception as e:
            console.print(f"âŒ ì„±ëŠ¥ ìµœì í™” ë§¤í•‘ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def optimize_clustering_parameters(self) -> tuple:
        """í´ëŸ¬ìŠ¤í„°ë§ íŒŒë¼ë¯¸í„° ìµœì í™”"""
        n_samples = len(self.embeddings)
        
        # UMAP íŒŒë¼ë¯¸í„° ì¡°ì •
        if n_samples < 100:
            n_neighbors = min(5, n_samples - 1)
            min_dist = 0.1
        elif n_samples < 500:
            n_neighbors = min(10, n_samples // 10)
            min_dist = 0.2
        elif n_samples < 1000:
            n_neighbors = 25
            min_dist = 0.1
        else:
            n_neighbors = 30
            min_dist = 0.1
        
        # HDBSCAN íŒŒë¼ë¯¸í„° ì¡°ì •
        min_cluster_size = max(3, n_samples // 200)  # ì „ì²´ì˜ 0.5%
        min_samples = max(2, min_cluster_size // 2)
        
        return (n_neighbors, min_dist, min_cluster_size, min_samples)
    
    def run_umap_reduction(self) -> bool:
        """UMAP ì°¨ì› ì¶•ì†Œ"""
        try:
            console.print("ğŸ”„ UMAP ì°¨ì› ì¶•ì†Œ ì‹¤í–‰ ì¤‘...")
            
            n_neighbors, min_dist, _, _ = self.optimize_clustering_parameters()
            
            reducer = umap.UMAP(
                n_components=2,
                n_neighbors=n_neighbors,
                min_dist=min_dist,
                random_state=42,
                verbose=True,
                n_jobs=-1
            )
            
            self.umap_embedding = reducer.fit_transform(self.embeddings)
            
            console.print(f"âœ… UMAP ì™„ë£Œ: {self.embeddings.shape[1]}D â†’ 2D")
            console.print(f"   - íŒŒë¼ë¯¸í„°: n_neighbors={n_neighbors}, min_dist={min_dist}")
            
            return True
            
        except Exception as e:
            console.print(f"âŒ UMAP ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return False
    
    def run_hdbscan_clustering(self) -> bool:
        """HDBSCAN í´ëŸ¬ìŠ¤í„°ë§"""
        try:
            console.print("ğŸ”„ HDBSCAN í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰ ì¤‘...")
            
            _, _, min_cluster_size, min_samples = self.optimize_clustering_parameters()
            
            clusterer = hdbscan.HDBSCAN(
                min_cluster_size=min_cluster_size,
                min_samples=min_samples,
                metric='euclidean',
                cluster_selection_epsilon=0.1
            )
            
            self.cluster_labels = clusterer.fit_predict(self.umap_embedding)
            
            # í´ëŸ¬ìŠ¤í„° í†µê³„
            unique_labels = np.unique(self.cluster_labels)
            n_clusters = len(unique_labels) - (1 if -1 in unique_labels else 0)
            n_noise = np.sum(self.cluster_labels == -1)
            
            console.print(f"âœ… HDBSCAN ì™„ë£Œ:")
            console.print(f"   - í´ëŸ¬ìŠ¤í„° ìˆ˜: {n_clusters}ê°œ")
            console.print(f"   - ë…¸ì´ì¦ˆ ê¸°ì‚¬: {n_noise}ê°œ")
            console.print(f"   - íŒŒë¼ë¯¸í„°: min_cluster_size={min_cluster_size}, min_samples={min_samples}")
            
            return True
            
        except Exception as e:
            console.print(f"âŒ HDBSCAN ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return False
    
    def analyze_clusters(self) -> bool:
        """í´ëŸ¬ìŠ¤í„° ë¶„ì„"""
        try:
            console.print("ğŸ” í´ëŸ¬ìŠ¤í„° ë¶„ì„ ì¤‘...")
            
            # í´ëŸ¬ìŠ¤í„°ë³„ ê¸°ì‚¬ ê·¸ë£¹í™”
            clusters_info = []
            
            for cluster_id in np.unique(self.cluster_labels):
                if cluster_id == -1:  # ë…¸ì´ì¦ˆ ì œì™¸
                    continue
                
                cluster_mask = self.cluster_labels == cluster_id
                cluster_embedding_ids = self.embeddings_data[cluster_mask]['cleaned_article_id'].tolist()
                
                clusters_info.append({
                    'cluster_id': cluster_id,
                    'size': len(cluster_embedding_ids),
                    'embedding_ids': cluster_embedding_ids
                })
            
            # í¬ê¸°ìˆœ ì •ë ¬
            clusters_info.sort(key=lambda x: x['size'], reverse=True)
            self.clusters_info = clusters_info
            
            # ê²°ê³¼ í‘œì‹œ
            from rich.table import Table
            table = Table(title="í´ëŸ¬ìŠ¤í„° ë¶„ì„ ê²°ê³¼")
            table.add_column("í´ëŸ¬ìŠ¤í„° ID", style="cyan")
            table.add_column("í¬ê¸°", style="magenta")
            table.add_column("ë¹„ìœ¨", style="green")
            
            total_articles = sum(cluster['size'] for cluster in clusters_info)
            
            for cluster in clusters_info[:20]:  # ìƒìœ„ 20ê°œë§Œ í‘œì‹œ
                percentage = (cluster['size'] / total_articles) * 100
                table.add_row(
                    str(cluster['cluster_id']),
                    str(cluster['size']),
                    f"{percentage:.1f}%"
                )
            
            console.print(table)
            console.print(f"âœ… ë¶„ì„ ì™„ë£Œ: {len(clusters_info)}ê°œ í´ëŸ¬ìŠ¤í„°")
            
            return True
            
        except Exception as e:
            console.print(f"âŒ í´ëŸ¬ìŠ¤í„° ë¶„ì„ ì‹¤íŒ¨: {e}")
            return False
    
    def generate_issue_content_with_llm(self, cluster_info: dict) -> dict:
        """LLMìœ¼ë¡œ ì´ìŠˆ ë‚´ìš© ìƒì„±"""
        try:
            console.print(f"ğŸ¤– í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']} LLM ë‚´ìš© ìƒì„± ì¤‘...")
            
            # í´ëŸ¬ìŠ¤í„°ì˜ ê¸°ì‚¬ ë‚´ìš© ìˆ˜ì§‘ (ì›ë³¸ articles í…Œì´ë¸”ì—ì„œ) - ìµœì í™”ëœ ë°°ì¹˜ ì¿¼ë¦¬
            article_contents = []
            
            # 1ë‹¨ê³„: embedding_idì—ì„œ article_idë¡œ ë§¤í•‘ (ìµœì í™”ëœ ë”•ì…”ë„ˆë¦¬ ì¡°íšŒ)
            embedding_ids = cluster_info['embedding_ids'][:5]  # ìµœëŒ€ 5ê°œ ê¸°ì‚¬
            article_ids = []
            
            for embedding_id in embedding_ids:
                article_id = self.id_to_article.get(embedding_id)
                if article_id:
                    article_ids.append(article_id)
            
            # 2ë‹¨ê³„: ì›ë³¸ articles í…Œì´ë¸”ì—ì„œ ë°°ì¹˜ë¡œ ì „ì²´ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° (ë‹¨ì¼ ì¿¼ë¦¬!)
            if article_ids:
                original_articles = self.supabase.client.table('articles').select(
                    'id, title, content'
                ).in_('id', article_ids).execute()
                
                if original_articles.data:
                    # 3ë‹¨ê³„: ê²°ê³¼ ì²˜ë¦¬
                    for article_info in original_articles.data:
                        full_content = f"ì œëª©: {article_info['title']}\në‚´ìš©: {article_info['content']}"
                        if len(full_content.strip()) > 50:
                            article_contents.append(full_content[:1000])  # 1000ìë¡œ í™•ì¥
            
            if not article_contents:
                return {
                    'title': f"í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']}",
                    'subtitle': f"{cluster_info['size']}ê°œ ê¸°ì‚¬",
                    'summary': "ë‚´ìš© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                }
            
            # ì „ë¬¸ì ì´ê³  ì„¸ë ¨ëœ ê¸°ì‚¬ ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸
            prompt = f"""
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì£¼ìš” ì–¸ë¡ ì‚¬ì˜ ë² í…Œë‘ ê¸°ìì…ë‹ˆë‹¤. ì•„ë˜ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ì „ë¬¸ì ì´ê³  ì„¸ë ¨ëœ ê¸°ì‚¬ ìŠ¤íƒ€ì¼ë¡œ ì œëª©, ë¶€ì œëª©, ìš”ì•½ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

## ì œëª© ê°œì„  ê°€ì´ë“œë¼ì¸
âŒ í”¼í•´ì•¼ í•  í‘œí˜„:
- ê³¼ë„í•œ ê°íƒ„ë¶€í˜¸ (!, ?)
- "ê¸‰ê¸°ì•¼", "ê²°êµ­", "ë¬´ë ¤" ë“± ì„ ì •ì  ìˆ˜ì‹ì–´ ë‚¨ë°œ
- "í­ì¦", "í­ë°œ" ë“± ê³¼ì¥ëœ í‘œí˜„

âœ… ì§€í–¥í•´ì•¼ í•  í‘œí˜„:
- ê°„ê²°í•˜ê³  ì •í™•í•œ íŒ©íŠ¸ ì¤‘ì‹¬
- êµ¬ì²´ì  ìˆ˜ì¹˜ë‚˜ ê¸°ê´€ëª… í™œìš©
- ì¤‘ë¦½ì ì´ë©´ì„œë„ ì„íŒ©íŠ¸ ìˆëŠ” í‘œí˜„
- 12-15ì ë‚´ì™¸ ê¶Œì¥

## ë¶€ì œëª© ê°€ì´ë“œë¼ì¸
- ì œëª©ì—ì„œ ë‹¤ë£¨ì§€ ëª»í•œ í•µì‹¬ ì •ë³´ ë³´ì™„
- êµ¬ì²´ì  ë°°ê²½ì´ë‚˜ ì¶”ê°€ ìŸì  ì œì‹œ
- 20ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ

## ìš”ì•½ë¬¸ ê°œì„  ê°€ì´ë“œë¼ì¸
âŒ ê°œì„  í•„ìš”í•œ ë¶€ë¶„:
- "ë¬´ë ¤", "ê¸°ìŠ¹ì„ ë¶€ë¦¬ë©°" ë“± ê³¼ë„í•œ ìˆ˜ì‚¬ë²•
- ë‹¨ìˆœí•œ ì‚¬ì‹¤ ë‚˜ì—´
- ëª¨í˜¸í•œ ì „ë§ ("ê³„ì†ë  ì „ë§", "ì‹œê¸‰í•œ ìƒí™©")

âœ… ê°œì„  ë°©í–¥:
- ê°ê´€ì ì´ê³  êµ¬ì²´ì ì¸ ì‚¬ì‹¤ ê¸°ë°˜ ì„œìˆ 
- í•µì‹¬ ì´ìŠˆì˜ ë°°ê²½ê³¼ í˜„ì¬ ìƒí™©ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì—°ê²°
- êµ¬ì²´ì  ìˆ˜ì¹˜, ë‚ ì§œ, ê¸°ê´€ëª… í™œìš©
- ê° ë‹¹ì‚¬ìì˜ ì…ì¥ì„ ê· í˜•ìˆê²Œ ì œì‹œ
- ëª…í™•í•œ í›„ì† ì¼ì •ì´ë‚˜ ì ˆì°¨ ì–¸ê¸‰
- 60-80ì ë‚´ì™¸ ê¶Œì¥

## ë¬¸ì²´ ê°œì„  í¬ì¸íŠ¸
1. **ì¤‘ë¦½ì„± ìœ ì§€**: íŠ¹ì • ì •íŒŒì— ì¹˜ìš°ì¹˜ì§€ ì•ŠëŠ” ê· í˜•ì¡íŒ ì‹œê°
2. **ì •í™•ì„± ìš°ì„ **: ì¶”ì¸¡ì´ë‚˜ ê°ì •ì  í‘œí˜„ë³´ë‹¤ í™•ì¸ëœ ì‚¬ì‹¤ ì¤‘ì‹¬
3. **ê°„ê²°ì„±**: ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´ ì œê±°, í•µì‹¬ ë‚´ìš©ë§Œ ê°„ì¶”ë¦¼
4. **ì „ë¬¸ì„±**: í•´ë‹¹ ë¶„ì•¼ ì „ë¬¸ìš©ì–´ë¥¼ ì ì ˆíˆ í™œìš©

## ì°¸ê³ í•  ê¸°ì‚¬ ìŠ¤íƒ€ì¼
- ì—°í•©ë‰´ìŠ¤: ì •í™•í•˜ê³  ê°„ê²°í•œ íŒ©íŠ¸ ì¤‘ì‹¬
- í•œêµ­ê²½ì œ: ê²½ì œ ì´ìŠˆì˜ íŒŒê¸‰íš¨ê³¼ ëª…í™•íˆ ì œì‹œ
- ì¡°ì„ ì¼ë³´: ì„íŒ©íŠ¸ ìˆìœ¼ë©´ì„œë„ í’ˆê²©ìˆëŠ” í‘œí˜„

ê¸°ì‚¬ ë‚´ìš©ë“¤:
{chr(10).join(article_contents)}

ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
ì œëª©: [ì „ë¬¸ì ì´ê³  ì„¸ë ¨ëœ ì œëª©]
ë¶€ì œëª©: [í•µì‹¬ ì •ë³´ ë³´ì™„]
ìš”ì•½: [ê°ê´€ì ì´ê³  êµ¬ì²´ì ì¸ ìš”ì•½]

ì£¼ì˜ì‚¬í•­:
- ì œëª©, ë¶€ì œëª©, ìš”ì•½ ì•ì— ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë‚˜ ê¸°í˜¸ë¥¼ ë¶™ì´ì§€ ë§ˆì„¸ìš”
- ê° í•­ëª©ì€ ë°˜ë“œì‹œ "ì œëª©:", "ë¶€ì œëª©:", "ìš”ì•½:"ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”
- ì •ì¹˜ì  ì¤‘ë¦½ì„±ì„ ìœ ì§€í•˜ê³  ì „ë¬¸ì ì¸ ê¸°ì‚¬ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±í•˜ì„¸ìš”
"""
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì£¼ìš” ì–¸ë¡ ì‚¬ì˜ ë² í…Œë‘ ê¸°ìì…ë‹ˆë‹¤. ì „ë¬¸ì ì´ê³  ì„¸ë ¨ëœ ê¸°ì‚¬ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±í•˜ë©°, ê°ê´€ì ì´ê³  ì •í™•í•œ íŒ©íŠ¸ ì¤‘ì‹¬ì˜ ë‰´ìŠ¤ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”. ì„ ì •ì  í‘œí˜„ì„ í”¼í•˜ê³  ì¤‘ë¦½ì ì´ë©´ì„œë„ ì„íŒ©íŠ¸ ìˆëŠ” í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=500,
                temperature=0.7
            )
            
            content = response.choices[0].message.content.strip()
            
            # ì‘ë‹µ íŒŒì‹± (ê°œì„ ëœ íŒŒì‹±)
            lines = content.split('\n')
            title = f"í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']} ì´ìŠˆ"
            subtitle = f"{cluster_info['size']}ê°œ ê¸°ì‚¬ ë¶„ì„"
            summary = "ì •ì¹˜ ì´ìŠˆ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤."
            
            for line in lines:
                line = line.strip()
                if line.startswith('ì œëª©:'):
                    title = line.replace('ì œëª©:', '').strip()
                    # ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±°
                    title = title.replace('**', '').replace('*', '').strip()
                elif line.startswith('ë¶€ì œëª©:'):
                    subtitle = line.replace('ë¶€ì œëª©:', '').strip()
                    # ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±°
                    subtitle = subtitle.replace('**', '').replace('*', '').strip()
                elif line.startswith('ìš”ì•½:'):
                    summary = line.replace('ìš”ì•½:', '').strip()
                    # ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±°
                    summary = summary.replace('**', '').replace('*', '').strip()
            
            # ê¸°ë³¸ê°’ ë°©ì§€ ë° í’ˆì§ˆ ê²€ì¦
            if title == f"í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']} ì´ìŠˆ" and len(content) > 50:
                # ì²« ë²ˆì§¸ ì¤„ì„ ì œëª©ìœ¼ë¡œ ì‚¬ìš© (ê¸°í˜¸ ì œê±°)
                first_line = content.split('\n')[0].strip()
                if len(first_line) > 10 and len(first_line) < 100:
                    title = first_line.replace('**', '').replace('*', '').strip()
            
            # í’ˆì§ˆ ê²€ì¦ ë° ê°œì„ 
            if len(title) < 5:
                title = f"ì •ì¹˜ ì´ìŠˆ {cluster_info['cluster_id']}"
            if len(subtitle) < 5:
                subtitle = f"{cluster_info['size']}ê°œ ê¸°ì‚¬ ê´€ë ¨ ì´ìŠˆ"
            if len(summary) < 20:
                summary = f"í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']}ì— í¬í•¨ëœ {cluster_info['size']}ê°œ ê¸°ì‚¬ë¥¼ ë¶„ì„í•œ ê²°ê³¼, ì¤‘ìš”í•œ ì •ì¹˜ ì´ìŠˆê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤."
            
            return {
                'title': title,
                'subtitle': subtitle,
                'summary': summary
            }
            
        except Exception as e:
            console.print(f"âŒ LLM ë‚´ìš© ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'title': f"í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']}",
                'subtitle': f"{cluster_info['size']}ê°œ ê¸°ì‚¬",
                'summary': "ë‚´ìš© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
    
    async def generate_issue_content_with_llm_async(self, cluster_info: dict) -> dict:
        """ë¹„ë™ê¸° LLMìœ¼ë¡œ ì´ìŠˆ ë‚´ìš© ìƒì„±"""
        try:
            console.print(f"ğŸ¤– í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']} LLM ë‚´ìš© ìƒì„± ì¤‘...")
            
            # í´ëŸ¬ìŠ¤í„°ì˜ ê¸°ì‚¬ ë‚´ìš© ìˆ˜ì§‘ (ì›ë³¸ articles í…Œì´ë¸”ì—ì„œ) - ìµœì í™”ëœ ë°°ì¹˜ ì¿¼ë¦¬
            article_contents = []
            
            # 1ë‹¨ê³„: embedding_idì—ì„œ article_idë¡œ ë§¤í•‘ (ìµœì í™”ëœ ë”•ì…”ë„ˆë¦¬ ì¡°íšŒ)
            embedding_ids = cluster_info['embedding_ids'][:5]  # ìµœëŒ€ 5ê°œ ê¸°ì‚¬
            article_ids = []
            
            for embedding_id in embedding_ids:
                article_id = self.id_to_article.get(embedding_id)
                if article_id:
                    article_ids.append(article_id)
            
            # 2ë‹¨ê³„: ì›ë³¸ articles í…Œì´ë¸”ì—ì„œ ë°°ì¹˜ë¡œ ì „ì²´ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° (ë‹¨ì¼ ì¿¼ë¦¬!)
            if article_ids:
                original_articles = self.supabase.client.table('articles').select(
                    'id, title, content'
                ).in_('id', article_ids).execute()
                
                if original_articles.data:
                    # 3ë‹¨ê³„: ê²°ê³¼ ì²˜ë¦¬
                    for article_info in original_articles.data:
                        full_content = f"ì œëª©: {article_info['title']}\në‚´ìš©: {article_info['content']}"
                        if len(full_content.strip()) > 50:
                            article_contents.append(full_content[:1000])  # 1000ìë¡œ í™•ì¥
            
            if not article_contents:
                return {
                    'title': f"í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']}",
                    'subtitle': f"{cluster_info['size']}ê°œ ê¸°ì‚¬",
                    'summary': "ë‚´ìš© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                }
            
            # ì „ë¬¸ì ì´ê³  ì„¸ë ¨ëœ ê¸°ì‚¬ ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸
            prompt = f"""
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì£¼ìš” ì–¸ë¡ ì‚¬ì˜ ë² í…Œë‘ ê¸°ìì…ë‹ˆë‹¤. ì•„ë˜ ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ì „ë¬¸ì ì´ê³  ì„¸ë ¨ëœ ê¸°ì‚¬ ìŠ¤íƒ€ì¼ë¡œ ì œëª©, ë¶€ì œëª©, ìš”ì•½ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

## ì œëª© ê°œì„  ê°€ì´ë“œë¼ì¸
âŒ í”¼í•´ì•¼ í•  í‘œí˜„:
- ê³¼ë„í•œ ê°íƒ„ë¶€í˜¸ (!, ?)
- "ê¸‰ê¸°ì•¼", "ê²°êµ­", "ë¬´ë ¤" ë“± ì„ ì •ì  ìˆ˜ì‹ì–´ ë‚¨ë°œ
- "í­ì¦", "í­ë°œ" ë“± ê³¼ì¥ëœ í‘œí˜„

âœ… ì§€í–¥í•´ì•¼ í•  í‘œí˜„:
- ê°„ê²°í•˜ê³  ì •í™•í•œ íŒ©íŠ¸ ì¤‘ì‹¬
- êµ¬ì²´ì  ìˆ˜ì¹˜ë‚˜ ê¸°ê´€ëª… í™œìš©
- ì¤‘ë¦½ì ì´ë©´ì„œë„ ì„íŒ©íŠ¸ ìˆëŠ” í‘œí˜„
- 12-15ì ë‚´ì™¸ ê¶Œì¥

## ë¶€ì œëª© ê°€ì´ë“œë¼ì¸
- ì œëª©ì—ì„œ ë‹¤ë£¨ì§€ ëª»í•œ í•µì‹¬ ì •ë³´ ë³´ì™„
- êµ¬ì²´ì  ë°°ê²½ì´ë‚˜ ì¶”ê°€ ìŸì  ì œì‹œ
- 20ì ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ

## ìš”ì•½ë¬¸ ê°œì„  ê°€ì´ë“œë¼ì¸
âŒ ê°œì„  í•„ìš”í•œ ë¶€ë¶„:
- "ë¬´ë ¤", "ê¸°ìŠ¹ì„ ë¶€ë¦¬ë©°" ë“± ê³¼ë„í•œ ìˆ˜ì‚¬ë²•
- ë‹¨ìˆœí•œ ì‚¬ì‹¤ ë‚˜ì—´
- ëª¨í˜¸í•œ ì „ë§ ("ê³„ì†ë  ì „ë§", "ì‹œê¸‰í•œ ìƒí™©")

âœ… ê°œì„  ë°©í–¥:
- ê°ê´€ì ì´ê³  êµ¬ì²´ì ì¸ ì‚¬ì‹¤ ê¸°ë°˜ ì„œìˆ 
- í•µì‹¬ ì´ìŠˆì˜ ë°°ê²½ê³¼ í˜„ì¬ ìƒí™©ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì—°ê²°
- êµ¬ì²´ì  ìˆ˜ì¹˜, ë‚ ì§œ, ê¸°ê´€ëª… í™œìš©
- ê° ë‹¹ì‚¬ìì˜ ì…ì¥ì„ ê· í˜•ìˆê²Œ ì œì‹œ
- ëª…í™•í•œ í›„ì† ì¼ì •ì´ë‚˜ ì ˆì°¨ ì–¸ê¸‰
- 60-80ì ë‚´ì™¸ ê¶Œì¥

## ë¬¸ì²´ ê°œì„  í¬ì¸íŠ¸
1. **ì¤‘ë¦½ì„± ìœ ì§€**: íŠ¹ì • ì •íŒŒì— ì¹˜ìš°ì¹˜ì§€ ì•ŠëŠ” ê· í˜•ì¡íŒ ì‹œê°
2. **ì •í™•ì„± ìš°ì„ **: ì¶”ì¸¡ì´ë‚˜ ê°ì •ì  í‘œí˜„ë³´ë‹¤ í™•ì¸ëœ ì‚¬ì‹¤ ì¤‘ì‹¬
3. **ê°„ê²°ì„±**: ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´ ì œê±°, í•µì‹¬ ë‚´ìš©ë§Œ ê°„ì¶”ë¦¼
4. **ì „ë¬¸ì„±**: í•´ë‹¹ ë¶„ì•¼ ì „ë¬¸ìš©ì–´ë¥¼ ì ì ˆíˆ í™œìš©

## ì°¸ê³ í•  ê¸°ì‚¬ ìŠ¤íƒ€ì¼
- ì—°í•©ë‰´ìŠ¤: ì •í™•í•˜ê³  ê°„ê²°í•œ íŒ©íŠ¸ ì¤‘ì‹¬
- í•œêµ­ê²½ì œ: ê²½ì œ ì´ìŠˆì˜ íŒŒê¸‰íš¨ê³¼ ëª…í™•íˆ ì œì‹œ
- ì¡°ì„ ì¼ë³´: ì„íŒ©íŠ¸ ìˆìœ¼ë©´ì„œë„ í’ˆê²©ìˆëŠ” í‘œí˜„

ê¸°ì‚¬ ë‚´ìš©ë“¤:
{chr(10).join(article_contents)}

ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
ì œëª©: [ì „ë¬¸ì ì´ê³  ì„¸ë ¨ëœ ì œëª©]
ë¶€ì œëª©: [í•µì‹¬ ì •ë³´ ë³´ì™„]
ìš”ì•½: [ê°ê´€ì ì´ê³  êµ¬ì²´ì ì¸ ìš”ì•½]

ì£¼ì˜ì‚¬í•­:
- ì œëª©, ë¶€ì œëª©, ìš”ì•½ ì•ì— ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë‚˜ ê¸°í˜¸ë¥¼ ë¶™ì´ì§€ ë§ˆì„¸ìš”
- ê° í•­ëª©ì€ ë°˜ë“œì‹œ "ì œëª©:", "ë¶€ì œëª©:", "ìš”ì•½:"ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”
- ì •ì¹˜ì  ì¤‘ë¦½ì„±ì„ ìœ ì§€í•˜ê³  ì „ë¬¸ì ì¸ ê¸°ì‚¬ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±í•˜ì„¸ìš”
"""
            
            # ë¹„ë™ê¸° LLM í˜¸ì¶œ
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                lambda: self.openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì£¼ìš” ì–¸ë¡ ì‚¬ì˜ ë² í…Œë‘ ê¸°ìì…ë‹ˆë‹¤. ì „ë¬¸ì ì´ê³  ì„¸ë ¨ëœ ê¸°ì‚¬ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±í•˜ë©°, ê°ê´€ì ì´ê³  ì •í™•í•œ íŒ©íŠ¸ ì¤‘ì‹¬ì˜ ë‰´ìŠ¤ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”. ì„ ì •ì  í‘œí˜„ì„ í”¼í•˜ê³  ì¤‘ë¦½ì ì´ë©´ì„œë„ ì„íŒ©íŠ¸ ìˆëŠ” í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=500,
                    temperature=0.7
                )
            )
            
            content = response.choices[0].message.content.strip()
            
            # ì‘ë‹µ íŒŒì‹± (ê°œì„ ëœ íŒŒì‹±)
            lines = content.split('\n')
            title = f"í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']} ì´ìŠˆ"
            subtitle = f"{cluster_info['size']}ê°œ ê¸°ì‚¬ ë¶„ì„"
            summary = "ì •ì¹˜ ì´ìŠˆ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤."
            
            for line in lines:
                line = line.strip()
                if line.startswith('ì œëª©:'):
                    title = line.replace('ì œëª©:', '').strip()
                    # ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±°
                    title = title.replace('**', '').replace('*', '').strip()
                elif line.startswith('ë¶€ì œëª©:'):
                    subtitle = line.replace('ë¶€ì œëª©:', '').strip()
                    # ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±°
                    subtitle = subtitle.replace('**', '').replace('*', '').strip()
                elif line.startswith('ìš”ì•½:'):
                    summary = line.replace('ìš”ì•½:', '').strip()
                    # ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±°
                    summary = summary.replace('**', '').replace('*', '').strip()
            
            # ê¸°ë³¸ê°’ ë°©ì§€ ë° í’ˆì§ˆ ê²€ì¦
            if title == f"í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']} ì´ìŠˆ" and len(content) > 50:
                # ì²« ë²ˆì§¸ ì¤„ì„ ì œëª©ìœ¼ë¡œ ì‚¬ìš© (ê¸°í˜¸ ì œê±°)
                first_line = content.split('\n')[0].strip()
                if len(first_line) > 10 and len(first_line) < 100:
                    title = first_line.replace('**', '').replace('*', '').strip()
            
            # í’ˆì§ˆ ê²€ì¦ ë° ê°œì„ 
            if len(title) < 5:
                title = f"ì •ì¹˜ ì´ìŠˆ {cluster_info['cluster_id']}"
            if len(subtitle) < 5:
                subtitle = f"{cluster_info['size']}ê°œ ê¸°ì‚¬ ê´€ë ¨ ì´ìŠˆ"
            if len(summary) < 20:
                summary = f"í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']}ì— í¬í•¨ëœ {cluster_info['size']}ê°œ ê¸°ì‚¬ë¥¼ ë¶„ì„í•œ ê²°ê³¼, ì¤‘ìš”í•œ ì •ì¹˜ ì´ìŠˆê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤."
            
            return {
                'title': title,
                'subtitle': subtitle,
                'summary': summary
            }
            
        except Exception as e:
            console.print(f"âŒ LLM ë‚´ìš© ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'title': f"í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']}",
                'subtitle': f"{cluster_info['size']}ê°œ ê¸°ì‚¬",
                'summary': "ë‚´ìš© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
    
    def analyze_political_bias(self, cluster_info: dict) -> dict:
        """ì •ì¹˜ ì„±í–¥ ë¶„ì„ - ìµœì í™”ëœ ë°°ì¹˜ ì²˜ë¦¬"""
        try:
            bias_counts = {'left': 0, 'center': 0, 'right': 0}
            
            # ìµœì í™”ëœ ë”•ì…”ë„ˆë¦¬ ì¡°íšŒ ë°©ì‹
            for embedding_id in cluster_info['embedding_ids']:
                # 1ë‹¨ê³„: embedding_id -> article_id (O(1) ì¡°íšŒ)
                article_id = self.id_to_article.get(embedding_id)
                if not article_id:
                    continue
                
                # 2ë‹¨ê³„: article_id -> media_id (O(1) ì¡°íšŒ)
                media_id = self.id_to_media.get(article_id)
                if not media_id:
                    continue
                
                # 3ë‹¨ê³„: ì–¸ë¡ ì‚¬ ì„±í–¥ ë¶„ì„ (O(1) ì¡°íšŒ)
                outlet_data = self.media_outlets[self.media_outlets['id'] == media_id]
                if not outlet_data.empty:
                    bias = outlet_data.iloc[0]['bias']
                    if bias in bias_counts:
                        bias_counts[bias] += 1
            
            return bias_counts
            
        except Exception as e:
            console.print(f"âŒ ì •ì¹˜ ì„±í–¥ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'left': 0, 'center': 0, 'right': 0}
    
    def save_clusters_to_database(self) -> bool:
        """í´ëŸ¬ìŠ¤í„° ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (LLM ë¹„ìš© ì ˆì•½ì„ ìœ„í•´ í¬ê¸° ìˆœ TOP3ë§Œ ì„ íƒ)"""
        try:
            console.print("ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘...")
            
            # LLM ë¹„ìš© ì ˆì•½ì„ ìœ„í•´ í´ëŸ¬ìŠ¤í„° ì¤‘ í¬ê¸° ìˆœìœ¼ë¡œ TOP3ë§Œ ì„ íƒ
            if len(self.clusters_info) > 3:
                selected_clusters = self.clusters_info[:3]  # ì´ë¯¸ í¬ê¸°ìˆœìœ¼ë¡œ ì •ë ¬ë˜ì–´ ìˆìŒ
                console.print(f"ğŸ† LLM ë¹„ìš© ì ˆì•½: {len(self.clusters_info)}ê°œ ì¤‘ TOP3 ì„ íƒ")
            else:
                selected_clusters = self.clusters_info
                console.print(f"ğŸ“ ëª¨ë“  í´ëŸ¬ìŠ¤í„° ({len(self.clusters_info)}ê°œ) ì²˜ë¦¬")
            
            saved_count = 0
            
            for cluster_info in selected_clusters:
                # LLMìœ¼ë¡œ ì´ìŠˆ ë‚´ìš© ìƒì„±
                llm_content = self.generate_issue_content_with_llm(cluster_info)
                
                # ì •ì¹˜ ì„±í–¥ ë¶„ì„
                bias_analysis = self.analyze_political_bias(cluster_info)
                
                # ì´ìŠˆ ë°ì´í„° êµ¬ì„±
                issue_data = {
                    'title': llm_content['title'],
                    'subtitle': llm_content['subtitle'],
                    'summary': llm_content['summary'],
                    'left_view': str(bias_analysis['left']),
                    'center_view': str(bias_analysis['center']),
                    'right_view': str(bias_analysis['right']),
                    'source': str(cluster_info['size']),
                    'date': datetime.now().date().isoformat()
                }
                
                # ì´ìŠˆ ì €ì¥
                issue_result = self.supabase.client.table('issues').insert(issue_data).execute()
                
                if issue_result.data:
                    issue_id = issue_result.data[0]['id']
                    
                    # issue_articles ë§¤í•‘ ì €ì¥ (ìµœì í™”ëœ ë”•ì…”ë„ˆë¦¬ ì¡°íšŒ)
                    for embedding_id in cluster_info['embedding_ids']:
                        # embedding_id -> article_id (O(1) ì¡°íšŒ)
                        article_id = self.id_to_article.get(embedding_id)
                        if article_id:
                            # issue_articles í…Œì´ë¸”ì— ë§¤í•‘ ì €ì¥
                            mapping_data = {
                                'issue_id': issue_id,
                                'article_id': article_id,
                                'stance': 'center'  # ê¸°ë³¸ê°’ (neutral ëŒ€ì‹  center ì‚¬ìš©)
                            }
                            
                            self.supabase.client.table('issue_articles').insert(mapping_data).execute()
                    
                    saved_count += 1
                    console.print(f"âœ… í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']} ì €ì¥ ì™„ë£Œ")
            
            console.print(f"âœ… ì´ {saved_count}ê°œ ì´ìŠˆ ì €ì¥ ì™„ë£Œ")
            return True
            
        except Exception as e:
            console.print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    async def save_clusters_to_database_async(self) -> bool:
        """ë¹„ë™ê¸° í´ëŸ¬ìŠ¤í„° ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (LLM ë¹„ìš© ì ˆì•½ì„ ìœ„í•´ í¬ê¸° ìˆœ TOP3ë§Œ ì„ íƒ)"""
        try:
            console.print("ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘...")
            
            # LLM ë¹„ìš© ì ˆì•½ì„ ìœ„í•´ í´ëŸ¬ìŠ¤í„° ì¤‘ í¬ê¸° ìˆœìœ¼ë¡œ TOP3ë§Œ ì„ íƒ
            if len(self.clusters_info) > 3:
                selected_clusters = self.clusters_info[:3]  # ì´ë¯¸ í¬ê¸°ìˆœìœ¼ë¡œ ì •ë ¬ë˜ì–´ ìˆìŒ
                console.print(f"ğŸ† LLM ë¹„ìš© ì ˆì•½: {len(self.clusters_info)}ê°œ ì¤‘ TOP3 ì„ íƒ")
            else:
                selected_clusters = self.clusters_info
                console.print(f"ğŸ“ ëª¨ë“  í´ëŸ¬ìŠ¤í„° ({len(self.clusters_info)}ê°œ) ì²˜ë¦¬")
            
            # ë¹„ë™ê¸° LLM í˜¸ì¶œë“¤ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
            llm_tasks = []
            for cluster_info in selected_clusters:
                task = self.generate_issue_content_with_llm_async(cluster_info)
                llm_tasks.append(task)
            
            # ëª¨ë“  LLM í˜¸ì¶œì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
            llm_results = await asyncio.gather(*llm_tasks)
            
            saved_count = 0
            
            for i, cluster_info in enumerate(selected_clusters):
                # LLM ê²°ê³¼ ì‚¬ìš©
                llm_content = llm_results[i]
                
                # ì •ì¹˜ ì„±í–¥ ë¶„ì„
                bias_analysis = self.analyze_political_bias(cluster_info)
                
                # ì´ìŠˆ ë°ì´í„° êµ¬ì„±
                issue_data = {
                    'title': llm_content['title'],
                    'subtitle': llm_content['subtitle'],
                    'summary': llm_content['summary'],
                    'left_view': str(bias_analysis['left']),
                    'center_view': str(bias_analysis['center']),
                    'right_view': str(bias_analysis['right']),
                    'source': str(cluster_info['size']),
                    'date': datetime.now().date().isoformat()
                }
                
                # ì´ìŠˆ ì €ì¥
                issue_result = self.supabase.client.table('issues').insert(issue_data).execute()
                
                if issue_result.data:
                    issue_id = issue_result.data[0]['id']
                    
                    # issue_articles ë§¤í•‘ ì €ì¥ (ìµœì í™”ëœ ë”•ì…”ë„ˆë¦¬ ì¡°íšŒ)
                    for embedding_id in cluster_info['embedding_ids']:
                        # embedding_id -> article_id (O(1) ì¡°íšŒ)
                        article_id = self.id_to_article.get(embedding_id)
                        if article_id:
                            # issue_articles í…Œì´ë¸”ì— ë§¤í•‘ ì €ì¥
                            mapping_data = {
                                'issue_id': issue_id,
                                'article_id': article_id,
                                'stance': 'center'  # ê¸°ë³¸ê°’ (neutral ëŒ€ì‹  center ì‚¬ìš©)
                            }
                            
                            self.supabase.client.table('issue_articles').insert(mapping_data).execute()
                    
                    saved_count += 1
                    console.print(f"âœ… í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']} ì €ì¥ ì™„ë£Œ")
            
            console.print(f"âœ… ì´ {saved_count}ê°œ ì´ìŠˆ ì €ì¥ ì™„ë£Œ")
            return True
            
        except Exception as e:
            console.print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    async def run_full_clustering(self) -> bool:
        """ì „ì²´ í´ëŸ¬ìŠ¤í„°ë§ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        try:
            console.print(Panel(
                "[bold blue]ğŸš€ ì •ì¹˜ ë‰´ìŠ¤ í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘[/bold blue]\n"
                "[yellow]UMAP + HDBSCAN + LLM[/yellow]",
                title="í´ëŸ¬ìŠ¤í„°ë§ íŒŒì´í”„ë¼ì¸"
            ))
            
            # 1. ë°ì´í„° ë¡œë“œ
            if not self.load_embeddings_with_pagination():
                return False
            
            if not self.load_articles_data():
                return False
            
            if not self.load_media_outlets():
                return False
            
            # 1.5. ì„±ëŠ¥ ìµœì í™” ë§¤í•‘ ìƒì„±
            if not self.create_performance_mappings():
                return False
            
            # 2. UMAP ì°¨ì› ì¶•ì†Œ
            if not self.run_umap_reduction():
                return False
            
            # 3. HDBSCAN í´ëŸ¬ìŠ¤í„°ë§
            if not self.run_hdbscan_clustering():
                    return False
            
            # 4. í´ëŸ¬ìŠ¤í„° ë¶„ì„
            if not self.analyze_clusters():
                return False
            
            # 5. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ (ë¹„ë™ê¸°)
            if not await self.save_clusters_to_database_async():
                return False
            
            console.print(Panel(
                f"[bold green]âœ… í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ! ì´ {len(self.clusters_info)}ê°œ ì´ìŠˆ ìƒì„±[/bold green]",
                title="ì™„ë£Œ"
            ))
            
            return True
            
        except Exception as e:
            console.print(f"âŒ í´ëŸ¬ìŠ¤í„°ë§ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            return False

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        clusterer = PoliticalNewsClusterer()
        await clusterer.run_full_clustering()
    except Exception as e:
        console.print(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")

def run_main():
    """ë¹„ë™ê¸° ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰"""
    asyncio.run(main())

if __name__ == "__main__":
    run_main()
