#!/usr/bin/env python3
"""
ìƒ˜í”Œ ë°ì´í„°ë¡œ UMAP + HDBSCAN í´ëŸ¬ìŠ¤í„°ë§ í…ŒìŠ¤íŠ¸
"""

import sys
import os
import numpy as np
import pandas as pd
from datetime import datetime
from typing import Dict, Any, List
import json

# í´ëŸ¬ìŠ¤í„°ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬
import umap
import hdbscan
from sklearn.metrics import silhouette_score

# ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬
import matplotlib.pyplot as plt
import seaborn as sns

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.supabase_manager import get_supabase_client
from rich.console import Console
from rich.panel import Panel
from rich.table import Table

console = Console()

class SampleClusterer:
    """ìƒ˜í”Œ ë°ì´í„° í´ëŸ¬ìŠ¤í„°ëŸ¬"""
    
    def __init__(self, sample_size: int = 200):
        """í´ëŸ¬ìŠ¤í„°ëŸ¬ ì´ˆê¸°í™”"""
        self.sample_size = sample_size
        self.supabase = get_supabase_client()
        self.embeddings = None
        self.articles_data = None
        self.cluster_labels = None
        self.umap_embedding = None
        
    def load_sample_data(self) -> bool:
        """ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ"""
        try:
            console.print(f"ğŸ“Š ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ ì¤‘... (í¬ê¸°: {self.sample_size}ê°œ)")
            
            # ì„ë² ë”© ë°ì´í„° ì¡°íšŒ (í˜ì´ì§€ë„¤ì´ì…˜ ì ìš©)
            all_embeddings = []
            offset = 0
            batch_size = 1000  # Supabase ê¸°ë³¸ ì œí•œ
            
            while len(all_embeddings) < self.sample_size:
                remaining = self.sample_size - len(all_embeddings)
                current_batch_size = min(batch_size, remaining)
                
                result = self.supabase.client.table('articles_embeddings').select(
                    'cleaned_article_id, embedding_vector, model_name'
                ).eq('embedding_type', 'combined').range(offset, offset + current_batch_size - 1).execute()
                
                if not result.data:
                    break
                    
                all_embeddings.extend(result.data)
                offset += current_batch_size
                
                if len(result.data) < current_batch_size:
                    break
            
            result = type('obj', (object,), {'data': all_embeddings})
            
            if not result.data:
                console.print("âŒ ì„ë² ë”© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # ê¸°ì‚¬ ë©”íƒ€ë°ì´í„° ì¡°íšŒ (ë°°ì¹˜ ì²˜ë¦¬)
            article_ids = [item['cleaned_article_id'] for item in result.data]
            
            batch_size = 50
            articles_data_list = []
            
            for i in range(0, len(article_ids), batch_size):
                batch_ids = article_ids[i:i+batch_size]
                articles_result = self.supabase.client.table('articles_cleaned').select(
                    'id, title_cleaned, lead_paragraph, merged_content, original_article_id'
                ).in_('id', batch_ids).execute()
                
                if articles_result.data:
                    articles_data_list.extend(articles_result.data)
            
            # ë°ì´í„° ì •ë¦¬
            embeddings_df = pd.DataFrame(result.data)
            articles_df = pd.DataFrame(articles_data_list)
            
            # ì„ë² ë”© ë²¡í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            embeddings_list = []
            for embedding_str in embeddings_df['embedding_vector']:
                if isinstance(embedding_str, str):
                    embedding_vector = json.loads(embedding_str)
                else:
                    embedding_vector = embedding_str
                embeddings_list.append(embedding_vector)
            
            self.embeddings = np.array(embeddings_list)
            
            # ê¸°ì‚¬ ë°ì´í„°ì™€ ë§¤í•‘
            self.articles_data = articles_df.merge(
                embeddings_df[['cleaned_article_id']], 
                left_on='id', 
                right_on='cleaned_article_id'
            )
            
            console.print(f"âœ… ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ:")
            console.print(f"   - ì„ë² ë”©: {len(self.embeddings)}ê°œ")
            console.print(f"   - ê¸°ì‚¬ ë©”íƒ€ë°ì´í„°: {len(self.articles_data)}ê°œ")
            console.print(f"   - ì„ë² ë”© ì°¨ì›: {self.embeddings.shape[1]}")
            
            return True
            
        except Exception as e:
            console.print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def run_umap(self, n_components: int = 2) -> bool:
        """UMAP ì°¨ì› ì¶•ì†Œ"""
        try:
            console.print("ğŸ”„ UMAP ì°¨ì› ì¶•ì†Œ ì‹¤í–‰ ì¤‘...")
            
            # UMAP íŒŒë¼ë¯¸í„° ì¡°ì • (ìƒ˜í”Œ ë°ì´í„°ì— ë§ê²Œ)
            n_neighbors = min(15, len(self.embeddings) - 1)
            
            reducer = umap.UMAP(
                n_components=n_components,
                n_neighbors=n_neighbors,
                min_dist=0.1,
                random_state=42,
                verbose=True
            )
            
            self.umap_embedding = reducer.fit_transform(self.embeddings)
            
            console.print(f"âœ… UMAP ì™„ë£Œ: {self.embeddings.shape[1]}D â†’ {n_components}D")
            console.print(f"   - íŒŒë¼ë¯¸í„°: n_neighbors={n_neighbors}, min_dist=0.1")
            
            return True
            
        except Exception as e:
            console.print(f"âŒ UMAP ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return False
    
    def run_hdbscan(self) -> bool:
        """HDBSCAN í´ëŸ¬ìŠ¤í„°ë§"""
        try:
            console.print("ğŸ”„ HDBSCAN í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰ ì¤‘...")
            
            # HDBSCAN íŒŒë¼ë¯¸í„° ì¡°ì • (ìƒ˜í”Œ ë°ì´í„°ì— ë§ê²Œ)
            min_cluster_size = max(3, len(self.embeddings) // 20)  # ì „ì²´ì˜ 5%
            min_samples = max(2, min_cluster_size // 2)
            
            clusterer = hdbscan.HDBSCAN(
                min_cluster_size=min_cluster_size,
                min_samples=min_samples,
                metric='euclidean'
            )
            
            self.cluster_labels = clusterer.fit_predict(self.umap_embedding)
            
            # í´ëŸ¬ìŠ¤í„° í†µê³„
            unique_labels = np.unique(self.cluster_labels)
            n_clusters = len(unique_labels) - (1 if -1 in unique_labels else 0)
            n_noise = list(self.cluster_labels).count(-1)
            
            console.print(f"âœ… HDBSCAN ì™„ë£Œ:")
            console.print(f"   - í´ëŸ¬ìŠ¤í„° ìˆ˜: {n_clusters}ê°œ")
            console.print(f"   - ë…¸ì´ì¦ˆ ê¸°ì‚¬: {n_noise}ê°œ")
            console.print(f"   - íŒŒë¼ë¯¸í„°: min_cluster_size={min_cluster_size}, min_samples={min_samples}")
            
            return True
            
        except Exception as e:
            console.print(f"âŒ HDBSCAN ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return False
    
    def evaluate_clusters(self) -> Dict[str, Any]:
        """í´ëŸ¬ìŠ¤í„° í’ˆì§ˆ í‰ê°€"""
        try:
            console.print("ğŸ“Š í´ëŸ¬ìŠ¤í„° í’ˆì§ˆ í‰ê°€ ì¤‘...")
            
            # ë…¸ì´ì¦ˆê°€ ì•„ë‹Œ ë°ì´í„°ë§Œ ì‚¬ìš©
            valid_mask = self.cluster_labels != -1
            if np.sum(valid_mask) < 2:
                console.print("âŒ ìœ íš¨í•œ í´ëŸ¬ìŠ¤í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                return {}
            
            # ì‹¤ë£¨ì—£ ì ìˆ˜ ê³„ì‚°
            silhouette_avg = silhouette_score(
                self.umap_embedding[valid_mask], 
                self.cluster_labels[valid_mask]
            )
            
            # í´ëŸ¬ìŠ¤í„°ë³„ í†µê³„
            cluster_stats = {}
            for label in np.unique(self.cluster_labels):
                if label == -1:  # ë…¸ì´ì¦ˆ ì œì™¸
                    continue
                cluster_mask = self.cluster_labels == label
                cluster_size = np.sum(cluster_mask)
                cluster_stats[f'cluster_{label}'] = {
                    'size': cluster_size,
                    'percentage': cluster_size / len(self.cluster_labels) * 100
                }
            
            console.print(f"âœ… í‰ê°€ ì™„ë£Œ:")
            console.print(f"   - ì‹¤ë£¨ì—£ ì ìˆ˜: {silhouette_avg:.3f}")
            console.print(f"   - í´ëŸ¬ìŠ¤í„° ìˆ˜: {len(cluster_stats)}ê°œ")
            console.print(f"   - ë…¸ì´ì¦ˆ ë¹„ìœ¨: {np.sum(self.cluster_labels == -1)/len(self.cluster_labels)*100:.1f}%")
            
            return {
                'silhouette_score': silhouette_avg,
                'n_clusters': len(cluster_stats),
                'n_noise': np.sum(self.cluster_labels == -1),
                'cluster_details': cluster_stats
            }
            
        except Exception as e:
            console.print(f"âŒ í‰ê°€ ì‹¤íŒ¨: {e}")
            return {}
    
    def visualize_clusters(self) -> bool:
        """í´ëŸ¬ìŠ¤í„° ì‹œê°í™”"""
        try:
            console.print("ğŸ¨ í´ëŸ¬ìŠ¤í„° ì‹œê°í™” ìƒì„± ì¤‘...")
            
            # ë°ì´í„° ì¤€ë¹„
            df_viz = pd.DataFrame({
                'x': self.umap_embedding[:, 0],
                'y': self.umap_embedding[:, 1],
                'cluster': self.cluster_labels,
                'title': self.articles_data['title_cleaned'].values
            })
            
            # matplotlib ì‹œê°í™”
            plt.figure(figsize=(12, 8))
            scatter = plt.scatter(df_viz['x'], df_viz['y'], 
                               c=df_viz['cluster'], 
                               cmap='tab20', 
                               alpha=0.7,
                               s=50)
            plt.colorbar(scatter)
            plt.title(f'Political News Clusters (Sample: {len(self.embeddings)} articles)')
            plt.xlabel('UMAP Dimension 1')
            plt.ylabel('UMAP Dimension 2')
            
            # í´ëŸ¬ìŠ¤í„°ë³„ ê¸°ì‚¬ ìˆ˜ í‘œì‹œ
            for label in np.unique(self.cluster_labels):
                if label == -1:
                    continue
                cluster_mask = self.cluster_labels == label
                cluster_center = self.umap_embedding[cluster_mask].mean(axis=0)
                plt.annotate(f'C{label}\n({np.sum(cluster_mask)})', 
                           cluster_center, 
                           ha='center', 
                           va='center',
                           bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))
            
            plt.tight_layout()
            plt.savefig('sample_clustering_results.png', dpi=300, bbox_inches='tight')
            console.print("âœ… ì‹œê°í™” ì €ì¥: sample_clustering_results.png")
            
            # í•­ìƒ ì´ë¯¸ì§€ ì €ì¥í•˜ê³  GUI í™˜ê²½ì—ì„œë§Œ show ì‹¤í–‰
            import os
            if os.environ.get('DISPLAY') or os.environ.get('WAYLAND_DISPLAY'):
                plt.show()
            else:
                plt.close()  # ë©”ëª¨ë¦¬ ì •ë¦¬
                console.print("ğŸ’¾ ì‹œê°í™” ì´ë¯¸ì§€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. GUI í™˜ê²½ì´ ì•„ë‹ˆë¯€ë¡œ í™”ë©´ì— í‘œì‹œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
            return True
            
        except Exception as e:
            console.print(f"âŒ ì‹œê°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def analyze_clusters(self) -> List[Dict[str, Any]]:
        """í´ëŸ¬ìŠ¤í„° ë¶„ì„"""
        try:
            console.print("ğŸ” í´ëŸ¬ìŠ¤í„° ë¶„ì„ ì¤‘...")
            
            clusters_info = []
            
            for label in np.unique(self.cluster_labels):
                if label == -1:  # ë…¸ì´ì¦ˆ ì œì™¸
                    continue
                
                cluster_mask = self.cluster_labels == label
                cluster_articles = self.articles_data[cluster_mask]
                
                # í´ëŸ¬ìŠ¤í„° ì •ë³´ ìˆ˜ì§‘
                cluster_info = {
                    'cluster_id': int(label),
                    'size': int(np.sum(cluster_mask)),
                    'articles': cluster_articles[['id', 'title_cleaned', 'lead_paragraph']].to_dict('records'),
                    'representative_article': cluster_articles.iloc[0].to_dict() if len(cluster_articles) > 0 else {}
                }
                
                clusters_info.append(cluster_info)
            
            # ê²°ê³¼ í…Œì´ë¸” ì¶œë ¥
            table = Table(title="í´ëŸ¬ìŠ¤í„° ë¶„ì„ ê²°ê³¼")
            table.add_column("í´ëŸ¬ìŠ¤í„° ID", style="cyan")
            table.add_column("ê¸°ì‚¬ ìˆ˜", style="magenta")
            table.add_column("ëŒ€í‘œ ê¸°ì‚¬ ì œëª©", style="green")
            
            for cluster_info in clusters_info:
                title = cluster_info['representative_article'].get('title_cleaned', 'N/A')
                if len(title) > 50:
                    title = title[:50] + "..."
                
                table.add_row(
                    str(cluster_info['cluster_id']),
                    str(cluster_info['size']),
                    title
                )
            
            console.print(table)
            
            return clusters_info
            
        except Exception as e:
            console.print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return []
    
    def run_sample_clustering(self) -> bool:
        """ìƒ˜í”Œ í´ëŸ¬ìŠ¤í„°ë§ ì „ì²´ íŒŒì´í”„ë¼ì¸"""
        try:
            console.print(Panel.fit(
                f"[bold blue]ğŸš€ ìƒ˜í”Œ í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘ (í¬ê¸°: {self.sample_size}ê°œ)[/bold blue]",
                title="ìƒ˜í”Œ í´ëŸ¬ìŠ¤í„°ë§"
            ))
            
            # 1. ë°ì´í„° ë¡œë“œ
            if not self.load_sample_data():
                return False
            
            # 2. UMAP ì°¨ì› ì¶•ì†Œ
            if not self.run_umap():
                return False
            
            # 3. HDBSCAN í´ëŸ¬ìŠ¤í„°ë§
            if not self.run_hdbscan():
                return False
            
            # 4. í’ˆì§ˆ í‰ê°€
            self.evaluate_clusters()
            
            # 5. ì‹œê°í™”
            self.visualize_clusters()
            
            # 6. í´ëŸ¬ìŠ¤í„° ë¶„ì„
            self.analyze_clusters()
            
            console.print(Panel.fit(
                "[bold green]âœ… ìƒ˜í”Œ í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ![/bold green]",
                title="ì™„ë£Œ"
            ))
            
            return True
            
        except Exception as e:
            console.print(f"âŒ ìƒ˜í”Œ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨: {e}")
            return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ìƒ˜í”Œ í¬ê¸° ì„ íƒ
    console.print("ìƒ˜í”Œ í¬ê¸°ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    console.print("1. 100ê°œ ê¸°ì‚¬")
    console.print("2. 200ê°œ ê¸°ì‚¬")
    console.print("3. 500ê°œ ê¸°ì‚¬")
    
    choice = input("ì„ íƒ (1-3): ").strip()
    
    sample_sizes = {'1': 100, '2': 200, '3': 500}
    sample_size = sample_sizes.get(choice, 200)
    
    clusterer = SampleClusterer(sample_size=sample_size)
    clusterer.run_sample_clustering()

if __name__ == "__main__":
    main()
