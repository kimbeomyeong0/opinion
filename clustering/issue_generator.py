#!/usr/bin/env python3
"""
ì´ìŠˆ ìƒì„±ê¸° í´ë˜ìŠ¤ - KISS ì›ì¹™ ì ìš©
LLMì„ í†µí•œ ì´ìŠˆ ìƒì„±ê³¼ DB ì €ì¥ë§Œ ë‹´ë‹¹í•˜ëŠ” ë‹¨ì¼ ì±…ì„
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio
from datetime import datetime
from rich.console import Console
from openai import OpenAI
from functools import lru_cache

from utils.supabase_manager import get_supabase_client
from clustering.config import get_config

console = Console()

class IssueGenerator:
    """ì´ìŠˆ ìƒì„±ê¸° í´ë˜ìŠ¤ - ë‹¨ì¼ ì±…ì„: ì´ìŠˆ ìƒì„± ë° ì €ì¥"""
    
    def __init__(self, clusters_info, articles_data, media_outlets):
        """ì´ˆê¸°í™”"""
        self.config = get_config()
        self.supabase = get_supabase_client()
        self.openai_client = OpenAI(api_key=self.config["openai_api_key"])
        self.clusters_info = clusters_info
        self.articles_data = articles_data
        self.media_outlets = media_outlets
        
        # ìºì‹±ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
        self._bias_classification_cache = {}
        self._content_cache = {}
        
        # ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
        self._max_cache_size = 1000  # ìµœëŒ€ ìºì‹œ í¬ê¸°
        self._cache_hit_count = 0
        self._cache_miss_count = 0
    
    async def generate_issue_content(self, cluster_info: dict) -> dict:
        """LLMìœ¼ë¡œ ì´ìŠˆ ë‚´ìš© ìƒì„± - ì„±í–¥ë³„ ê¸°ì‚¬ ë¶„ë¥˜ ê¸°ë°˜"""
        try:
            console.print(f"ğŸ¤– í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']} ì´ìŠˆ ìƒì„± ì¤‘...")
            
            # title, subtitle, summaryìš© (merged_content ì‚¬ìš©)
            articles_by_bias = self._classify_articles_by_bias(cluster_info['articles'])
            
            # viewìš© (articles.content ì‚¬ìš©)
            articles_by_bias_with_content = self._classify_articles_by_bias_with_content(cluster_info['articles'])
            
            # 1. title, subtitle ìƒì„± (merged_content ê¸°ë°˜)
            title, subtitle = await self._generate_title_and_subtitle(articles_by_bias['all'])
            
            # 2. summary ìƒì„± (ëª¨ë“  ê¸°ì‚¬ ë³¸ë¬¸ - merged_content)
            summary = await self._generate_summary(articles_by_bias['all'])
            
            # 3. ì„±í–¥ë³„ ê´€ì  ìƒì„± (articles.content ì‚¬ìš©) - ì§€ì§€/ì¤‘ë¦½/ë¹„íŒ ê´€ì  ëª…í™•í™”
            left_view = await self._generate_bias_view(articles_by_bias_with_content['left'], 'ì§„ë³´ì ')  # ì§€ì§€ ê´€ì 
            center_view = await self._generate_bias_view(articles_by_bias_with_content['center'], 'ì¤‘ë„ì ')  # ì¤‘ë¦½ ê´€ì 
            right_view = await self._generate_bias_view(articles_by_bias_with_content['right'], 'ë³´ìˆ˜ì ')  # ë¹„íŒ ê´€ì 
            
            return {
                'title': title,
                'subtitle': subtitle,
                'summary': summary,
                'left_view': left_view,
                'center_view': center_view,
                'right_view': right_view
            }
            
        except Exception as e:
            console.print(f"âŒ ì´ìŠˆ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'title': f"í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']}",
                'subtitle': f"{cluster_info['size']}ê°œ ê¸°ì‚¬",
                'summary': "ë‚´ìš© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                'left_view': "",
                'center_view': "",
                'right_view': ""
            }
    
    def _classify_articles_by_bias(self, articles: list) -> dict:
        """ê¸°ì‚¬ë¥¼ ì„±í–¥ë³„ë¡œ ë¶„ë¥˜ (í†µí•© í•¨ìˆ˜ ì‚¬ìš©)"""
        unified = self._classify_articles_by_bias_unified(articles)
        return {
            'all': unified['all_merged'],
            'left': unified['left_merged'],
            'center': unified['center_merged'],
            'right': unified['right_merged']
        }
    
    def _select_articles_by_bias_ratio(self, articles: list, max_articles: int) -> list:
        """ì„±í–¥ë³„ ë¹„ìœ¨ì— ë§ì¶° ê¸°ì‚¬ ì„ íƒ (ì‹œê°„ìˆœ)"""
        # 1ë‹¨ê³„: ì‹¤ì œ ì„±í–¥ ë¹„ìœ¨ ê³„ì‚°
        total = len(articles)
        left_articles = []
        center_articles = []
        right_articles = []
        
        bias_mapping = self.config["media_bias_mapping"]
        
        for article in articles:
            media_id = article.get('media_id', '')
            media_name = self._get_media_name(media_id)
            
            if media_name in bias_mapping['left']:
                left_articles.append(article)
            elif media_name in bias_mapping['center']:
                center_articles.append(article)
            elif media_name in bias_mapping['right']:
                right_articles.append(article)
        
        # 2ë‹¨ê³„: ë¹„ìœ¨ ê³„ì‚°
        left_ratio = len(left_articles) / total if total > 0 else 0
        center_ratio = len(center_articles) / total if total > 0 else 0
        right_ratio = len(right_articles) / total if total > 0 else 0
        
        # 3ë‹¨ê³„: ë¹„ìœ¨ì— ë§ì¶° ìƒ˜í”Œ ìˆ˜ ê³„ì‚°
        left_samples = int(max_articles * left_ratio)
        center_samples = int(max_articles * center_ratio)
        right_samples = int(max_articles * right_ratio)
        
        # 4ë‹¨ê³„: ê° ì„±í–¥ë³„ë¡œ ìµœì‹ ìˆœìœ¼ë¡œ ì„ íƒ
        selected = []
        
        # ìµœì‹ ìˆœ ì •ë ¬ (published_at ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ)
        left_sorted = sorted(left_articles, key=lambda x: x.get('published_at', ''), reverse=True)
        center_sorted = sorted(center_articles, key=lambda x: x.get('published_at', ''), reverse=True)
        right_sorted = sorted(right_articles, key=lambda x: x.get('published_at', ''), reverse=True)
        
        # ê° ì„±í–¥ë³„ë¡œ ìµœì‹  ê¸°ì‚¬ë“¤ ì„ íƒ
        selected.extend(left_sorted[:left_samples])
        selected.extend(center_sorted[:center_samples])
        selected.extend(right_sorted[:right_samples])
        
        console.print(f"ğŸ“Š í¬ê¸° ì œí•œ ì ìš©: {total}ê°œ â†’ {len(selected)}ê°œ (ì¢Œ:{left_samples}, ì¤‘:{center_samples}, ìš°:{right_samples})")
        
        return selected
    
    def _classify_articles_by_bias_unified(self, articles: list) -> dict:
        """í†µí•© ì„±í–¥ ë¶„ë¥˜ (ìºì‹± ì ìš©)"""
        # ìºì‹œ í‚¤ ìƒì„± (ê¸°ì‚¬ ID ëª©ë¡ìœ¼ë¡œ)
        article_ids = tuple(sorted([article.get('article_id', '') for article in articles]))
        cache_key = article_ids
        
        # ìºì‹œ í™•ì¸
        if cache_key in self._bias_classification_cache:
            self._cache_hit_count += 1
            console.print(f"ğŸ“Š ìºì‹œëœ ì„±í–¥ ë¶„ë¥˜ ê²°ê³¼ ì‚¬ìš©")
            return self._bias_classification_cache[cache_key]
        
        self._cache_miss_count += 1
        
        # í¬ê¸° ì œí•œ ì ìš©
        max_articles = self.config["max_articles_per_cluster"]
        if len(articles) > max_articles:
            articles = self._select_articles_by_bias_ratio(articles, max_articles)
        
        # ì¼ê´„ content ë¡œë”© (ìºì‹± ì ìš©)
        article_contents = self._load_article_contents_batch_cached(articles)
        
        # í†µí•© ë¶„ë¥˜ ê²°ê³¼
        result = {
            'all_merged': [],      # title, subtitle, summaryìš©
            'all_content': [],     # viewìš©
            'left_merged': [],     # ì¢ŒíŒŒ merged_content
            'left_content': [],    # ì¢ŒíŒŒ content
            'center_merged': [],   # ì¤‘íŒŒ merged_content
            'center_content': [],  # ì¤‘íŒŒ content
            'right_merged': [],    # ìš°íŒŒ merged_content
            'right_content': []    # ìš°íŒŒ content
        }
        
        bias_mapping = self.config["media_bias_mapping"]
        
        # í•œ ë²ˆë§Œ ì„±í–¥ ë¶„ë¥˜
        for article in articles:
            media_id = article.get('media_id', '')
            media_name = self._get_media_name(media_id)
            
            merged_content = article.get('merged_content', '')
            article_id = article.get('article_id', '')
            content = article_contents.get(article_id, '')
            
            # merged_content ë¶„ë¥˜
            if merged_content and merged_content.strip():
                result['all_merged'].append(merged_content.strip())
                if media_name in bias_mapping['left']:
                    result['left_merged'].append(merged_content.strip())
                elif media_name in bias_mapping['center']:
                    result['center_merged'].append(merged_content.strip())
                elif media_name in bias_mapping['right']:
                    result['right_merged'].append(merged_content.strip())
            
            # content ë¶„ë¥˜
            if content and content.strip():
                result['all_content'].append(content.strip())
                if media_name in bias_mapping['left']:
                    result['left_content'].append(content.strip())
                elif media_name in bias_mapping['center']:
                    result['center_content'].append(content.strip())
                elif media_name in bias_mapping['right']:
                    result['right_content'].append(content.strip())
        
        # ê²°ê³¼ ìºì‹±
        self._bias_classification_cache[cache_key] = result
        
        # ìºì‹œ í¬ê¸° ê´€ë¦¬
        self._manage_cache_size()
        
        console.print(f"ğŸ“Š í†µí•© ì„±í–¥ ë¶„ë¥˜: {len(articles)}ê°œ ê¸°ì‚¬ â†’ ì¢Œ:{len(result['left_merged'])}, ì¤‘:{len(result['center_merged'])}, ìš°:{len(result['right_merged'])}")
        
        return result
    
    def _load_article_contents_batch(self, articles: list) -> dict:
        """ê¸°ì‚¬ë“¤ì˜ contentë¥¼ ì¼ê´„ ë¡œë”© (ì¤‘ë³µ DB ì¡°íšŒ ì œê±°)"""
        try:
            # article_id ëª©ë¡ ì¶”ì¶œ
            article_ids = [article.get('article_id', '') for article in articles if article.get('article_id')]
            
            if not article_ids:
                return {}
            
            # ì¼ê´„ ì¡°íšŒ
            result = self.supabase.client.table('articles').select('id,content').in_('id', article_ids).execute()
            
            # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            content_dict = {}
            for item in result.data:
                content_dict[item['id']] = item.get('content', '')
            
            console.print(f"ğŸ“Š ì¼ê´„ content ë¡œë”©: {len(article_ids)}ê°œ ê¸°ì‚¬ â†’ {len(content_dict)}ê°œ ì„±ê³µ")
            return content_dict
            
        except Exception as e:
            console.print(f"âŒ ì¼ê´„ content ë¡œë”© ì‹¤íŒ¨: {e}")
            return {}
    
    def _manage_cache_size(self):
        """ìºì‹œ í¬ê¸° ê´€ë¦¬ (ë©”ëª¨ë¦¬ ìµœì í™”)"""
        # content ìºì‹œ í¬ê¸° ê´€ë¦¬
        if len(self._content_cache) > self._max_cache_size:
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª©ë“¤ ì œê±° (ê°„ë‹¨í•œ FIFO)
            items_to_remove = len(self._content_cache) - self._max_cache_size
            keys_to_remove = list(self._content_cache.keys())[:items_to_remove]
            for key in keys_to_remove:
                del self._content_cache[key]
            console.print(f"ğŸ—‘ï¸ content ìºì‹œ ì •ë¦¬: {items_to_remove}ê°œ í•­ëª© ì œê±°")
        
        # bias ë¶„ë¥˜ ìºì‹œ í¬ê¸° ê´€ë¦¬
        if len(self._bias_classification_cache) > 100:  # ë” ì‘ì€ í¬ê¸°ë¡œ ì œí•œ
            items_to_remove = len(self._bias_classification_cache) - 100
            keys_to_remove = list(self._bias_classification_cache.keys())[:items_to_remove]
            for key in keys_to_remove:
                del self._bias_classification_cache[key]
            console.print(f"ğŸ—‘ï¸ bias ë¶„ë¥˜ ìºì‹œ ì •ë¦¬: {items_to_remove}ê°œ í•­ëª© ì œê±°")
    
    def _get_cache_stats(self) -> dict:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        total_requests = self._cache_hit_count + self._cache_miss_count
        hit_rate = (self._cache_hit_count / total_requests * 100) if total_requests > 0 else 0
        
        return {
            'content_cache_size': len(self._content_cache),
            'bias_cache_size': len(self._bias_classification_cache),
            'cache_hits': self._cache_hit_count,
            'cache_misses': self._cache_miss_count,
            'hit_rate': hit_rate
        }
    
    def _load_article_contents_batch_cached(self, articles: list) -> dict:
        """ê¸°ì‚¬ë“¤ì˜ contentë¥¼ ì¼ê´„ ë¡œë”© (ìºì‹± ì ìš©)"""
        try:
            # article_id ëª©ë¡ ì¶”ì¶œ
            article_ids = [article.get('article_id', '') for article in articles if article.get('article_id')]
            
            if not article_ids:
                return {}
            
            # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
            cached_contents = {}
            uncached_ids = []
            
            for article_id in article_ids:
                if article_id in self._content_cache:
                    cached_contents[article_id] = self._content_cache[article_id]
                else:
                    uncached_ids.append(article_id)
            
            # ìºì‹œì— ì—†ëŠ” ê²ƒë“¤ë§Œ DBì—ì„œ ì¡°íšŒ
            if uncached_ids:
                result = self.supabase.client.table('articles').select('id,content').in_('id', uncached_ids).execute()
                
                # ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥
                for item in result.data:
                    content = item.get('content', '')
                    self._content_cache[item['id']] = content
                    cached_contents[item['id']] = content
            
            console.print(f"ğŸ“Š ìºì‹±ëœ content ë¡œë”©: {len(article_ids)}ê°œ ì¤‘ {len(uncached_ids)}ê°œ ìƒˆë¡œ ë¡œë”©")
            
            # ìºì‹œ í¬ê¸° ê´€ë¦¬
            self._manage_cache_size()
            
            return cached_contents
            
        except Exception as e:
            console.print(f"âŒ ìºì‹±ëœ content ë¡œë”© ì‹¤íŒ¨: {e}")
            return {}
    
    def _get_article_content(self, article_id: str) -> str:
        """articles í…Œì´ë¸”ì—ì„œ ì›ë³¸ content ì¡°íšŒ"""
        try:
            result = self.supabase.client.table('articles').select('content').eq('id', article_id).execute()
            if result.data:
                return result.data[0].get('content', '')
            return ''
        except Exception as e:
            console.print(f"âŒ ê¸°ì‚¬ ë‚´ìš© ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return ''
    
    def _classify_articles_by_bias_with_content(self, articles: list) -> dict:
        """ê¸°ì‚¬ë¥¼ ì„±í–¥ë³„ë¡œ ë¶„ë¥˜ (í†µí•© í•¨ìˆ˜ ì‚¬ìš©)"""
        unified = self._classify_articles_by_bias_unified(articles)
        return {
            'all': unified['all_merged'],
            'left': unified['left_content'],
            'center': unified['center_content'],
            'right': unified['right_content']
        }
    
    async def _generate_title_and_subtitle(self, articles: list) -> tuple:
        """ì œëª©ê³¼ ë¶€ì œëª© ìƒì„± (merged_content ê¸°ë°˜, ì œí•œ ì—†ìŒ)"""
        if not articles:
            return "ì •ì¹˜ ì´ìŠˆ", "ê¸°ì‚¬ ì—†ìŒ"
        
        # ëª¨ë“  ê¸°ì‚¬ì˜ ì œëª© ë¶€ë¶„ ì¶”ì¶œ (ì œí•œ ì—†ìŒ)
        titles = []
        for article_content in articles:  # ì œí•œ ì œê±°
            lines = article_content.split('\n')
            for line in lines:
                if line.startswith('ì œëª©:'):
                    title = line.replace('ì œëª©:', '').strip()
                    if title:
                        titles.append(title)
                    break
        
        if not titles:
            return "ì •ì¹˜ ì´ìŠˆ", f"{len(articles)}ê°œ ê¸°ì‚¬"
        
        titles_text = "\n".join(titles)
        prompt = f"""
ë‹¤ìŒ ì •ì¹˜ ë‰´ìŠ¤ ì œëª©ë“¤ì„ ë¶„ì„í•˜ì—¬ ì´ìŠˆ ì œëª©ê³¼ ë¶€ì œëª©ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”:

{titles_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
ì œëª©: [ê°„ê²°í•˜ê³  ëª…í™•í•œ ì´ìŠˆ ì œëª©]
ë¶€ì œëª©: [ì´ìŠˆì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª…]
"""
        
        try:
            response = self.openai_client.chat.completions.create(
                model=self.config["openai_model"],
                messages=[{"role": "user", "content": prompt}],
                max_tokens=500,  # í† í° ìˆ˜ ì¦ê°€
                temperature=0.7
            )
            
            content = response.choices[0].message.content.strip()
            lines = content.split('\n')
            
            title = "ì •ì¹˜ ì´ìŠˆ"
            subtitle = f"{len(articles)}ê°œ ê¸°ì‚¬"
            
            for line in lines:
                if line.startswith('ì œëª©:'):
                    title = line.replace('ì œëª©:', '').strip()
                elif line.startswith('ë¶€ì œëª©:'):
                    subtitle = line.replace('ë¶€ì œëª©:', '').strip()
            
            return title, subtitle
            
        except Exception as e:
            console.print(f"âŒ ì œëª©+ë¶€ì œëª© ìƒì„± ì‹¤íŒ¨: {e}")
            return "ì •ì¹˜ ì´ìŠˆ", f"{len(articles)}ê°œ ê¸°ì‚¬"
    
    async def _generate_summary(self, articles: list) -> str:
        """ê°„ê²°í•œ ìš”ì•½ ìƒì„± (ë°°ì¹˜ ì²˜ë¦¬)"""
        if not articles:
            return "ë‚´ìš© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        
        # ë°°ì¹˜ í¬ê¸° ì„¤ì • (í† í° ì œí•œ ê³ ë ¤)
        batch_size = self.config["summary_batch_size"]
        batches = [articles[i:i + batch_size] for i in range(0, len(articles), batch_size)]
        
        console.print(f"ğŸ“ ê°„ê²°í•œ ìš”ì•½ ìƒì„± ì¤‘... ({len(articles)}ê°œ ê¸°ì‚¬ë¥¼ {len(batches)}ê°œ ë°°ì¹˜ë¡œ ì²˜ë¦¬)")
        
        batch_summaries = []
        
        for i, batch in enumerate(batches):
            try:
                console.print(f"  ë°°ì¹˜ {i+1}/{len(batches)} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ ê¸°ì‚¬)")
                
                content_text = "\n\n".join(batch)
                prompt = f"""
ë‹¤ìŒ ì •ì¹˜ ë‰´ìŠ¤ë“¤ì„ ë¶„ì„í•˜ì—¬ ì´ìŠˆì˜ í•µì‹¬ ë‚´ìš©ì„ ê¸°ìŠ¹ì „ê²° êµ¬ì¡°ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:

{content_text}

ìš”ì•½: [ê¸°ìŠ¹ì „ê²° êµ¬ì¡°ì— ë§ì¶° 4-6ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±]
- ì„œë¡ : í•µì‹¬ ì‚¬ê±´ì˜ ë°°ê²½ê³¼ ìƒí™©
- ì „ê°œ: ì£¼ìš” ì „ê°œ ìƒí™©ê³¼ ì§„í–‰ ê³¼ì •  
- ì „í™˜: í•µì‹¬ ìŸì ê³¼ ê°ˆë“± ìš”ì†Œ
- ê²°ë¡ : í˜„ì¬ ìƒí™©ê³¼ í–¥í›„ ì „ë§

ë‹¨, "ê¸°/ìŠ¹/ì „/ê²°" ê°™ì€ ë ˆì´ë¸”ì€ ì‚¬ìš©í•˜ì§€ ë§ê³  ë…¼ë¦¬ì  íë¦„ë§Œ ë“œëŸ¬ë‚˜ë„ë¡ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
                
                response = self.openai_client.chat.completions.create(
                    model=self.config["openai_model"],
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=300,  # 150 â†’ 300ìœ¼ë¡œ ì¦ê°€ (ê¸°ìŠ¹ì „ê²° êµ¬ì¡°ë¥¼ ìœ„í•´)
                    temperature=0.7
                )
                
                content = response.choices[0].message.content.strip()
                if content.startswith('ìš”ì•½:'):
                    summary = content.replace('ìš”ì•½:', '').strip()
                else:
                    summary = content
                
                batch_summaries.append(summary)
                
                # API ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸°
                await asyncio.sleep(2)  # ëŒ€ê¸° ì‹œê°„ ì¦ê°€
                
            except Exception as e:
                console.print(f"âŒ ë°°ì¹˜ {i+1} ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
                batch_summaries.append(f"ë°°ì¹˜ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨")
        
        # ëª¨ë“  ë°°ì¹˜ ìš”ì•½ì„ ì¢…í•©
        if len(batch_summaries) == 1:
            return batch_summaries[0]
        
        try:
            combined_summaries = "\n\n".join(batch_summaries)
            final_prompt = f"""
ë‹¤ìŒ ìš”ì•½ë“¤ì„ ì¢…í•©í•˜ì—¬ í•˜ë‚˜ì˜ ê¸°ìŠ¹ì „ê²° êµ¬ì¡°ì˜ ì´ìŠˆ ìš”ì•½ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”:

{combined_summaries}

í†µí•© ìš”ì•½: [ê¸°ìŠ¹ì „ê²° êµ¬ì¡°ì— ë§ì¶° 4-6ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í†µí•©]
- ì„œë¡ : í•µì‹¬ ì‚¬ê±´ì˜ ë°°ê²½ê³¼ ìƒí™©
- ì „ê°œ: ì£¼ìš” ì „ê°œ ìƒí™©ê³¼ ì§„í–‰ ê³¼ì •
- ì „í™˜: í•µì‹¬ ìŸì ê³¼ ê°ˆë“± ìš”ì†Œ  
- ê²°ë¡ : í˜„ì¬ ìƒí™©ê³¼ í–¥í›„ ì „ë§

ë‹¨, "ê¸°/ìŠ¹/ì „/ê²°" ê°™ì€ ë ˆì´ë¸”ì€ ì‚¬ìš©í•˜ì§€ ë§ê³  ë…¼ë¦¬ì  íë¦„ë§Œ ë“œëŸ¬ë‚˜ë„ë¡ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
            
            response = self.openai_client.chat.completions.create(
                model=self.config["openai_model"],
                messages=[{"role": "user", "content": final_prompt}],
                max_tokens=400,  # 200 â†’ 400ìœ¼ë¡œ ì¦ê°€ (ê¸°ìŠ¹ì „ê²° êµ¬ì¡°ë¥¼ ìœ„í•´)
                temperature=0.7
            )
            
            content = response.choices[0].message.content.strip()
            if content.startswith('í†µí•© ìš”ì•½:'):
                return content.replace('í†µí•© ìš”ì•½:', '').strip()
            return content
            
        except Exception as e:
            console.print(f"âŒ í†µí•© ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return "\n".join(batch_summaries)
    
    async def _generate_bias_view(self, articles: list, bias_type: str) -> str:
        """ì„±í–¥ë³„ ê´€ì  ìƒì„± (ì§€ì§€/ì¤‘ë¦½/ë¹„íŒ ê´€ì  ëª…í™•í™”)"""
        if not articles:
            return ""
        
        # ë°°ì¹˜ í¬ê¸° ì„¤ì • (í† í° ì œí•œ ê³ ë ¤)
        batch_size = self.config["view_batch_size"]
        batches = [articles[i:i + batch_size] for i in range(0, len(articles), batch_size)]
        
        # ê´€ì  íƒ€ì… ë§¤í•‘
        view_type_mapping = {
            'ì§„ë³´ì ': 'ì§€ì§€',
            'ì¤‘ë„ì ': 'ì¤‘ë¦½', 
            'ë³´ìˆ˜ì ': 'ë¹„íŒ'
        }
        view_type = view_type_mapping.get(bias_type, bias_type)
        
        console.print(f"ğŸ“ {bias_type} ì„±í–¥ â†’ {view_type} ê´€ì  ìƒì„± ì¤‘... ({len(articles)}ê°œ ê¸°ì‚¬ë¥¼ {len(batches)}ê°œ ë°°ì¹˜ë¡œ ì²˜ë¦¬)")
        
        batch_views = []
        
        for i, batch in enumerate(batches):
            try:
                console.print(f"  {view_type} ê´€ì  ë°°ì¹˜ {i+1}/{len(batches)} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ ê¸°ì‚¬)")
                
                content_text = "\n\n".join(batch)
                prompt = f"""
ë‹¤ìŒ {bias_type} ì„±í–¥ì˜ ì–¸ë¡ ì‚¬ ê¸°ì‚¬ë“¤ì„ ë¶„ì„í•˜ì—¬ {view_type} ê´€ì ì—ì„œì˜ ì…ì¥ì„ ê¸°ìŠ¹ì „ê²° êµ¬ì¡°ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”:

{content_text}

{view_type} ê´€ì : [ê¸°ìŠ¹ì „ê²° êµ¬ì¡°ì— ë§ì¶° 4-5ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±]
- ì„œë¡ : {view_type} ê´€ì ì—ì„œ ë°”ë¼ë³¸ ì´ìŠˆì˜ í•µì‹¬ ì¸ì‹ê³¼ ê¸°ë³¸ ì…ì¥
- ì „ê°œ: {view_type} ê´€ì ì˜ í•µì‹¬ ë…¼ë¦¬ì™€ ê·¼ê±°, êµ¬ì²´ì  ë¶„ì„
- ì „í™˜: {view_type} ê´€ì ì—ì„œ ì œê¸°í•˜ëŠ” ì£¼ìš” ìŸì ê³¼ ë¹„íŒ/ì§€ì§€ ì‚¬í•­
- ê²°ë¡ : {view_type} ê´€ì ì˜ ëª…í™•í•œ ì…ì¥ê³¼ í–¥í›„ ë°©í–¥ì„±

ë‹¨, "ê¸°/ìŠ¹/ì „/ê²°" ê°™ì€ ë ˆì´ë¸”ì€ ì‚¬ìš©í•˜ì§€ ë§ê³  ë…¼ë¦¬ì  íë¦„ë§Œ ë“œëŸ¬ë‚˜ë„ë¡ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
{view_type} ê´€ì ì˜ ëšœë ·í•œ ëª©ì†Œë¦¬ì™€ ì£¼ì¥ì´ ëª…í™•íˆ ë“œëŸ¬ë‚˜ë„ë¡ í•´ì£¼ì„¸ìš”.
"""
                
                response = self.openai_client.chat.completions.create(
                    model=self.config["openai_model"],
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=400,  # 250 â†’ 400ìœ¼ë¡œ ì¦ê°€ (ê¸°ìŠ¹ì „ê²° êµ¬ì¡°ë¥¼ ìœ„í•´)
                    temperature=0.7
                )
                
                content = response.choices[0].message.content.strip()
                if content.startswith(f'{view_type} ê´€ì :'):
                    view = content.replace(f'{view_type} ê´€ì :', '').strip()
                else:
                    view = content
                
                batch_views.append(view)
                
                # API ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸°
                await asyncio.sleep(2)  # ëŒ€ê¸° ì‹œê°„ ì¦ê°€
                
            except Exception as e:
                console.print(f"âŒ {view_type} ê´€ì  ë°°ì¹˜ {i+1} ìƒì„± ì‹¤íŒ¨: {e}")
                batch_views.append(f"{view_type} ê´€ì  ë°°ì¹˜ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨")
        
        # ëª¨ë“  ë°°ì¹˜ ê´€ì ì„ ì¢…í•©
        if len(batch_views) == 1:
            return batch_views[0]
        
        try:
            combined_views = "\n\n".join(batch_views)
            final_prompt = f"""
ë‹¤ìŒ {view_type} ê´€ì ë“¤ì„ ì¢…í•©í•˜ì—¬ ê¸°ìŠ¹ì „ê²° êµ¬ì¡°ì˜ ì¼ê´€ëœ {view_type} ì…ì¥ì„ ì •ë¦¬í•´ì£¼ì„¸ìš”:

{combined_views}

í†µí•© {view_type} ê´€ì : [ê¸°ìŠ¹ì „ê²° êµ¬ì¡°ì— ë§ì¶° 4-5ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í†µí•©]
- ì„œë¡ : {view_type} ê´€ì ì—ì„œ ë°”ë¼ë³¸ ì´ìŠˆì˜ í•µì‹¬ ì¸ì‹ê³¼ ê¸°ë³¸ ì…ì¥
- ì „ê°œ: {view_type} ê´€ì ì˜ í•µì‹¬ ë…¼ë¦¬ì™€ ê·¼ê±°, êµ¬ì²´ì  ë¶„ì„
- ì „í™˜: {view_type} ê´€ì ì—ì„œ ì œê¸°í•˜ëŠ” ì£¼ìš” ìŸì ê³¼ ë¹„íŒ/ì§€ì§€ ì‚¬í•­
- ê²°ë¡ : {view_type} ê´€ì ì˜ ëª…í™•í•œ ì…ì¥ê³¼ í–¥í›„ ë°©í–¥ì„±

ë‹¨, "ê¸°/ìŠ¹/ì „/ê²°" ê°™ì€ ë ˆì´ë¸”ì€ ì‚¬ìš©í•˜ì§€ ë§ê³  ë…¼ë¦¬ì  íë¦„ë§Œ ë“œëŸ¬ë‚˜ë„ë¡ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
{view_type} ê´€ì ì˜ ëšœë ·í•œ ëª©ì†Œë¦¬ì™€ ì£¼ì¥ì´ ëª…í™•íˆ ë“œëŸ¬ë‚˜ë„ë¡ í•´ì£¼ì„¸ìš”.
"""
            
            response = self.openai_client.chat.completions.create(
                model=self.config["openai_model"],
                messages=[{"role": "user", "content": final_prompt}],
                max_tokens=500,  # 350 â†’ 500ìœ¼ë¡œ ì¦ê°€ (ê¸°ìŠ¹ì „ê²° êµ¬ì¡°ë¥¼ ìœ„í•´)
                temperature=0.7
            )
            
            content = response.choices[0].message.content.strip()
            if content.startswith(f'í†µí•© {view_type} ê´€ì :'):
                return content.replace(f'í†µí•© {view_type} ê´€ì :', '').strip()
            return content
            
        except Exception as e:
            console.print(f"âŒ í†µí•© {view_type} ê´€ì  ìƒì„± ì‹¤íŒ¨: {e}")
            return "\n".join(batch_views)
    
    async def generate_title_and_subtitle(self, cluster_info: dict) -> dict:
        """ì œëª©ê³¼ ë¶€ì œëª©ì„ LLMìœ¼ë¡œ ìƒì„±í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ê¸°ë³¸ê°’ ì„¤ì • - ê¸°ì‚¬ ë³¸ë¬¸ ê¸°ë°˜"""
        try:
            console.print(f"ğŸ¤– í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']} ì œëª©+ë¶€ì œëª© ìƒì„± ì¤‘...")
            
            # í´ëŸ¬ìŠ¤í„°ì˜ ê¸°ì‚¬ ë³¸ë¬¸ì—ì„œ ì œëª© ë¶€ë¶„ë§Œ ì¶”ì¶œ (ìµœëŒ€ ì„¤ì •ê°’ë§Œí¼)
            article_titles = []
            max_titles = 50  # í•˜ë“œì½”ë”©ìœ¼ë¡œ ì„ì‹œ ìˆ˜ì •
            
            for article in cluster_info['articles'][:max_titles]:
                merged_content = article.get('merged_content', '')
                if merged_content and merged_content.strip():
                    # merged_contentì—ì„œ ì œëª© ë¶€ë¶„ ì¶”ì¶œ ("ì œëª©: ..." í˜•ì‹)
                    lines = merged_content.split('\n')
                    for line in lines:
                        if line.startswith('ì œëª©:'):
                            title = line.replace('ì œëª©:', '').strip()
                            if title:
                                article_titles.append(title)
                            break
            
            if not article_titles:
                return {
                    'title': f"ì •ì¹˜ ì´ìŠˆ {cluster_info['cluster_id']}",
                    'subtitle': f"{cluster_info['size']}ê°œ ê¸°ì‚¬",
                    'summary': f"í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']}ì— ì†í•œ {cluster_info['size']}ê°œì˜ ê¸°ì‚¬ë“¤",
                    'left_view': "",
                    'center_view': "",
                    'right_view': ""
                }
            
            # ì œëª©ê³¼ ë¶€ì œëª© ìƒì„± í”„ë¡¬í”„íŠ¸
            titles_text = "\n".join(article_titles)
            prompt = f"""
ë‹¤ìŒ ì •ì¹˜ ë‰´ìŠ¤ ì œëª©ë“¤ì„ ë¶„ì„í•˜ì—¬ ì´ìŠˆ ì œëª©ê³¼ ë¶€ì œëª©ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”:

{titles_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
ì œëª©: [10-20ì ì´ë‚´ì˜ ê°„ê²°í•œ ì´ìŠˆ ì œëª©]
ë¶€ì œëª©: [ì´ìŠˆì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª…, 30ì ì´ë‚´]

ìš”êµ¬ì‚¬í•­:
- ì œëª©: í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨, ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ í‘œí˜„
- ë¶€ì œëª©: ì´ìŠˆì˜ í•µì‹¬ ë‚´ìš©ì„ ê°„ë‹¨íˆ ì„¤ëª…
"""
            
            # OpenAI API í˜¸ì¶œ
            response = self.openai_client.chat.completions.create(
                model=self.config["openai_model"],
                messages=[{"role": "user", "content": prompt}],
                max_tokens=100,
                temperature=0.7
            )
            
            content = response.choices[0].message.content.strip()
            
            # ì‘ë‹µ íŒŒì‹±
            lines = content.split('\n')
            title = f"ì •ì¹˜ ì´ìŠˆ {cluster_info['cluster_id']}"
            subtitle = f"{cluster_info['size']}ê°œ ê¸°ì‚¬"
            
            for line in lines:
                if line.startswith('ì œëª©:'):
                    title = line.replace('ì œëª©:', '').strip()
                elif line.startswith('ë¶€ì œëª©:'):
                    subtitle = line.replace('ë¶€ì œëª©:', '').strip()
            
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ë‚˜ë¨¸ì§€ í•„ë“œ ì„¤ì •
            return {
                'title': title,
                'subtitle': subtitle,
                'summary': f"í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']}ì— ì†í•œ {cluster_info['size']}ê°œì˜ ê¸°ì‚¬ë“¤",
                'left_view': "",
                'center_view': "",
                'right_view': ""
            }
            
        except Exception as e:
            console.print(f"âŒ ì œëª©+ë¶€ì œëª© ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'title': f"ì •ì¹˜ ì´ìŠˆ {cluster_info['cluster_id']}",
                'subtitle': f"{cluster_info['size']}ê°œ ê¸°ì‚¬",
                'summary': f"í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']}ì— ì†í•œ {cluster_info['size']}ê°œì˜ ê¸°ì‚¬ë“¤",
                'left_view': "",
                'center_view': "",
                'right_view': ""
            }
    
    def analyze_political_bias(self, cluster_info: dict) -> dict:
        """ì •ì¹˜ ì„±í–¥ ë¶„ì„ - config ê¸°ë°˜"""
        try:
            # ì–¸ë¡ ì‚¬ë³„ ê¸°ì‚¬ ìˆ˜
            media_counts = cluster_info.get('media_counts', {})
            
            # configì—ì„œ ì–¸ë¡ ì‚¬ ì„±í–¥ ë§¤í•‘ ê°€ì ¸ì˜¤ê¸°
            bias_mapping = self.config["media_bias_mapping"]
            left_media = bias_mapping['left']
            center_media = bias_mapping['center']
            right_media = bias_mapping['right']
            
            left_count = sum(media_counts.get(media_id, 0) for media_id in media_counts 
                           if self._get_media_name(media_id) in left_media)
            center_count = sum(media_counts.get(media_id, 0) for media_id in media_counts 
                             if self._get_media_name(media_id) in center_media)
            right_count = sum(media_counts.get(media_id, 0) for media_id in media_counts 
                            if self._get_media_name(media_id) in right_media)
            
            return {
                'left': left_count,
                'center': center_count,
                'right': right_count
            }
            
        except Exception as e:
            console.print(f"âŒ ì„±í–¥ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'left': 0, 'center': 0, 'right': 0}
    
    @lru_cache(maxsize=1000)
    def _get_media_name(self, media_id: int) -> str:
        """ì–¸ë¡ ì‚¬ IDë¡œ ì´ë¦„ ì¡°íšŒ (ìºì‹± ì ìš©)"""
        try:
            media = self.media_outlets[self.media_outlets['id'] == media_id]
            return media.iloc[0]['name'] if not media.empty else 'unknown'
        except:
            return 'unknown'
    
    async def save_issues_to_database(self) -> bool:
        """ì´ìŠˆë“¤ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ - source ê¸°ì¤€ ë­í‚¹ ì ìš©"""
        try:
            console.print("ğŸ’¾ ì´ìŠˆ ì €ì¥ ì¤‘...")
            
            # í´ëŸ¬ìŠ¤í„°ë¥¼ í¬ê¸°ìˆœìœ¼ë¡œ ì •ë ¬ (source ê¸°ì¤€)
            sorted_clusters = sorted(self.clusters_info, key=lambda x: x['size'], reverse=True)
            
            # source ê¸°ì¤€ 5ìœ„ê¹Œì§€ë§Œ ì²˜ë¦¬
            max_issues = self.config["max_issues"]
            top_issues_full = self.config["top_issues_full_content"]
            
            clusters_to_process = sorted_clusters[:max_issues]
            console.print(f"ğŸ“Š ì²˜ë¦¬ ëŒ€ìƒ: {len(clusters_to_process)}ê°œ í´ëŸ¬ìŠ¤í„° (source ê¸°ì¤€ {max_issues}ìœ„ê¹Œì§€)")
            
            saved_count = 0
            
            for i, cluster_info in enumerate(clusters_to_process):
                is_top_ranked = (i < top_issues_full)  # 5ìœ„ê¹Œì§€ëŠ” ì „ì²´ ë‚´ìš© ìƒì„±
                
                if is_top_ranked:
                    # 5ìœ„ê¹Œì§€: ì „ì²´ ë‚´ìš© + ê´€ì  LLM ìƒì„±
                    console.print(f"ğŸ¤– í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']} (ìˆœìœ„ {i+1}) - ì „ì²´ ë‚´ìš© + ê´€ì  ìƒì„±")
                    issue_content = await self.generate_issue_content(cluster_info)
                else:
                    # 6ìœ„ ì´í›„: ì œëª©, ë¶€ì œëª©, ìš”ì•½ë§Œ ìƒì„±
                    console.print(f"ğŸ¤– í´ëŸ¬ìŠ¤í„° {cluster_info['cluster_id']} (ìˆœìœ„ {i+1}) - ì œëª©+ë¶€ì œëª©ë§Œ ìƒì„±")
                    issue_content = await self.generate_title_and_subtitle(cluster_info)
                
                # ì •ì¹˜ ì„±í–¥ ë¶„ì„
                bias_analysis = self.analyze_political_bias(cluster_info)
                
                # ì´ìŠˆ ë°ì´í„° êµ¬ì„±
                issue_data = {
                    'title': issue_content['title'],
                    'subtitle': issue_content['subtitle'],
                    'summary': issue_content['summary'],
                    'left_source': str(bias_analysis['left']),
                    'center_source': str(bias_analysis['center']),
                    'right_source': str(bias_analysis['right']),
                    'source': str(cluster_info['size']),
                    'date': datetime.now().date().isoformat()
                }
                
                # 5ìœ„ê¹Œì§€ë§Œ ê´€ì  ì •ë³´ ì¶”ê°€
                if is_top_ranked:
                    issue_data.update({
                        'left_view': issue_content.get('left_view', ''),
                        'center_view': issue_content.get('center_view', ''),
                        'right_view': issue_content.get('right_view', '')
                    })
                else:
                    # 6ìœ„ ì´í›„ëŠ” ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •
                    issue_data.update({
                        'left_view': '',
                        'center_view': '',
                        'right_view': ''
                    })
                
                # ì´ìŠˆ ì €ì¥
                issue_result = self.supabase.client.table('issues').insert(issue_data).execute()
                
                if issue_result.data:
                    issue_id = issue_result.data[0]['id']
                    
                    # issue_articles ë§¤í•‘ ì €ì¥ (ì›ë³¸ articlesì˜ id ì‚¬ìš©)
                    for article in cluster_info['articles']:
                        mapping_data = {
                            'issue_id': issue_id,
                            'article_id': article['article_id'],  # ì›ë³¸ articlesì˜ id ì‚¬ìš©
                            'stance': 'center'
                        }
                        self.supabase.client.table('issue_articles').insert(mapping_data).execute()
                    
                    saved_count += 1
            
            console.print(f"âœ… ì´ìŠˆ ì €ì¥ ì™„ë£Œ: {saved_count}ê°œ")
            console.print(f"   - 1-{top_issues_full}ìœ„: ì „ì²´ ë‚´ìš© + ê´€ì  ìƒì„±")
            console.print(f"   - ëª¨ë“  ì´ìŠˆ: ì§€ì§€/ì¤‘ë¦½/ë¹„íŒ ê´€ì  ëª…í™•í™”")
            return True
            
        except Exception as e:
            console.print(f"âŒ ì´ìŠˆ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False