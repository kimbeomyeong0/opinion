#!/usr/bin/env python3
"""
í•˜ì´ë¸Œë¦¬ë“œ ìœ ì‚¬ë„ ê³„ì‚° ìœ í‹¸ë¦¬í‹°
- ë‹¨ê³„ë³„ ì¤‘ë³µ ê²€ì‚¬ë¡œ ì„±ëŠ¥ ìµœì í™”
- í•´ì‹œ ê¸°ë°˜ ì •í™•í•œ ì¤‘ë³µ + ì œëª©/ë¦¬ë“œ ê¸°ë°˜ ë¹ ë¥¸ ì¤‘ë³µ
- O(n) ì‹œê°„ ë³µì¡ë„ë¡œ ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬
"""

import re
import difflib
import hashlib
from typing import List, Tuple, Optional, Dict, Set
from dataclasses import dataclass

@dataclass
class SimilarityResult:
    """ìœ ì‚¬ë„ ê³„ì‚° ê²°ê³¼"""
    similarity_score: float
    is_duplicate: bool
    similarity_type: str  # 'title' or 'content'
    threshold: float

class SimilarityCalculator:
    """ìœ ì‚¬ë„ ê³„ì‚° í´ë˜ìŠ¤"""
    
    def __init__(self, title_threshold: float = 1.0, content_threshold: float = 0.95):
        """
        ì´ˆê¸°í™”
        
        Args:
            title_threshold: ì œëª© ìœ ì‚¬ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 1.0 = ì •í™•í•œ ë§¤ì¹­)
            content_threshold: ë³¸ë¬¸ ìœ ì‚¬ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.95)
        """
        self.title_threshold = title_threshold
        self.content_threshold = content_threshold
    
    def normalize_text(self, text: str) -> str:
        """
        í…ìŠ¤íŠ¸ ì •ê·œí™”
        
        Args:
            text: ì •ê·œí™”í•  í…ìŠ¤íŠ¸
            
        Returns:
            ì •ê·œí™”ëœ í…ìŠ¤íŠ¸
        """
        if not text:
            return ""
        
        # ê³µë°± ì •ê·œí™”
        text = re.sub(r'\s+', ' ', text.strip())
        
        # íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™”
        text = re.sub(r'[^\w\sê°€-í£]', '', text)
        
        # ì†Œë¬¸ì ë³€í™˜ (ì˜ë¬¸ì˜ ê²½ìš°)
        text = text.lower()
        
        return text
    
    def calculate_title_similarity(self, title1: str, title2: str) -> SimilarityResult:
        """
        ì œëª© ìœ ì‚¬ë„ ê³„ì‚°
        
        Args:
            title1: ì²« ë²ˆì§¸ ì œëª©
            title2: ë‘ ë²ˆì§¸ ì œëª©
            
        Returns:
            ìœ ì‚¬ë„ ê³„ì‚° ê²°ê³¼
        """
        if not title1 or not title2:
            return SimilarityResult(0.0, False, 'title', self.title_threshold)
        
        # í…ìŠ¤íŠ¸ ì •ê·œí™”
        norm_title1 = self.normalize_text(title1)
        norm_title2 = self.normalize_text(title2)
        
        # ì •í™•í•œ ë§¤ì¹­ í™•ì¸
        if norm_title1 == norm_title2:
            return SimilarityResult(1.0, True, 'title', self.title_threshold)
        
        # difflibì„ ì‚¬ìš©í•œ ìœ ì‚¬ë„ ê³„ì‚°
        similarity = difflib.SequenceMatcher(None, norm_title1, norm_title2).ratio()
        
        return SimilarityResult(
            similarity_score=similarity,
            is_duplicate=similarity >= self.title_threshold,
            similarity_type='title',
            threshold=self.title_threshold
        )
    
    def calculate_content_similarity(self, content1: str, content2: str) -> SimilarityResult:
        """
        ë³¸ë¬¸ ìœ ì‚¬ë„ ê³„ì‚°
        
        Args:
            content1: ì²« ë²ˆì§¸ ë³¸ë¬¸
            content2: ë‘ ë²ˆì§¸ ë³¸ë¬¸
            
        Returns:
            ìœ ì‚¬ë„ ê³„ì‚° ê²°ê³¼
        """
        if not content1 or not content2:
            return SimilarityResult(0.0, False, 'content', self.content_threshold)
        
        # í…ìŠ¤íŠ¸ ì •ê·œí™”
        norm_content1 = self.normalize_text(content1)
        norm_content2 = self.normalize_text(content2)
        
        # ë¹ˆ ë¬¸ìì—´ì´ë‚˜ ê³µë°±ë§Œ ìˆëŠ” ê²½ìš°ë§Œ ì œì™¸
        if not norm_content1.strip() or not norm_content2.strip():
            return SimilarityResult(0.0, False, 'content', self.content_threshold)
        
        # difflibì„ ì‚¬ìš©í•œ ìœ ì‚¬ë„ ê³„ì‚°
        similarity = difflib.SequenceMatcher(None, norm_content1, norm_content2).ratio()
        
        return SimilarityResult(
            similarity_score=similarity,
            is_duplicate=similarity >= self.content_threshold,
            similarity_type='content',
            threshold=self.content_threshold
        )
    
    def find_duplicate_titles(self, articles: List[dict]) -> List[Tuple[int, int, SimilarityResult]]:
        """
        ì¤‘ë³µ ì œëª© ì°¾ê¸°
        
        Args:
            articles: ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì¤‘ë³µ ì œëª© ìŒ ë¦¬ìŠ¤íŠ¸ [(ì¸ë±ìŠ¤1, ì¸ë±ìŠ¤2, ìœ ì‚¬ë„ê²°ê³¼), ...]
        """
        duplicates = []
        
        for i in range(len(articles)):
            for j in range(i + 1, len(articles)):
                title1 = articles[i].get('title', '')
                title2 = articles[j].get('title', '')
                
                similarity_result = self.calculate_title_similarity(title1, title2)
                
                if similarity_result.is_duplicate:
                    duplicates.append((i, j, similarity_result))
        
        return duplicates
    
    def find_duplicate_contents(self, articles: List[dict]) -> List[Tuple[int, int, SimilarityResult]]:
        """
        ì¤‘ë³µ ë³¸ë¬¸ ì°¾ê¸° (ìµœì í™”ë¨)
        
        Args:
            articles: ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì¤‘ë³µ ë³¸ë¬¸ ìŒ ë¦¬ìŠ¤íŠ¸ [(ì¸ë±ìŠ¤1, ì¸ë±ìŠ¤2, ìœ ì‚¬ë„ê²°ê³¼), ...]
        """
        duplicates = []
        total_comparisons = len(articles) * (len(articles) - 1) // 2
        current_comparison = 0
        
        # ì§„í–‰ ìƒí™© ì¶œë ¥ì„ ìœ„í•œ ì²´í¬í¬ì¸íŠ¸
        progress_checkpoints = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
        checkpoint_index = 0
        
        # ë³¸ë¬¸ì´ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ì€ ê¸°ì‚¬ë“¤ì€ ë¯¸ë¦¬ ì œì™¸
        valid_articles = []
        for i, article in enumerate(articles):
            content = article.get('content', '')
            if content and len(content.strip()) > 50:  # ìµœì†Œ ê¸¸ì´ ì²´í¬
                valid_articles.append((i, article, self.normalize_text(content)))
        
        print(f"ğŸ“Š ìœ ì‚¬ë„ ë¹„êµ ëŒ€ìƒ: {len(valid_articles)}/{len(articles)}ê°œ ê¸°ì‚¬")
        
        for i in range(len(valid_articles)):
            for j in range(i + 1, len(valid_articles)):
                idx1, article1, norm_content1 = valid_articles[i]
                idx2, article2, norm_content2 = valid_articles[j]
                
                # ë¹ ë¥¸ ì‚¬ì „ í•„í„°ë§: ê¸¸ì´ ì°¨ì´ê°€ ë„ˆë¬´ í¬ë©´ ìŠ¤í‚µ
                len_diff = abs(len(norm_content1) - len(norm_content2))
                if len_diff > max(len(norm_content1), len(norm_content2)) * 0.5:
                    current_comparison += 1
                    continue
                
                # difflibì„ ì‚¬ìš©í•œ ìœ ì‚¬ë„ ê³„ì‚°
                similarity = difflib.SequenceMatcher(None, norm_content1, norm_content2).ratio()
                
                similarity_result = SimilarityResult(
                    similarity_score=similarity,
                    is_duplicate=similarity >= self.content_threshold,
                    similarity_type='content',
                    threshold=self.content_threshold
                )
                
                if similarity_result.is_duplicate:
                    duplicates.append((idx1, idx2, similarity_result))
                
                current_comparison += 1
                
                # ì§„í–‰ ìƒí™© ì¶œë ¥
                if checkpoint_index < len(progress_checkpoints):
                    progress = current_comparison / total_comparisons
                    if progress >= progress_checkpoints[checkpoint_index]:
                        print(f"ğŸ” ë³¸ë¬¸ ìœ ì‚¬ë„ ê³„ì‚° ì§„í–‰: {progress_checkpoints[checkpoint_index]*100:.0f}% ({current_comparison:,}/{total_comparisons:,})")
                        checkpoint_index += 1
        
        return duplicates
    
    def find_exact_duplicates(self, articles: List[dict]) -> List[Tuple[int, int, SimilarityResult]]:
        """
        í•´ì‹œ ê¸°ë°˜ ì •í™•í•œ ì¤‘ë³µ ì°¾ê¸° (O(n))
        
        Args:
            articles: ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì •í™•í•œ ì¤‘ë³µ ìŒ ë¦¬ìŠ¤íŠ¸
        """
        content_hashes = {}
        duplicates = []
        
        print("ğŸ” 1ë‹¨ê³„: í•´ì‹œ ê¸°ë°˜ ì •í™•í•œ ì¤‘ë³µ ê²€ì‚¬...")
        
        for i, article in enumerate(articles):
            content = article.get('content', '')
            if not content.strip():
                continue
                
            # ì •ê·œí™”ëœ ë³¸ë¬¸ìœ¼ë¡œ í•´ì‹œ ìƒì„±
            normalized_content = self.normalize_text(content)
            if len(normalized_content) < 50:  # ë„ˆë¬´ ì§§ì€ ë³¸ë¬¸ ì œì™¸
                continue
                
            content_hash = hashlib.md5(normalized_content.encode('utf-8')).hexdigest()
            
            if content_hash in content_hashes:
                # ì •í™•í•œ ì¤‘ë³µ ë°œê²¬
                original_idx = content_hashes[content_hash]
                similarity_result = SimilarityResult(
                    similarity_score=1.0,
                    is_duplicate=True,
                    similarity_type='exact_content',
                    threshold=1.0
                )
                duplicates.append((original_idx, i, similarity_result))
            else:
                content_hashes[content_hash] = i
        
        print(f"âœ… ì •í™•í•œ ì¤‘ë³µ {len(duplicates)}ê°œ ë°œê²¬")
        return duplicates
    
    def find_signature_duplicates(self, articles: List[dict], excluded_indices: Set[int]) -> List[Tuple[int, int, SimilarityResult]]:
        """
        ì œëª© + ë¦¬ë“œ ë¬¸ë‹¨ ê¸°ë°˜ ë¹ ë¥¸ ì¤‘ë³µ ì°¾ê¸° (O(n))
        
        Args:
            articles: ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
            excluded_indices: ì´ë¯¸ ì¤‘ë³µìœ¼ë¡œ íŒì •ëœ ì¸ë±ìŠ¤ë“¤ (ì œì™¸)
            
        Returns:
            ì‹œê·¸ë‹ˆì²˜ ê¸°ë°˜ ì¤‘ë³µ ìŒ ë¦¬ìŠ¤íŠ¸
        """
        signatures = {}
        duplicates = []
        
        print("ğŸ” 2ë‹¨ê³„: ì œëª©+ë¦¬ë“œ ê¸°ë°˜ ë¹ ë¥¸ ì¤‘ë³µ ê²€ì‚¬...")
        
        for i, article in enumerate(articles):
            if i in excluded_indices:
                continue
                
            title = article.get('title', '').strip()
            content = article.get('content', '').strip()
            
            if not title and not content:
                continue
            
            # ì‹œê·¸ë‹ˆì²˜ ìƒì„±: ì œëª© + ë³¸ë¬¸ ì²« 200ì
            lead_content = content[:200] if content else ""
            signature_text = f"{title}|{lead_content}"
            normalized_signature = self.normalize_text(signature_text)
            
            if len(normalized_signature) < 20:  # ë„ˆë¬´ ì§§ì€ ì‹œê·¸ë‹ˆì²˜ ì œì™¸
                continue
            
            # ì‹œê·¸ë‹ˆì²˜ í•´ì‹œ ìƒì„±
            signature_hash = hashlib.md5(normalized_signature.encode('utf-8')).hexdigest()
            
            if signature_hash in signatures:
                # ì‹œê·¸ë‹ˆì²˜ ì¤‘ë³µ ë°œê²¬
                original_idx = signatures[signature_hash]
                
                # ì‹¤ì œ ìœ ì‚¬ë„ ê³„ì‚°ìœ¼ë¡œ ê²€ì¦
                similarity_result = self.calculate_content_similarity(
                    articles[original_idx].get('content', ''),
                    content
                )
                
                # ì„ê³„ê°’ ì´ìƒì´ë©´ ì¤‘ë³µìœ¼ë¡œ íŒì •
                if similarity_result.similarity_score >= 0.8:  # ì‹œê·¸ë‹ˆì²˜ëŠ” ì¢€ ë” ê´€ëŒ€í•˜ê²Œ
                    similarity_result.similarity_type = 'signature_content'
                    duplicates.append((original_idx, i, similarity_result))
            else:
                signatures[signature_hash] = i
        
        print(f"âœ… ì‹œê·¸ë‹ˆì²˜ ì¤‘ë³µ {len(duplicates)}ê°œ ë°œê²¬")
        return duplicates
    
    def find_title_length_duplicates(self, articles: List[dict], excluded_indices: Set[int]) -> List[Tuple[int, int, SimilarityResult]]:
        """
        ì œëª© ê¸¸ì´ + í‚¤ì›Œë“œ ê¸°ë°˜ ì˜ì‹¬ ì¤‘ë³µ ì°¾ê¸° (O(n))
        
        Args:
            articles: ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
            excluded_indices: ì´ë¯¸ ì¤‘ë³µìœ¼ë¡œ íŒì •ëœ ì¸ë±ìŠ¤ë“¤ (ì œì™¸)
            
        Returns:
            ê¸¸ì´ ê¸°ë°˜ ì˜ì‹¬ ì¤‘ë³µ ìŒ ë¦¬ìŠ¤íŠ¸
        """
        length_groups = {}
        duplicates = []
        
        print("ğŸ” 3ë‹¨ê³„: ì œëª© ê¸¸ì´ ê¸°ë°˜ ì˜ì‹¬ ì¤‘ë³µ ê²€ì‚¬...")
        
        # ê¸¸ì´ë³„ ê·¸ë£¹í™”
        for i, article in enumerate(articles):
            if i in excluded_indices:
                continue
                
            title = article.get('title', '').strip()
            content = article.get('content', '').strip()
            
            if not content or len(content) < 100:
                continue
            
            # ë³¸ë¬¸ ê¸¸ì´ë¥¼ 100ì ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”
            content_length_bucket = len(content) // 100
            
            if content_length_bucket not in length_groups:
                length_groups[content_length_bucket] = []
            
            length_groups[content_length_bucket].append((i, article))
        
        # ê° ê¸¸ì´ ê·¸ë£¹ ë‚´ì—ì„œ ì œëª© ìœ ì‚¬ë„ ê²€ì‚¬
        total_suspicious = 0
        for length_bucket, group in length_groups.items():
            if len(group) < 2:
                continue
                
            # ê·¸ë£¹ ë‚´ì—ì„œë§Œ ì œëª© ë¹„êµ (O(nÂ²)ì´ì§€ë§Œ ê·¸ë£¹ í¬ê¸°ê°€ ì‘ìŒ)
            for i in range(len(group)):
                for j in range(i + 1, len(group)):
                    idx1, article1 = group[i]
                    idx2, article2 = group[j]
                    
                    title1 = article1.get('title', '')
                    title2 = article2.get('title', '')
                    
                    # ì œëª© ìœ ì‚¬ë„ ê²€ì‚¬
                    title_similarity = self.calculate_title_similarity(title1, title2)
                    
                    # ì œëª©ì´ ë§¤ìš° ìœ ì‚¬í•˜ë©´ ë³¸ë¬¸ë„ ê²€ì‚¬
                    if title_similarity.similarity_score >= 0.7:
                        content_similarity = self.calculate_content_similarity(
                            article1.get('content', ''),
                            article2.get('content', '')
                        )
                        
                        if content_similarity.is_duplicate:
                            content_similarity.similarity_type = 'length_group_content'
                            duplicates.append((idx1, idx2, content_similarity))
                            total_suspicious += 1
        
        print(f"âœ… ê¸¸ì´ ê·¸ë£¹ ê¸°ë°˜ ì¤‘ë³µ {len(duplicates)}ê°œ ë°œê²¬")
        return duplicates
    
    def find_hybrid_duplicates(self, articles: List[dict]) -> List[Tuple[int, int, SimilarityResult]]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ì¤‘ë³µ ê²€ì‚¬ (ë‹¨ê³„ë³„ ì ‘ê·¼)
        
        Args:
            articles: ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ëª¨ë“  ì¤‘ë³µ ìŒ ë¦¬ìŠ¤íŠ¸
        """
        print(f"ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ì¤‘ë³µ ê²€ì‚¬ ì‹œì‘ ({len(articles)}ê°œ ê¸°ì‚¬)")
        print("=" * 50)
        
        all_duplicates = []
        excluded_indices = set()
        
        # 1ë‹¨ê³„: í•´ì‹œ ê¸°ë°˜ ì •í™•í•œ ì¤‘ë³µ
        exact_duplicates = self.find_exact_duplicates(articles)
        all_duplicates.extend(exact_duplicates)
        
        # ì¤‘ë³µìœ¼ë¡œ íŒì •ëœ ê¸°ì‚¬ë“¤ì„ ì œì™¸ ëª©ë¡ì— ì¶”ê°€
        for _, duplicate_idx, _ in exact_duplicates:
            excluded_indices.add(duplicate_idx)
        
        # 2ë‹¨ê³„: ì‹œê·¸ë‹ˆì²˜ ê¸°ë°˜ ë¹ ë¥¸ ì¤‘ë³µ
        signature_duplicates = self.find_signature_duplicates(articles, excluded_indices)
        all_duplicates.extend(signature_duplicates)
        
        # ì¶”ê°€ë¡œ ì¤‘ë³µ íŒì •ëœ ê¸°ì‚¬ë“¤ì„ ì œì™¸ ëª©ë¡ì— ì¶”ê°€
        for _, duplicate_idx, _ in signature_duplicates:
            excluded_indices.add(duplicate_idx)
        
        # 3ë‹¨ê³„: ê¸¸ì´ ê·¸ë£¹ ê¸°ë°˜ ì˜ì‹¬ ì¤‘ë³µ (ì„ íƒì )
        if len(articles) - len(excluded_indices) < 500:  # ë‚¨ì€ ê¸°ì‚¬ê°€ ì ìœ¼ë©´ ì •ë°€ ê²€ì‚¬
            length_duplicates = self.find_title_length_duplicates(articles, excluded_indices)
            all_duplicates.extend(length_duplicates)
        
        print("=" * 50)
        print(f"ğŸ¯ ì´ {len(all_duplicates)}ê°œ ì¤‘ë³µ ë°œê²¬")
        print(f"ğŸ“Š ì œì™¸ëœ ê¸°ì‚¬: {len(excluded_indices)}ê°œ")
        print(f"ğŸ“Š ìœ ì§€ë  ê¸°ì‚¬: {len(articles) - len(excluded_indices)}ê°œ")
        
        return all_duplicates
    
    def find_all_duplicates(self, articles: List[dict]) -> dict:
        """
        ëª¨ë“  ì¤‘ë³µ ì°¾ê¸°
        
        Args:
            articles: ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì¤‘ë³µ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        title_duplicates = self.find_duplicate_titles(articles)
        content_duplicates = self.find_duplicate_contents(articles)
        
        return {
            'title_duplicates': title_duplicates,
            'content_duplicates': content_duplicates,
            'total_title_duplicates': len(title_duplicates),
            'total_content_duplicates': len(content_duplicates)
        }

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_articles = [
        {
            'id': 1,
            'title': 'ì •ì¹˜ ë‰´ìŠ¤ 1',
            'content': 'ì´ê²ƒì€ ì •ì¹˜ ë‰´ìŠ¤ ë‚´ìš©ì…ë‹ˆë‹¤.',
            'published_at': '2024-01-01'
        },
        {
            'id': 2,
            'title': 'ì •ì¹˜ ë‰´ìŠ¤ 1',  # ì¤‘ë³µ ì œëª©
            'content': 'ì´ê²ƒì€ ë‹¤ë¥¸ ì •ì¹˜ ë‰´ìŠ¤ ë‚´ìš©ì…ë‹ˆë‹¤.',
            'published_at': '2024-01-02'
        },
        {
            'id': 3,
            'title': 'ê²½ì œ ë‰´ìŠ¤ 1',
            'content': 'ì´ê²ƒì€ ì •ì¹˜ ë‰´ìŠ¤ ë‚´ìš©ì…ë‹ˆë‹¤.',  # ì¤‘ë³µ ë³¸ë¬¸
            'published_at': '2024-01-03'
        }
    ]
    
    # ìœ ì‚¬ë„ ê³„ì‚°ê¸° ìƒì„±
    calculator = SimilarityCalculator()
    
    # ì¤‘ë³µ ì°¾ê¸°
    duplicates = calculator.find_all_duplicates(test_articles)
    
    print("ì¤‘ë³µ ì œëª©:", duplicates['title_duplicates'])
    print("ì¤‘ë³µ ë³¸ë¬¸:", duplicates['content_duplicates'])
