#!/usr/bin/env python3
"""
ë‹¨ìˆœí™”ëœ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ - KISS ì›ì¹™ ì ìš©
ë³µì¡í•œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ê³¼ ê³¼ë„í•œ ê¸°ëŠ¥ì„ ì œê±°í•˜ê³  í•µì‹¬ ê¸°ëŠ¥ë§Œ ìœ ì§€
"""

import sys
import os
import time
from datetime import datetime, timedelta
import pytz
from typing import Dict, List, Any, Optional
from rich.console import Console
from rich.panel import Panel

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from utils.supabase_manager import SupabaseManager
from preprocessing.modules.duplicate_remover import IntegratedPreprocessor
from preprocessing.modules.text_cleaner import TextCleaner
from preprocessing.modules.text_normalizer import TextNormalizer
from preprocessing.modules.content_merger import ContentMerger

console = Console()

def get_kct_to_utc_range(date_filter):
    """KCT ê¸°ì¤€ ë‚ ì§œ í•„í„°ë¥¼ UTC ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
    
    Args:
        date_filter: 'yesterday', 'today', None
        
    Returns:
        tuple: (start_utc, end_utc) ë˜ëŠ” None
    """
    if not date_filter:
        return None
    
    # ì‹œê°„ëŒ€ ì„¤ì •
    kct = pytz.timezone('Asia/Seoul')
    utc = pytz.UTC
    
    if date_filter == 'yesterday':
        # KCT ê¸°ì¤€ ì „ë‚  00:00-23:59
        kct_yesterday = datetime.now(kct).replace(hour=0, minute=0, second=0, microsecond=0) - timedelta(days=1)
        kct_start = kct_yesterday
        kct_end = kct_yesterday.replace(hour=23, minute=59, second=59, microsecond=999999)
        
        # UTCë¡œ ë³€í™˜
        utc_start = kct_start.astimezone(utc)
        utc_end = kct_end.astimezone(utc)
        
    elif date_filter == 'today':
        # KCT ê¸°ì¤€ ì˜¤ëŠ˜ 00:00-í˜„ì¬
        kct_today = datetime.now(kct).replace(hour=0, minute=0, second=0, microsecond=0)
        kct_start = kct_today
        kct_end = datetime.now(kct)
        
        # UTCë¡œ ë³€í™˜
        utc_start = kct_start.astimezone(utc)
        utc_end = kct_end.astimezone(utc)
    
    else:
        return None
    
    return utc_start, utc_end

class SimplePreprocessingPipeline:
    """ë‹¨ìˆœí™”ëœ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ - í•µì‹¬ ê¸°ëŠ¥ë§Œ ìœ ì§€"""
    
    def __init__(self, date_filter=None):
        """ì´ˆê¸°í™”
        
        Args:
            date_filter: ë‚ ì§œ í•„í„° ì˜µì…˜
                - None: ì „ì²´ ê¸°ì‚¬
                - 'yesterday': ì „ë‚  ê¸°ì‚¬ë§Œ (KCT ê¸°ì¤€ 00:00-23:59)
                - 'today': ì˜¤ëŠ˜ ê¸°ì‚¬ë§Œ
        """
        self.supabase_manager = SupabaseManager()
        self.date_filter = date_filter
        
        # ê° ëª¨ë“ˆ ì´ˆê¸°í™”
        self.duplicate_processor = IntegratedPreprocessor(date_filter=self.date_filter)
        self.text_cleaner = TextCleaner()
        self.text_normalizer = TextNormalizer()
        self.content_merger = ContentMerger()
        
        # ë‹¨ê³„ë³„ ì •ì˜
        self.stages = {
            'duplicate_removal': '1ë‹¨ê³„: ì¤‘ë³µ ì œê±° + ê¸°ë³¸ í•„í„°ë§',
            'text_cleaning': '2ë‹¨ê³„: í…ìŠ¤íŠ¸ ì •ì œ',
            'text_normalization': '3ë‹¨ê³„: í…ìŠ¤íŠ¸ ì •ê·œí™”',
            'content_merging': '4ë‹¨ê³„: ì œëª©+ë³¸ë¬¸ í†µí•©'
        }
    
    def get_pipeline_status(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ í˜„ì¬ ìƒíƒœ ì¡°íšŒ"""
        try:
            if not self.supabase_manager.client:
                return {'pipeline_ready': False, 'error': 'Supabase client not initialized'}
            
            # ë‚ ì§œ í•„í„° ì ìš©ëœ ê¸°ì‚¬ ìˆ˜ ì¡°íšŒ
            if self.date_filter:
                utc_start, utc_end = get_kct_to_utc_range(self.date_filter)
                if utc_start and utc_end:
                    articles_total = self.supabase_manager.client.table('articles').select('id', count='exact').gte('published_at', utc_start.isoformat()).lte('published_at', utc_end.isoformat()).execute()
                else:
                    articles_total = self.supabase_manager.client.table('articles').select('id', count='exact').execute()
            else:
                articles_total = self.supabase_manager.client.table('articles').select('id', count='exact').execute()
            
            articles_preprocessed = self.supabase_manager.client.table('articles').select('id', count='exact').eq('is_preprocessed', True).execute()
            cleaned_result = self.supabase_manager.client.table('articles_cleaned').select('id', count='exact').execute()
            merged_count = self.supabase_manager.client.table('articles_cleaned').select('id', count='exact').not_.is_('merged_content', 'null').execute()
            
            return {
                'articles_total': articles_total.count if articles_total else 0,
                'articles_preprocessed': articles_preprocessed.count if articles_preprocessed else 0,
                'cleaned_articles': cleaned_result.count if cleaned_result else 0,
                'merged_articles': merged_count.count if merged_count else 0,
                'pipeline_ready': True
            }
            
        except Exception as e:
            console.print(f"âŒ íŒŒì´í”„ë¼ì¸ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {'pipeline_ready': False, 'error': str(e)}
    
    def run_stage_1_duplicate_removal(self) -> bool:
        """1ë‹¨ê³„: ì¤‘ë³µ ì œê±° + ê¸°ë³¸ í•„í„°ë§"""
        try:
            console.print("ğŸ”„ 1ë‹¨ê³„: ì¤‘ë³µ ì œê±° + ê¸°ë³¸ í•„í„°ë§ ì‹œì‘")
            
            result = self.duplicate_processor.process_integrated_preprocessing()
            
            if result.success:
                console.print(f"âœ… 1ë‹¨ê³„ ì™„ë£Œ: {result.final_articles}ê°œ ê¸°ì‚¬ ì²˜ë¦¬ë¨")
                return True
            else:
                console.print(f"âŒ 1ë‹¨ê³„ ì‹¤íŒ¨: {result.error_message}")
                return False
                
        except Exception as e:
            console.print(f"âŒ 1ë‹¨ê³„ ì˜ˆì™¸ ë°œìƒ: {e}")
            return False
    
    def run_stage_2_text_cleaning(self) -> bool:
        """2ë‹¨ê³„: í…ìŠ¤íŠ¸ ì •ì œ"""
        try:
            console.print("ğŸ”„ 2ë‹¨ê³„: í…ìŠ¤íŠ¸ ì •ì œ ì‹œì‘")
            
            # ì •ì œë˜ì§€ ì•Šì€ ê¸°ì‚¬ë“¤ì„ ì¡°íšŒ
            articles = self._fetch_articles_for_cleaning()
            
            if not articles:
                console.print("âœ… 2ë‹¨ê³„: ì •ì œí•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤")
                return True
            
            # ë°°ì¹˜ ì²˜ë¦¬ë¡œ í…ìŠ¤íŠ¸ ì •ì œ ì‹¤í–‰
            processed_count, failed_count = self._process_articles_batch(
                articles, self._clean_single_article
            )
            
            console.print(f"âœ… 2ë‹¨ê³„ ì™„ë£Œ: {processed_count}ê°œ ì •ì œ, {failed_count}ê°œ ì‹¤íŒ¨")
            return True
            
        except Exception as e:
            console.print(f"âŒ 2ë‹¨ê³„ ì˜ˆì™¸ ë°œìƒ: {e}")
            return False
    
    def run_stage_3_text_normalization(self) -> bool:
        """3ë‹¨ê³„: í…ìŠ¤íŠ¸ ì •ê·œí™”"""
        try:
            console.print("ğŸ”„ 3ë‹¨ê³„: í…ìŠ¤íŠ¸ ì •ê·œí™” ì‹œì‘")
            
            # ì •ê·œí™”ë˜ì§€ ì•Šì€ ê¸°ì‚¬ë“¤ì„ ì¡°íšŒ
            articles = self._fetch_articles_for_normalization()
            
            if not articles:
                console.print("âœ… 3ë‹¨ê³„: ì •ê·œí™”í•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤")
                return True
            
            # ë°°ì¹˜ ì²˜ë¦¬ë¡œ í…ìŠ¤íŠ¸ ì •ê·œí™” ì‹¤í–‰
            processed_count, failed_count = self._process_articles_batch(
                articles, self._normalize_single_article
            )
            
            console.print(f"âœ… 3ë‹¨ê³„ ì™„ë£Œ: {processed_count}ê°œ ì •ê·œí™”, {failed_count}ê°œ ì‹¤íŒ¨")
            return True
            
        except Exception as e:
            console.print(f"âŒ 3ë‹¨ê³„ ì˜ˆì™¸ ë°œìƒ: {e}")
            return False
    
    def run_stage_4_content_merging(self) -> bool:
        """4ë‹¨ê³„: ì œëª©+ë³¸ë¬¸ í†µí•©"""
        try:
            console.print("ğŸ”„ 4ë‹¨ê³„: ì œëª©+ë³¸ë¬¸ í†µí•© ì‹œì‘")
            
            result = self.content_merger.process_content_merge()
            
            if result['successful_saves'] > 0:
                console.print(f"âœ… 4ë‹¨ê³„ ì™„ë£Œ: {result['successful_saves']}ê°œ ê¸°ì‚¬ í†µí•©ë¨")
                return True
            else:
                console.print("âŒ 4ë‹¨ê³„ ì‹¤íŒ¨: í†µí•©ëœ ê¸°ì‚¬ê°€ ì—†ìŒ")
                return False
                
        except Exception as e:
            console.print(f"âŒ 4ë‹¨ê³„ ì˜ˆì™¸ ë°œìƒ: {e}")
            return False
    
    def run_single_stage(self, stage_name: str) -> bool:
        """ë‹¨ì¼ ë‹¨ê³„ ì‹¤í–‰"""
        if stage_name not in self.stages:
            console.print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ë‹¨ê³„: {stage_name}")
            return False
        
        console.print(f"ğŸš€ {self.stages[stage_name]} ì‹¤í–‰ ì‹œì‘")
        
        if stage_name == 'duplicate_removal':
            return self.run_stage_1_duplicate_removal()
        elif stage_name == 'text_cleaning':
            return self.run_stage_2_text_cleaning()
        elif stage_name == 'text_normalization':
            return self.run_stage_3_text_normalization()
        elif stage_name == 'content_merging':
            return self.run_stage_4_content_merging()
    
    def run_full_pipeline(self, skip_stages: List[str] = None) -> bool:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        skip_stages = skip_stages or []
        
        console.print(Panel.fit("ğŸš€ ë‹¨ìˆœí™”ëœ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘", style="bold blue"))
        
        # ì´ˆê¸° ìƒíƒœ í™•ì¸
        initial_status = self.get_pipeline_status()
        console.print(f"ğŸ“Š ì´ˆê¸° ìƒíƒœ: ì „ì²´ ê¸°ì‚¬ {initial_status.get('articles_total', 0)}ê°œ")
        
        # ë‹¨ê³„ë³„ ì‹¤í–‰
        stage_order = ['duplicate_removal', 'text_cleaning', 'text_normalization', 'content_merging']
        
        for stage_name in stage_order:
            if stage_name in skip_stages:
                console.print(f"â­ï¸  {self.stages[stage_name]} ê±´ë„ˆëœ€")
                continue
                
            success = self.run_single_stage(stage_name)
            
            if not success:
                console.print(f"âŒ {self.stages[stage_name]} ì‹¤íŒ¨")
                return False
            
            console.print("-" * 40)
        
        # ìµœì¢… ìƒíƒœ í™•ì¸
        final_status = self.get_pipeline_status()
        console.print(f"ğŸ“Š ìµœì¢… ìƒíƒœ: ì •ì œëœ ê¸°ì‚¬ {final_status.get('cleaned_articles', 0)}ê°œ")
        
        console.print(Panel.fit("âœ… ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!", style="bold green"))
        return True
    
    def _fetch_articles_for_cleaning(self) -> List[Dict[str, Any]]:
        """ì •ì œë˜ì§€ ì•Šì€ ê¸°ì‚¬ë“¤ì„ ì¡°íšŒ"""
        try:
            result = self.supabase_manager.client.table('articles_cleaned').select(
                'id, article_id, title_cleaned, lead_paragraph'
            ).or_(
                'preprocessing_metadata->>text_cleaned.is.null,preprocessing_metadata->>text_cleaned.eq.false'
            ).execute()
            
            return result.data if result else []
        except Exception as e:
            console.print(f"âŒ ê¸°ì‚¬ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def _fetch_articles_for_normalization(self) -> List[Dict[str, Any]]:
        """ì •ê·œí™”ë˜ì§€ ì•Šì€ ê¸°ì‚¬ë“¤ì„ ì¡°íšŒ"""
        try:
            result = self.supabase_manager.client.table('articles_cleaned').select(
                'id, title_cleaned, lead_paragraph'
            ).or_(
                'preprocessing_metadata->>text_normalized.is.null,preprocessing_metadata->>text_normalized.eq.false'
            ).execute()
            
            return result.data if result else []
        except Exception as e:
            console.print(f"âŒ ê¸°ì‚¬ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def _process_articles_batch(self, articles: List[Dict[str, Any]], process_func) -> tuple:
        """ê¸°ì‚¬ë“¤ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬"""
        processed_count = 0
        failed_count = 0
        batch_size = 50
        update_batch = []
        
        for i, article in enumerate(articles):
            try:
                result = process_func(article)
                
                if result:
                    update_batch.append(result)
                    processed_count += 1
                else:
                    failed_count += 1
                
                # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ ì¼ê´„ ì—…ë°ì´íŠ¸
                if len(update_batch) >= batch_size or i == len(articles) - 1:
                    if update_batch:
                        self._batch_update_articles(update_batch)
                        update_batch = []
                        
            except Exception as e:
                failed_count += 1
                console.print(f"âŒ ê¸°ì‚¬ {article.get('id', 'unknown')} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        return processed_count, failed_count
    
    def _clean_single_article(self, article: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ë‹¨ì¼ ê¸°ì‚¬ ì •ì œ ì²˜ë¦¬"""
        try:
            # ì œëª©ê³¼ ë¦¬ë“œë¬¸ ì •ì œ
            cleaned_title, title_patterns = self.text_cleaner.clean_title(article['title_cleaned'] or '', 'unknown')
            cleaned_lead, lead_patterns = self.text_cleaner.clean_content(article['lead_paragraph'] or '', 'unknown')
            
            return {
                'id': article['id'],
                'title_cleaned': cleaned_title,
                'lead_paragraph': cleaned_lead,
                'preprocessing_metadata': {
                    'text_cleaned': True,
                    'text_cleaned_at': datetime.now().isoformat(),
                    'title_patterns_removed': title_patterns,
                    'lead_patterns_removed': lead_patterns
                },
                'updated_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            console.print(f"âŒ ê¸°ì‚¬ {article.get('id', 'unknown')} ì •ì œ ì‹¤íŒ¨: {e}")
            return None
    
    def _normalize_single_article(self, article: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ë‹¨ì¼ ê¸°ì‚¬ ì •ê·œí™” ì²˜ë¦¬"""
        try:
            # í…ìŠ¤íŠ¸ ì •ê·œí™” ì‹¤í–‰
            title_result = self.text_normalizer.normalize_text(article['title_cleaned'] or '')
            content_result = self.text_normalizer.normalize_text(article['lead_paragraph'] or '')
            
            return {
                'id': article['id'],
                'title_cleaned': title_result.normalized_text,
                'lead_paragraph': content_result.normalized_text,
                'preprocessing_metadata': {
                    'text_normalized': True,
                    'text_normalized_at': datetime.now().isoformat(),
                    'title_changes': title_result.changes_made,
                    'content_changes': content_result.changes_made
                },
                'updated_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            console.print(f"âŒ ê¸°ì‚¬ {article.get('id', 'unknown')} ì •ê·œí™” ì‹¤íŒ¨: {e}")
            return None
    
    def _batch_update_articles(self, update_batch: List[Dict[str, Any]]) -> None:
        """ê¸°ì‚¬ë“¤ì„ ë°°ì¹˜ë¡œ ì—…ë°ì´íŠ¸"""
        try:
            for update_data in update_batch:
                self.supabase_manager.client.table('articles_cleaned').update({
                    'title_cleaned': update_data['title_cleaned'],
                    'lead_paragraph': update_data['lead_paragraph'],
                    'preprocessing_metadata': update_data['preprocessing_metadata'],
                    'updated_at': update_data['updated_at']
                }).eq('id', update_data['id']).execute()
                
        except Exception as e:
            console.print(f"âŒ ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    # ì§ì ‘ ì‹¤í–‰ ì‹œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = SimplePreprocessingPipeline()
    
    # ìƒíƒœ í™•ì¸
    console.print("ğŸ“‹ íŒŒì´í”„ë¼ì¸ ìƒíƒœ í™•ì¸...")
    status = pipeline.get_pipeline_status()
    console.print(f"ì „ì²´ ê¸°ì‚¬: {status.get('articles_total', 0)}ê°œ")
    console.print(f"ì „ì²˜ë¦¬ëœ ê¸°ì‚¬: {status.get('articles_preprocessed', 0)}ê°œ")
    console.print(f"ì •ì œëœ ê¸°ì‚¬: {status.get('cleaned_articles', 0)}ê°œ")
    console.print(f"í†µí•©ëœ ê¸°ì‚¬: {status.get('merged_articles', 0)}ê°œ")
    console.print()
    
    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    success = pipeline.run_full_pipeline()
    
    if success:
        console.print("ğŸ‰ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        console.print("ğŸ’¥ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
