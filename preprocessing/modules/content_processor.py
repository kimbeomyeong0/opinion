#!/usr/bin/env python3
"""
í†µí•© ë‚´ìš© ì²˜ë¦¬ ëª¨ë“ˆ - KISS ì›ì¹™ ì ìš©
content_merger.pyì™€ lead_extractor.pyë¥¼ í†µí•©
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from utils.supabase_manager import SupabaseManager

@dataclass
class ContentMergeResult:
    """ë‚´ìš© í†µí•© ê²°ê³¼"""
    successful_saves: int
    failed_saves: int
    total_articles: int
    successful_merges: int
    failed_merges: int
    merge_strategies: Dict[str, int]

class ContentProcessor:
    """í†µí•© ë‚´ìš© ì²˜ë¦¬ í´ë˜ìŠ¤ - ë¦¬ë“œë¬¸ ì¶”ì¶œ + ë‚´ìš© í†µí•©"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.supabase_manager = SupabaseManager()
        
        # í†µí•© ì „ëµ ì •ì˜
        self.merge_strategies = {
            'title_only': 0,
            'lead_only': 0,
            'title_lead': 0,
            'full_content': 0
        }
    
    def process_content_merge(self) -> ContentMergeResult:
        """ë‚´ìš© í†µí•© ì²˜ë¦¬"""
        try:
            # í†µí•©í•  ê¸°ì‚¬ë“¤ ì¡°íšŒ
            articles = self._fetch_articles_for_merge()
            
            if not articles:
                return ContentMergeResult(
                    successful_saves=0,
                    failed_saves=0,
                    total_articles=0,
                    successful_merges=0,
                    failed_merges=0,
                    merge_strategies=self.merge_strategies
                )
            
            successful_saves = 0
            failed_saves = 0
            successful_merges = 0
            failed_merges = 0
            
            for article in articles:
                try:
                    # ë¦¬ë“œë¬¸ ì¶”ì¶œ
                    lead_paragraph = self._extract_lead_paragraph(article)
                    
                    # ë‚´ìš© í†µí•©
                    merged_content = self._merge_content(article, lead_paragraph)
                    
                    if merged_content:
                        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                        success = self._save_merged_content(article, merged_content)
                        
                        if success:
                            successful_saves += 1
                            successful_merges += 1
                        else:
                            failed_saves += 1
                            failed_merges += 1
                    else:
                        failed_saves += 1
                        failed_merges += 1
                        
                except Exception as e:
                    print(f"âŒ ê¸°ì‚¬ ì²˜ë¦¬ ì‹¤íŒ¨ (ID: {article.get('id', 'unknown')}): {str(e)}")
                    failed_saves += 1
                    failed_merges += 1
                    continue
            
            return ContentMergeResult(
                successful_saves=successful_saves,
                failed_saves=failed_saves,
                total_articles=len(articles),
                successful_merges=successful_merges,
                failed_merges=failed_merges,
                merge_strategies=self.merge_strategies
            )
            
        except Exception as e:
            return ContentMergeResult(
                successful_saves=0,
                failed_saves=0,
                total_articles=0,
                successful_merges=0,
                failed_merges=0,
                merge_strategies=self.merge_strategies
            )
    
    def _fetch_articles_for_merge(self) -> List[Dict[str, Any]]:
        """í†µí•©í•  ê¸°ì‚¬ë“¤ ì¡°íšŒ (articles í…Œì´ë¸”ì—ì„œ articles_cleanedì— ì—†ëŠ” ê¸°ì‚¬ë“¤) - í˜ì´ì§€ë„¤ì´ì…˜ ì ìš©"""
        try:
            # ë¨¼ì € ì´ë¯¸ ì „ì²˜ë¦¬ëœ ê¸°ì‚¬ IDë“¤ì„ ê°€ì ¸ì˜´
            processed_result = self.supabase_manager.client.table('articles_cleaned').select('article_id').execute()
            processed_ids = set(item['article_id'] for item in processed_result.data)
            
            # í˜ì´ì§€ë„¤ì´ì…˜ì„ ìœ„í•œ ë³€ìˆ˜ë“¤
            all_articles = []
            page_size = 1000  # Supabase ì œí•œ
            offset = 0
            
            print(f"ğŸ“… content_processor: articles í…Œì´ë¸”ì˜ ì „ì²˜ë¦¬ ëŒ€ê¸° ê¸°ì‚¬ ì²˜ë¦¬ (í˜ì´ì§€ë„¤ì´ì…˜ ì ìš©)")
            
            while True:
                # articles í…Œì´ë¸”ì—ì„œ í˜ì´ì§€ë³„ë¡œ ê¸°ì‚¬ ì¡°íšŒ
                result = self.supabase_manager.client.table('articles').select(
                    'id, title, content, media_id, published_at'
                ).range(offset, offset + page_size - 1).execute()
                
                if not result.data:
                    break  # ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
                
                # ì´ë¯¸ ì „ì²˜ë¦¬ëœ ê¸°ì‚¬ ì œì™¸
                new_articles = [article for article in result.data if article['id'] not in processed_ids]
                all_articles.extend(new_articles)
                
                print(f"  - í˜ì´ì§€ {offset//page_size + 1}: {len(result.data)}ê°œ ì¡°íšŒ, {len(new_articles)}ê°œ ì‹ ê·œ (ì´ {len(all_articles)}ê°œ)")
                
                # ë§ˆì§€ë§‰ í˜ì´ì§€ì¸ ê²½ìš° (ì¡°íšŒëœ ë°ì´í„°ê°€ page_sizeë³´ë‹¤ ì ìœ¼ë©´)
                if len(result.data) < page_size:
                    break
                
                offset += page_size
            
            print(f"âœ… ì´ {len(all_articles)}ê°œ ì‹ ê·œ ê¸°ì‚¬ ì¡°íšŒ ì™„ë£Œ")
            return all_articles
            
        except Exception as e:
            print(f"âŒ ê¸°ì‚¬ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _extract_lead_paragraph(self, article: Dict[str, Any]) -> str:
        """ë¦¬ë“œë¬¸ ì¶”ì¶œ - contentì—ì„œ ì²« ë²ˆì§¸ ë¬¸ë‹¨ ì¶”ì¶œ"""
        content = article.get('content', '').strip()
        
        if not content:
            return ''
        
        # ì²« ë²ˆì§¸ ë¬¸ë‹¨ ì¶”ì¶œ (ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)
        paragraphs = content.split('\n')
        first_paragraph = paragraphs[0].strip() if paragraphs else ''
        
        # ì²« ë²ˆì§¸ ë¬¸ë‹¨ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ì²˜ìŒ 200ì ì‚¬ìš©
        if len(first_paragraph) < 50:
            return content[:200].strip()
        
        return first_paragraph
    
    def _merge_content(self, article: Dict[str, Any], lead_paragraph: str) -> Optional[str]:
        """ë‚´ìš© í†µí•© - title + leadë§Œ í†µí•© (ê¸°ì‚¬ ë³¸ë¬¸ ì œì™¸)"""
        title = article.get('title', '').strip()
        lead = lead_paragraph.strip()
        
        if not title and not lead:
            return None
        
        # í†µí•© ì „ëµ ê²°ì • (ì œëª© + ë¦¬ë“œë§Œ)
        merged_parts = []
        
        if title:
            merged_parts.append(f"ì œëª©: {title}")
            self.merge_strategies['title_only'] += 1
        
        if lead:
            merged_parts.append(f"ë¦¬ë“œ: {lead}")
            self.merge_strategies['lead_only'] += 1
        
        if len(merged_parts) > 1:
            self.merge_strategies['title_lead'] += 1
        
        return '\n\n'.join(merged_parts)
    
    def _save_merged_content(self, article: Dict[str, Any], merged_content: str) -> bool:
        """í†µí•©ëœ ë‚´ìš©ì„ articles_cleaned í…Œì´ë¸”ì— ì €ì¥"""
        try:
            # articles_cleaned í…Œì´ë¸”ì— ìƒˆ ë ˆì½”ë“œ ìƒì„±
            data = {
                'article_id': article['id'],
                'merged_content': merged_content,
                'media_id': article['media_id'],
                'published_at': article['published_at']
            }
            
            result = self.supabase_manager.client.table('articles_cleaned').insert(data).execute()
            
            if result.data:
                # articles í…Œì´ë¸”ì—ëŠ” preprocessing_status ì»¬ëŸ¼ì´ ì—†ìœ¼ë¯€ë¡œ ì—…ë°ì´íŠ¸ ë¶ˆí•„ìš”
                return True
            
            return False
        except Exception as e:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            return False
